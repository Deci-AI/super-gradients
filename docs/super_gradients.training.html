<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Training package &mdash; SuperGradients 3.0.3 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Common package" href="super_gradients.common.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> SuperGradients
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Welcome To SuperGradients</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="welcome.html">Version 3 is out! Notebooks have been updated!</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#build-with-supergradients">Build with SuperGradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#quick-installation">Quick Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#what-s-new">What’s New</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#coming-soon">Coming soon</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#table-of-content">Table of Content</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#getting-started">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#advanced-features">Advanced Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#installation-methods">Installation Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#implemented-model-architectures">Implemented Model Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#documentation">Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#contributing">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#citation">Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#community">Community</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#license">License</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#deci-platform">Deci Platform</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Technical Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="super_gradients.common.html">Common package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training">super_gradients.training module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.DataAugmentation"><code class="docutils literal notranslate"><span class="pre">DataAugmentation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.DataAugmentation.to_tensor"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.to_tensor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.DataAugmentation.normalize"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.normalize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.DataAugmentation.cutout"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.cutout()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.train"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.predict"><code class="docutils literal notranslate"><span class="pre">Trainer.predict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.train_from_config"><code class="docutils literal notranslate"><span class="pre">Trainer.train_from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.resume_experiment"><code class="docutils literal notranslate"><span class="pre">Trainer.resume_experiment()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.evaluate_from_recipe"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate_from_recipe()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.evaluate_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate_checkpoint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id0"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.get_arch_params"><code class="docutils literal notranslate"><span class="pre">Trainer.get_arch_params</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.get_structure"><code class="docutils literal notranslate"><span class="pre">Trainer.get_structure</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.get_architecture"><code class="docutils literal notranslate"><span class="pre">Trainer.get_architecture</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.set_experiment_name"><code class="docutils literal notranslate"><span class="pre">Trainer.set_experiment_name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.get_module"><code class="docutils literal notranslate"><span class="pre">Trainer.get_module</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.set_module"><code class="docutils literal notranslate"><span class="pre">Trainer.set_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.test"><code class="docutils literal notranslate"><span class="pre">Trainer.test()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.evaluate"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.get_net"><code class="docutils literal notranslate"><span class="pre">Trainer.get_net</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.set_net"><code class="docutils literal notranslate"><span class="pre">Trainer.set_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.set_ckpt_best_name"><code class="docutils literal notranslate"><span class="pre">Trainer.set_ckpt_best_name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.Trainer.set_ema"><code class="docutils literal notranslate"><span class="pre">Trainer.set_ema()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.KDTrainer"><code class="docutils literal notranslate"><span class="pre">KDTrainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.KDTrainer.train_from_config"><code class="docutils literal notranslate"><span class="pre">KDTrainer.train_from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.KDTrainer.train"><code class="docutils literal notranslate"><span class="pre">KDTrainer.train()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.MultiGPUMode"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.MultiGPUMode.OFF"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.OFF</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.MultiGPUMode.DATA_PARALLEL"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.DATA_PARALLEL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.DISTRIBUTED_DATA_PARALLEL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.MultiGPUMode.AUTO"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.AUTO</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.MultiGPUMode.dict"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.dict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.StrictLoad"><code class="docutils literal notranslate"><span class="pre">StrictLoad</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.StrictLoad.OFF"><code class="docutils literal notranslate"><span class="pre">StrictLoad.OFF</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.StrictLoad.ON"><code class="docutils literal notranslate"><span class="pre">StrictLoad.ON</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.StrictLoad.NO_KEY_MATCHING"><code class="docutils literal notranslate"><span class="pre">StrictLoad.NO_KEY_MATCHING</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.EvaluationType"><code class="docutils literal notranslate"><span class="pre">EvaluationType</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.EvaluationType.TEST"><code class="docutils literal notranslate"><span class="pre">EvaluationType.TEST</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.EvaluationType.VALIDATION"><code class="docutils literal notranslate"><span class="pre">EvaluationType.VALIDATION</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-datasets-module">super_gradients.training.datasets module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.DataAugmentation"><code class="docutils literal notranslate"><span class="pre">DataAugmentation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DataAugmentation.to_tensor"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.to_tensor()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DataAugmentation.normalize"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.normalize()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DataAugmentation.cutout"><code class="docutils literal notranslate"><span class="pre">DataAugmentation.cutout()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.ListDataset"><code class="docutils literal notranslate"><span class="pre">ListDataset</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.DirectoryDataSet"><code class="docutils literal notranslate"><span class="pre">DirectoryDataSet</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet"><code class="docutils literal notranslate"><span class="pre">SegmentationDataSet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet.sample_loader"><code class="docutils literal notranslate"><span class="pre">SegmentationDataSet.sample_loader()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet.sample_transform"><code class="docutils literal notranslate"><span class="pre">SegmentationDataSet.sample_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet.target_loader"><code class="docutils literal notranslate"><span class="pre">SegmentationDataSet.target_loader()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet.target_transform"><code class="docutils literal notranslate"><span class="pre">SegmentationDataSet.target_transform()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet"><code class="docutils literal notranslate"><span class="pre">PascalVOC2012SegmentationDataSet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.IGNORE_LABEL"><code class="docutils literal notranslate"><span class="pre">PascalVOC2012SegmentationDataSet.IGNORE_LABEL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.target_transform"><code class="docutils literal notranslate"><span class="pre">PascalVOC2012SegmentationDataSet.target_transform()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.decode_segmentation_mask"><code class="docutils literal notranslate"><span class="pre">PascalVOC2012SegmentationDataSet.decode_segmentation_mask()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.PascalAUG2012SegmentationDataSet"><code class="docutils literal notranslate"><span class="pre">PascalAUG2012SegmentationDataSet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalAUG2012SegmentationDataSet.target_loader"><code class="docutils literal notranslate"><span class="pre">PascalAUG2012SegmentationDataSet.target_loader()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset"><code class="docutils literal notranslate"><span class="pre">PascalVOCAndAUGUnifiedDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.datasets"><code class="docutils literal notranslate"><span class="pre">PascalVOCAndAUGUnifiedDataset.datasets</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.cumulative_sizes"><code class="docutils literal notranslate"><span class="pre">PascalVOCAndAUGUnifiedDataset.cumulative_sizes</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.CoCoSegmentationDataSet"><code class="docutils literal notranslate"><span class="pre">CoCoSegmentationDataSet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.CoCoSegmentationDataSet.target_loader"><code class="docutils literal notranslate"><span class="pre">CoCoSegmentationDataSet.target_loader()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset"><code class="docutils literal notranslate"><span class="pre">DetectionDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.get_random_item"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.get_random_item()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.get_sample"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.get_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.get_resized_image"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.get_resized_image()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.apply_transforms"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.apply_transforms()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.get_random_samples"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.get_random_samples()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.get_random_sample"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.get_random_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.output_target_format"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.output_target_format</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset.plot"><code class="docutils literal notranslate"><span class="pre">DetectionDataset.plot()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.COCODetectionDataset"><code class="docutils literal notranslate"><span class="pre">COCODetectionDataset</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOCDetectionDataset"><code class="docutils literal notranslate"><span class="pre">PascalVOCDetectionDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.PascalVOCDetectionDataset.download"><code class="docutils literal notranslate"><span class="pre">PascalVOCDetectionDataset.download()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.ImageNetDataset"><code class="docutils literal notranslate"><span class="pre">ImageNetDataset</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.Cifar10"><code class="docutils literal notranslate"><span class="pre">Cifar10</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.Cifar100"><code class="docutils literal notranslate"><span class="pre">Cifar100</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.datasets.SuperviselyPersonsDataset"><code class="docutils literal notranslate"><span class="pre">SuperviselyPersonsDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.datasets.SuperviselyPersonsDataset.CLASS_LABELS"><code class="docutils literal notranslate"><span class="pre">SuperviselyPersonsDataset.CLASS_LABELS</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-dataloaders-module">super_gradients.training.dataloaders module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_train"><code class="docutils literal notranslate"><span class="pre">coco2017_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_val"><code class="docutils literal notranslate"><span class="pre">coco2017_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_train_yolox"><code class="docutils literal notranslate"><span class="pre">coco2017_train_yolox()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_val_yolox"><code class="docutils literal notranslate"><span class="pre">coco2017_val_yolox()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_train_ssd_lite_mobilenet_v2"><code class="docutils literal notranslate"><span class="pre">coco2017_train_ssd_lite_mobilenet_v2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco2017_val_ssd_lite_mobilenet_v2"><code class="docutils literal notranslate"><span class="pre">coco2017_val_ssd_lite_mobilenet_v2()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_train"><code class="docutils literal notranslate"><span class="pre">imagenet_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_val"><code class="docutils literal notranslate"><span class="pre">imagenet_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_efficientnet_train"><code class="docutils literal notranslate"><span class="pre">imagenet_efficientnet_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_efficientnet_val"><code class="docutils literal notranslate"><span class="pre">imagenet_efficientnet_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_mobilenetv2_train"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv2_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_mobilenetv2_val"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv2_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_mobilenetv3_train"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv3_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_mobilenetv3_val"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv3_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_regnetY_train"><code class="docutils literal notranslate"><span class="pre">imagenet_regnetY_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_regnetY_val"><code class="docutils literal notranslate"><span class="pre">imagenet_regnetY_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_resnet50_train"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_resnet50_val"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_resnet50_kd_train"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_kd_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_resnet50_kd_val"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_kd_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_vit_base_train"><code class="docutils literal notranslate"><span class="pre">imagenet_vit_base_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.imagenet_vit_base_val"><code class="docutils literal notranslate"><span class="pre">imagenet_vit_base_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.tiny_imagenet_train"><code class="docutils literal notranslate"><span class="pre">tiny_imagenet_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.tiny_imagenet_val"><code class="docutils literal notranslate"><span class="pre">tiny_imagenet_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cifar10_train"><code class="docutils literal notranslate"><span class="pre">cifar10_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cifar10_val"><code class="docutils literal notranslate"><span class="pre">cifar10_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cifar100_train"><code class="docutils literal notranslate"><span class="pre">cifar100_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cifar100_val"><code class="docutils literal notranslate"><span class="pre">cifar100_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_train"><code class="docutils literal notranslate"><span class="pre">cityscapes_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_val"><code class="docutils literal notranslate"><span class="pre">cityscapes_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg50_train"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg50_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg50_val"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg50_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg75_train"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg75_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg75_val"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg75_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_regseg48_train"><code class="docutils literal notranslate"><span class="pre">cityscapes_regseg48_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_regseg48_val"><code class="docutils literal notranslate"><span class="pre">cityscapes_regseg48_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_ddrnet_train"><code class="docutils literal notranslate"><span class="pre">cityscapes_ddrnet_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.cityscapes_ddrnet_val"><code class="docutils literal notranslate"><span class="pre">cityscapes_ddrnet_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco_segmentation_train"><code class="docutils literal notranslate"><span class="pre">coco_segmentation_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.coco_segmentation_val"><code class="docutils literal notranslate"><span class="pre">coco_segmentation_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_aug_segmentation_train"><code class="docutils literal notranslate"><span class="pre">pascal_aug_segmentation_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_aug_segmentation_val"><code class="docutils literal notranslate"><span class="pre">pascal_aug_segmentation_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_voc_segmentation_train"><code class="docutils literal notranslate"><span class="pre">pascal_voc_segmentation_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_voc_segmentation_val"><code class="docutils literal notranslate"><span class="pre">pascal_voc_segmentation_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.supervisely_persons_train"><code class="docutils literal notranslate"><span class="pre">supervisely_persons_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.supervisely_persons_val"><code class="docutils literal notranslate"><span class="pre">supervisely_persons_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_voc_detection_train"><code class="docutils literal notranslate"><span class="pre">pascal_voc_detection_train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.pascal_voc_detection_val"><code class="docutils literal notranslate"><span class="pre">pascal_voc_detection_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.get_data_loader"><code class="docutils literal notranslate"><span class="pre">get_data_loader()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.dataloaders.get"><code class="docutils literal notranslate"><span class="pre">get()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-exceptions-module">super_gradients.training.exceptions module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-kd-trainer-module">super_gradients.training.kd_trainer module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.kd_trainer.KDTrainer"><code class="docutils literal notranslate"><span class="pre">KDTrainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.kd_trainer.KDTrainer.train_from_config"><code class="docutils literal notranslate"><span class="pre">KDTrainer.train_from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.kd_trainer.KDTrainer.train"><code class="docutils literal notranslate"><span class="pre">KDTrainer.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.legacy">super_gradients.training.legacy module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.losses">super_gradients.training.losses_models module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.Losses"><code class="docutils literal notranslate"><span class="pre">Losses</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.CROSS_ENTROPY"><code class="docutils literal notranslate"><span class="pre">Losses.CROSS_ENTROPY</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.MSE"><code class="docutils literal notranslate"><span class="pre">Losses.MSE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.R_SQUARED_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.R_SQUARED_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.SHELFNET_OHEM_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.SHELFNET_OHEM_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.SHELFNET_SE_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.SHELFNET_SE_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.YOLOX_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.YOLOX_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.YOLOX_FAST_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.YOLOX_FAST_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.SSD_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.SSD_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.STDC_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.STDC_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.BCE_DICE_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.BCE_DICE_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.KD_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.KD_LOSS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.Losses.DICE_CE_EDGE_LOSS"><code class="docutils literal notranslate"><span class="pre">Losses.DICE_CE_EDGE_LOSS</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.FocalLoss"><code class="docutils literal notranslate"><span class="pre">FocalLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.FocalLoss.reduction"><code class="docutils literal notranslate"><span class="pre">FocalLoss.reduction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.FocalLoss.forward"><code class="docutils literal notranslate"><span class="pre">FocalLoss.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss"><code class="docutils literal notranslate"><span class="pre">LabelSmoothingCrossEntropyLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.forward"><code class="docutils literal notranslate"><span class="pre">LabelSmoothingCrossEntropyLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.ignore_index"><code class="docutils literal notranslate"><span class="pre">LabelSmoothingCrossEntropyLoss.ignore_index</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.label_smoothing"><code class="docutils literal notranslate"><span class="pre">LabelSmoothingCrossEntropyLoss.label_smoothing</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetOHEMLoss"><code class="docutils literal notranslate"><span class="pre">ShelfNetOHEMLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetOHEMLoss.forward"><code class="docutils literal notranslate"><span class="pre">ShelfNetOHEMLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetOHEMLoss.component_names"><code class="docutils literal notranslate"><span class="pre">ShelfNetOHEMLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetOHEMLoss.reduction"><code class="docutils literal notranslate"><span class="pre">ShelfNetOHEMLoss.reduction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss"><code class="docutils literal notranslate"><span class="pre">ShelfNetSemanticEncodingLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.forward"><code class="docutils literal notranslate"><span class="pre">ShelfNetSemanticEncodingLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.component_names"><code class="docutils literal notranslate"><span class="pre">ShelfNetSemanticEncodingLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.ignore_index"><code class="docutils literal notranslate"><span class="pre">ShelfNetSemanticEncodingLoss.ignore_index</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.label_smoothing"><code class="docutils literal notranslate"><span class="pre">ShelfNetSemanticEncodingLoss.label_smoothing</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.strides"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.strides</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.num_classes"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.num_classes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.use_l1"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.use_l1</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.center_sampling_radius"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.center_sampling_radius</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.iou_type"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.iou_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.component_names"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.forward"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.prepare_predictions"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.prepare_predictions()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.get_l1_target"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.get_l1_target()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.get_assignments"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.get_assignments()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.get_in_boxes_info"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.get_in_boxes_info()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.dynamic_k_matching"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.dynamic_k_matching()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss.reduction"><code class="docutils literal notranslate"><span class="pre">YoloXDetectionLoss.reduction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.YoloXFastDetectionLoss"><code class="docutils literal notranslate"><span class="pre">YoloXFastDetectionLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXFastDetectionLoss.reduction"><code class="docutils literal notranslate"><span class="pre">YoloXFastDetectionLoss.reduction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.YoloXFastDetectionLoss.training"><code class="docutils literal notranslate"><span class="pre">YoloXFastDetectionLoss.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.RSquaredLoss"><code class="docutils literal notranslate"><span class="pre">RSquaredLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.RSquaredLoss.forward"><code class="docutils literal notranslate"><span class="pre">RSquaredLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.RSquaredLoss.reduction"><code class="docutils literal notranslate"><span class="pre">RSquaredLoss.reduction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.SSDLoss"><code class="docutils literal notranslate"><span class="pre">SSDLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.SSDLoss.component_names"><code class="docutils literal notranslate"><span class="pre">SSDLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.SSDLoss.match_dboxes"><code class="docutils literal notranslate"><span class="pre">SSDLoss.match_dboxes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.SSDLoss.forward"><code class="docutils literal notranslate"><span class="pre">SSDLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.SSDLoss.reduction"><code class="docutils literal notranslate"><span class="pre">SSDLoss.reduction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.BCEDiceLoss"><code class="docutils literal notranslate"><span class="pre">BCEDiceLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.BCEDiceLoss.loss_weights"><code class="docutils literal notranslate"><span class="pre">BCEDiceLoss.loss_weights</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.BCEDiceLoss.forward"><code class="docutils literal notranslate"><span class="pre">BCEDiceLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.BCEDiceLoss.training"><code class="docutils literal notranslate"><span class="pre">BCEDiceLoss.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.KDLogitsLoss"><code class="docutils literal notranslate"><span class="pre">KDLogitsLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.KDLogitsLoss.component_names"><code class="docutils literal notranslate"><span class="pre">KDLogitsLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.KDLogitsLoss.forward"><code class="docutils literal notranslate"><span class="pre">KDLogitsLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.KDLogitsLoss.reduction"><code class="docutils literal notranslate"><span class="pre">KDLogitsLoss.reduction</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.losses.DiceCEEdgeLoss"><code class="docutils literal notranslate"><span class="pre">DiceCEEdgeLoss</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.DiceCEEdgeLoss.component_names"><code class="docutils literal notranslate"><span class="pre">DiceCEEdgeLoss.component_names</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.DiceCEEdgeLoss.forward"><code class="docutils literal notranslate"><span class="pre">DiceCEEdgeLoss.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.losses.DiceCEEdgeLoss.reduction"><code class="docutils literal notranslate"><span class="pre">DiceCEEdgeLoss.reduction</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.metrics">super_gradients.training.metrics module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.Metrics"><code class="docutils literal notranslate"><span class="pre">Metrics</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.ACCURACY"><code class="docutils literal notranslate"><span class="pre">Metrics.ACCURACY</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.TOP5"><code class="docutils literal notranslate"><span class="pre">Metrics.TOP5</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS"><code class="docutils literal notranslate"><span class="pre">Metrics.DETECTION_METRICS</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_050_095"><code class="docutils literal notranslate"><span class="pre">Metrics.DETECTION_METRICS_050_095</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_050"><code class="docutils literal notranslate"><span class="pre">Metrics.DETECTION_METRICS_050</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_075"><code class="docutils literal notranslate"><span class="pre">Metrics.DETECTION_METRICS_075</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.IOU"><code class="docutils literal notranslate"><span class="pre">Metrics.IOU</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.BINARY_IOU"><code class="docutils literal notranslate"><span class="pre">Metrics.BINARY_IOU</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.DICE"><code class="docutils literal notranslate"><span class="pre">Metrics.DICE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.BINARY_DICE"><code class="docutils literal notranslate"><span class="pre">Metrics.BINARY_DICE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Metrics.PIXEL_ACCURACY"><code class="docutils literal notranslate"><span class="pre">Metrics.PIXEL_ACCURACY</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.accuracy"><code class="docutils literal notranslate"><span class="pre">accuracy()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.Accuracy"><code class="docutils literal notranslate"><span class="pre">Accuracy</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Accuracy.update"><code class="docutils literal notranslate"><span class="pre">Accuracy.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Accuracy.correct"><code class="docutils literal notranslate"><span class="pre">Accuracy.correct</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Accuracy.total"><code class="docutils literal notranslate"><span class="pre">Accuracy.total</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.Top5"><code class="docutils literal notranslate"><span class="pre">Top5</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Top5.update"><code class="docutils literal notranslate"><span class="pre">Top5.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Top5.compute"><code class="docutils literal notranslate"><span class="pre">Top5.compute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.ToyTestClassificationMetric"><code class="docutils literal notranslate"><span class="pre">ToyTestClassificationMetric</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.ToyTestClassificationMetric.update"><code class="docutils literal notranslate"><span class="pre">ToyTestClassificationMetric.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.ToyTestClassificationMetric.compute"><code class="docutils literal notranslate"><span class="pre">ToyTestClassificationMetric.compute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.num_cls"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.num_cls</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.post_prediction_callback"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.post_prediction_callback</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.normalize_targets"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.normalize_targets</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.iou_thresholds"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.iou_thresholds</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.recall_thresholds"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.recall_thresholds</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.score_threshold"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.score_threshold</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.top_k_predictions"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.top_k_predictions</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.dist_sync_on_step"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.dist_sync_on_step</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.update"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics.compute"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics.compute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.PreprocessSegmentationMetricsArgs"><code class="docutils literal notranslate"><span class="pre">PreprocessSegmentationMetricsArgs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.PixelAccuracy"><code class="docutils literal notranslate"><span class="pre">PixelAccuracy</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.PixelAccuracy.update"><code class="docutils literal notranslate"><span class="pre">PixelAccuracy.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.PixelAccuracy.compute"><code class="docutils literal notranslate"><span class="pre">PixelAccuracy.compute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.IoU"><code class="docutils literal notranslate"><span class="pre">IoU</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.IoU.update"><code class="docutils literal notranslate"><span class="pre">IoU.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.IoU.confmat"><code class="docutils literal notranslate"><span class="pre">IoU.confmat</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.Dice"><code class="docutils literal notranslate"><span class="pre">Dice</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Dice.update"><code class="docutils literal notranslate"><span class="pre">Dice.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Dice.compute"><code class="docutils literal notranslate"><span class="pre">Dice.compute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.Dice.confmat"><code class="docutils literal notranslate"><span class="pre">Dice.confmat</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.BinaryIOU"><code class="docutils literal notranslate"><span class="pre">BinaryIOU</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryIOU.compute"><code class="docutils literal notranslate"><span class="pre">BinaryIOU.compute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryIOU.confmat"><code class="docutils literal notranslate"><span class="pre">BinaryIOU.confmat</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryIOU.training"><code class="docutils literal notranslate"><span class="pre">BinaryIOU.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.BinaryDice"><code class="docutils literal notranslate"><span class="pre">BinaryDice</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryDice.compute"><code class="docutils literal notranslate"><span class="pre">BinaryDice.compute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryDice.confmat"><code class="docutils literal notranslate"><span class="pre">BinaryDice.confmat</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.metrics.BinaryDice.training"><code class="docutils literal notranslate"><span class="pre">BinaryDice.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics_050"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics_050</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics_075"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics_075</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics_050_095"><code class="docutils literal notranslate"><span class="pre">DetectionMetrics_050_095</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.models">super_gradients.training.models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.sg_trainer">super_gradients.training.sg_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer"><code class="docutils literal notranslate"><span class="pre">Trainer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.train"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.predict"><code class="docutils literal notranslate"><span class="pre">Trainer.predict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.train_from_config"><code class="docutils literal notranslate"><span class="pre">Trainer.train_from_config()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.resume_experiment"><code class="docutils literal notranslate"><span class="pre">Trainer.resume_experiment()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.evaluate_from_recipe"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate_from_recipe()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.evaluate_checkpoint"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate_checkpoint()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#id3"><code class="docutils literal notranslate"><span class="pre">Trainer.train()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.get_arch_params"><code class="docutils literal notranslate"><span class="pre">Trainer.get_arch_params</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.get_structure"><code class="docutils literal notranslate"><span class="pre">Trainer.get_structure</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.get_architecture"><code class="docutils literal notranslate"><span class="pre">Trainer.get_architecture</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.set_experiment_name"><code class="docutils literal notranslate"><span class="pre">Trainer.set_experiment_name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.get_module"><code class="docutils literal notranslate"><span class="pre">Trainer.get_module</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.set_module"><code class="docutils literal notranslate"><span class="pre">Trainer.set_module()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.test"><code class="docutils literal notranslate"><span class="pre">Trainer.test()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.evaluate"><code class="docutils literal notranslate"><span class="pre">Trainer.evaluate()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.get_net"><code class="docutils literal notranslate"><span class="pre">Trainer.get_net</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.set_net"><code class="docutils literal notranslate"><span class="pre">Trainer.set_net()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.set_ckpt_best_name"><code class="docutils literal notranslate"><span class="pre">Trainer.set_ckpt_best_name()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer.set_ema"><code class="docutils literal notranslate"><span class="pre">Trainer.set_ema()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode.OFF"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.OFF</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode.DATA_PARALLEL"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.DATA_PARALLEL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.DISTRIBUTED_DATA_PARALLEL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode.AUTO"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.AUTO</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode.dict"><code class="docutils literal notranslate"><span class="pre">MultiGPUMode.dict()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.sg_trainer.StrictLoad"><code class="docutils literal notranslate"><span class="pre">StrictLoad</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.StrictLoad.OFF"><code class="docutils literal notranslate"><span class="pre">StrictLoad.OFF</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.StrictLoad.ON"><code class="docutils literal notranslate"><span class="pre">StrictLoad.ON</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.sg_trainer.StrictLoad.NO_KEY_MATCHING"><code class="docutils literal notranslate"><span class="pre">StrictLoad.NO_KEY_MATCHING</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-training-hyperparams-module">super_gradients.training.training_hyperparams module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cifar10_resnet_train_params"><code class="docutils literal notranslate"><span class="pre">cifar10_resnet_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cityscapes_ddrnet_train_params"><code class="docutils literal notranslate"><span class="pre">cityscapes_ddrnet_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cityscapes_regseg48_train_params"><code class="docutils literal notranslate"><span class="pre">cityscapes_regseg48_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_base_train_params"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_base_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_seg50_train_params"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg50_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_seg75_train_params"><code class="docutils literal notranslate"><span class="pre">cityscapes_stdc_seg75_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.coco2017_ssd_lite_mobilenet_v2_train_params"><code class="docutils literal notranslate"><span class="pre">coco2017_ssd_lite_mobilenet_v2_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.coco2017_yolox_train_params"><code class="docutils literal notranslate"><span class="pre">coco2017_yolox_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.coco_segmentation_shelfnet_lw_train_params"><code class="docutils literal notranslate"><span class="pre">coco_segmentation_shelfnet_lw_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_efficientnet_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_efficientnet_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv2_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv2_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_base_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv3_base_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_large_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv3_large_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_small_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_mobilenetv3_small_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_regnetY_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_regnetY_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_repvgg_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_repvgg_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_resnet50_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_resnet50_kd_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_resnet50_kd_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_vit_base_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_vit_base_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.imagenet_vit_large_train_params"><code class="docutils literal notranslate"><span class="pre">imagenet_vit_large_train_params()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.training_hyperparams.get"><code class="docutils literal notranslate"><span class="pre">get()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#super-gradients-training-transforms-module">super_gradients.training.transforms module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.Transforms"><code class="docutils literal notranslate"><span class="pre">Transforms</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegRandomFlip"><code class="docutils literal notranslate"><span class="pre">Transforms.SegRandomFlip</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegResize"><code class="docutils literal notranslate"><span class="pre">Transforms.SegResize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegRescale"><code class="docutils literal notranslate"><span class="pre">Transforms.SegRescale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegRandomRescale"><code class="docutils literal notranslate"><span class="pre">Transforms.SegRandomRescale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegRandomRotate"><code class="docutils literal notranslate"><span class="pre">Transforms.SegRandomRotate</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegCropImageAndMask"><code class="docutils literal notranslate"><span class="pre">Transforms.SegCropImageAndMask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegRandomGaussianBlur"><code class="docutils literal notranslate"><span class="pre">Transforms.SegRandomGaussianBlur</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegPadShortToCropSize"><code class="docutils literal notranslate"><span class="pre">Transforms.SegPadShortToCropSize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.SegColorJitter"><code class="docutils literal notranslate"><span class="pre">Transforms.SegColorJitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionMosaic"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionMosaic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionRandomAffine"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionRandomAffine</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionMixup"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionMixup</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionHSV"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionHSV</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionHorizontalFlip"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionHorizontalFlip</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionPaddedRescale"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionPaddedRescale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionTargetsFormat"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionTargetsFormat</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.DetectionTargetsFormatTransform"><code class="docutils literal notranslate"><span class="pre">Transforms.DetectionTargetsFormatTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomResizedCropAndInterpolation"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomResizedCropAndInterpolation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandAugmentTransform"><code class="docutils literal notranslate"><span class="pre">Transforms.RandAugmentTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Lighting"><code class="docutils literal notranslate"><span class="pre">Transforms.Lighting</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomErase"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomErase</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Compose"><code class="docutils literal notranslate"><span class="pre">Transforms.Compose</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.ToTensor"><code class="docutils literal notranslate"><span class="pre">Transforms.ToTensor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.PILToTensor"><code class="docutils literal notranslate"><span class="pre">Transforms.PILToTensor</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.ConvertImageDtype"><code class="docutils literal notranslate"><span class="pre">Transforms.ConvertImageDtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.ToPILImage"><code class="docutils literal notranslate"><span class="pre">Transforms.ToPILImage</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Normalize"><code class="docutils literal notranslate"><span class="pre">Transforms.Normalize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Resize"><code class="docutils literal notranslate"><span class="pre">Transforms.Resize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.CenterCrop"><code class="docutils literal notranslate"><span class="pre">Transforms.CenterCrop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Pad"><code class="docutils literal notranslate"><span class="pre">Transforms.Pad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Lambda"><code class="docutils literal notranslate"><span class="pre">Transforms.Lambda</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomApply"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomApply</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomChoice"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomChoice</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomOrder"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomOrder</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomCrop"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomCrop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomHorizontalFlip"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomHorizontalFlip</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomVerticalFlip"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomVerticalFlip</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomResizedCrop"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomResizedCrop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.FiveCrop"><code class="docutils literal notranslate"><span class="pre">Transforms.FiveCrop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.TenCrop"><code class="docutils literal notranslate"><span class="pre">Transforms.TenCrop</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.LinearTransformation"><code class="docutils literal notranslate"><span class="pre">Transforms.LinearTransformation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.ColorJitter"><code class="docutils literal notranslate"><span class="pre">Transforms.ColorJitter</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomRotation"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomRotation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomAffine"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomAffine</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.Grayscale"><code class="docutils literal notranslate"><span class="pre">Transforms.Grayscale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomGrayscale"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomGrayscale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomPerspective"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomPerspective</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomErasing"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomErasing</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.GaussianBlur"><code class="docutils literal notranslate"><span class="pre">Transforms.GaussianBlur</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.InterpolationMode"><code class="docutils literal notranslate"><span class="pre">Transforms.InterpolationMode</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomInvert"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomInvert</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomPosterize"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomPosterize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomSolarize"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomSolarize</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomAdjustSharpness"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomAdjustSharpness</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomAutocontrast"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomAutocontrast</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.Transforms.RandomEqualize"><code class="docutils literal notranslate"><span class="pre">Transforms.RandomEqualize</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.DetectionMosaic"><code class="docutils literal notranslate"><span class="pre">DetectionMosaic</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionMosaic.input_dim"><code class="docutils literal notranslate"><span class="pre">DetectionMosaic.input_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionMosaic.prob"><code class="docutils literal notranslate"><span class="pre">DetectionMosaic.prob</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionMosaic.enable_mosaic"><code class="docutils literal notranslate"><span class="pre">DetectionMosaic.enable_mosaic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionMosaic.close"><code class="docutils literal notranslate"><span class="pre">DetectionMosaic.close()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.target_size"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.target_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.degrees"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.degrees</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.translate"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.translate</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.scales"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.scales</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.shear"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.shear</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.enable"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.enable</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.filter_box_candidates"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.filter_box_candidates</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.wh_thr"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.wh_thr</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.ar_thr"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.ar_thr</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.area_thr"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.area_thr</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionRandomAffine.close"><code class="docutils literal notranslate"><span class="pre">DetectionRandomAffine.close()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.DetectionHSV"><code class="docutils literal notranslate"><span class="pre">DetectionHSV</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.DetectionPaddedRescale"><code class="docutils literal notranslate"><span class="pre">DetectionPaddedRescale</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionPaddedRescale.input_dim"><code class="docutils literal notranslate"><span class="pre">DetectionPaddedRescale.input_dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionPaddedRescale.swap"><code class="docutils literal notranslate"><span class="pre">DetectionPaddedRescale.swap</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform"><code class="docutils literal notranslate"><span class="pre">DetectionTargetsFormatTransform</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.output_format"><code class="docutils literal notranslate"><span class="pre">DetectionTargetsFormatTransform.output_format</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.min_bbox_edge_size"><code class="docutils literal notranslate"><span class="pre">DetectionTargetsFormatTransform.min_bbox_edge_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.max_targets"><code class="docutils literal notranslate"><span class="pre">DetectionTargetsFormatTransform.max_targets</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-super_gradients.training.utils">super_gradients.training.utils module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.Timer"><code class="docutils literal notranslate"><span class="pre">Timer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.Timer.start"><code class="docutils literal notranslate"><span class="pre">Timer.start()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.Timer.stop"><code class="docutils literal notranslate"><span class="pre">Timer.stop()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.HpmStruct"><code class="docutils literal notranslate"><span class="pre">HpmStruct</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.HpmStruct.set_schema"><code class="docutils literal notranslate"><span class="pre">HpmStruct.set_schema()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.HpmStruct.override"><code class="docutils literal notranslate"><span class="pre">HpmStruct.override()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.HpmStruct.to_dict"><code class="docutils literal notranslate"><span class="pre">HpmStruct.to_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.HpmStruct.validate"><code class="docutils literal notranslate"><span class="pre">HpmStruct.validate()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.WrappedModel"><code class="docutils literal notranslate"><span class="pre">WrappedModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.WrappedModel.forward"><code class="docutils literal notranslate"><span class="pre">WrappedModel.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#super_gradients.training.utils.WrappedModel.training"><code class="docutils literal notranslate"><span class="pre">WrappedModel.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.convert_to_tensor"><code class="docutils literal notranslate"><span class="pre">convert_to_tensor()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.get_param"><code class="docutils literal notranslate"><span class="pre">get_param()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.tensor_container_to_device"><code class="docutils literal notranslate"><span class="pre">tensor_container_to_device()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.adapt_state_dict_to_fit_model_layer_names"><code class="docutils literal notranslate"><span class="pre">adapt_state_dict_to_fit_model_layer_names()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.raise_informative_runtime_error"><code class="docutils literal notranslate"><span class="pre">raise_informative_runtime_error()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.random_seed"><code class="docutils literal notranslate"><span class="pre">random_seed()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#super_gradients.training.utils.torch_version_is_greater_or_equal"><code class="docutils literal notranslate"><span class="pre">torch_version_is_greater_or_equal()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#module-contents">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperGradients</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Training package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/super_gradients.training.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="training-package">
<h1>Training package<a class="headerlink" href="#training-package" title="Permalink to this heading"></a></h1>
<table class="autosummary longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
</tbody>
</table>
<div class="section" id="module-super_gradients.training">
<span id="super-gradients-training-module"></span><h2>super_gradients.training module<a class="headerlink" href="#module-super_gradients.training" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.DataAugmentation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">DataAugmentation</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.DataAugmentation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.DataAugmentation.to_tensor">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.DataAugmentation.to_tensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.DataAugmentation.normalize">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.DataAugmentation.normalize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.DataAugmentation.cutout">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cutout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutout_inside</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.cutout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.DataAugmentation.cutout" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_gpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode" title="super_gradients.common.data_types.enum.multi_gpu_mode.MultiGPUMode"><span class="pre">MultiGPUMode</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">MultiGPUMode.OFF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>SuperGradient Model - Base Class for Sg Models</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.train" title="Permalink to this definition"></a></dt>
<dd><p>the main function used for the training, h.p. updating, logging etc.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#super_gradients.training.Trainer.predict" title="Permalink to this definition"></a></dt>
<dd><p>returns the predictions and label of the current inputs</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">test(epoch</span> <span class="pre">:</span> <span class="pre">int,</span> <span class="pre">idx</span> <span class="pre">:</span> <span class="pre">int,</span> <span class="pre">save</span> <span class="pre">:</span> <span class="pre">bool):</span></span></dt>
<dd><p>returns the test loss, accuracy and runtime</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.train_from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DictConfig</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train_from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.train_from_config" title="Permalink to this definition"></a></dt>
<dd><p>Trains according to cfg recipe configuration.</p>
<p>&#64;param cfg: The parsed DictConfig from yaml recipe files or a dictionary
&#64;return: the model and the output of trainer.train(…) (i.e results tuple)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.resume_experiment">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">resume_experiment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.resume_experiment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.resume_experiment" title="Permalink to this definition"></a></dt>
<dd><p>Resume a training that was run using our recipes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> – Name of the experiment to resume</p></li>
<li><p><strong>ckpt_root_dir</strong> – Directory including the checkpoints</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.evaluate_from_recipe">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate_from_recipe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DictConfig</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate_from_recipe"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.evaluate_from_recipe" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate according to a cfg recipe configuration.</p>
<dl class="simple">
<dt>Note:   This script does NOT run training, only validation.</dt><dd><p>Please make sure that the config refers to a PRETRAINED MODEL either from one of your checkpoint or from pretrained weights from model zoo.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cfg</strong> – The parsed DictConfig from yaml recipe files or a dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.evaluate_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ckpt_latest.pth'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.evaluate_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate a checkpoint resulting from one of your previous experiment, using the same parameters (dataset, valid_metrics,…)
as used during the training of the experiment</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parameters will be unchanged even if the recipe used for that experiment was changed since then.
This is to ensure that validation of the experiment will remain exactly the same as during training.</p>
</div>
<dl class="simple">
<dt>Example, evaluate the checkpoint “average_model.pth” from experiment “my_experiment_name”:</dt><dd><p>&gt;&gt; evaluate_checkpoint(experiment_name=”my_experiment_name”, ckpt_name=”average_model.pth”)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> – Name of the experiment to validate</p></li>
<li><p><strong>ckpt_name</strong> – Name of the checkpoint to test (“ckpt_latest.pth”, “average_model.pth” or “ckpt_best.pth” for instance)</p></li>
<li><p><strong>ckpt_root_dir</strong> – Directory including the checkpoints</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_configs_to_log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Permalink to this definition"></a></dt>
<dd><p>train - Trains the Model</p>
<dl>
<dt>IMPORTANT NOTE: Additional batch parameters can be added as a third item (optional) if a tuple is returned by</dt><dd><p>the data loaders, as dictionary. The phase context will hold the additional items, under an attribute with
the same name as the key in this dictionary. Then such items can be accessed through phase callbacks.</p>
<blockquote>
<div><dl class="field-list">
<dt class="field-odd">param additional_configs_to_log</dt>
<dd class="field-odd"><p>Dict, dictionary containing configs that will be added to the training’s
sg_logger. Format should be {“Config_title_1”: {…}, “Config_title_2”:{..}}.</p>
</dd>
<dt class="field-even">param model</dt>
<dd class="field-even"><p>torch.nn.Module, model to train.</p>
</dd>
<dt class="field-odd">param train_loader</dt>
<dd class="field-odd"><p>Dataloader for train set.</p>
</dd>
<dt class="field-even">param valid_loader</dt>
<dd class="field-even"><p>Dataloader for validation.</p>
</dd>
<dt class="field-odd">param training_params</dt>
<dd class="field-odd"><ul>
<li><p><cite>resume</cite> : bool (default=False)</p>
<blockquote>
<div><dl class="simple">
<dt>Whether to continue training from ckpt with the same experiment name</dt><dd><p>(i.e resume from CKPT_ROOT_DIR/EXPERIMENT_NAME/CKPT_NAME)</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ckpt_name</cite> : str (default=ckpt_latest.pth)</p>
<blockquote>
<div><dl class="simple">
<dt>The checkpoint (.pth file) filename in CKPT_ROOT_DIR/EXPERIMENT_NAME/ to use when resume=True and</dt><dd><p>resume_path=None</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>resume_path</cite>: str (default=None)</p>
<blockquote>
<div><p>Explicit checkpoint path (.pth file) to use to resume training.</p>
</div></blockquote>
</li>
<li><p><cite>max_epochs</cite> : int</p>
<blockquote>
<div><p>Number of epochs to run training.</p>
</div></blockquote>
</li>
<li><p><cite>lr_updates</cite> : list(int)</p>
<blockquote>
<div><p>List of fixed epoch numbers to perform learning rate updates when <cite>lr_mode=’step’</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_decay_factor</cite> : float</p>
<blockquote>
<div><p>Decay factor to apply to the learning rate at each update when <cite>lr_mode=’step’</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_mode</cite> : str</p>
<blockquote>
<div><p>Learning rate scheduling policy, one of [‘step’,’poly’,’cosine’,’function’]. ‘step’ refers to
constant updates at epoch numbers passed through <cite>lr_updates</cite>. ‘cosine’ refers to Cosine Anealing
policy as mentioned in <a class="reference external" href="https://arxiv.org/abs/1608.03983">https://arxiv.org/abs/1608.03983</a>. ‘poly’ refers to polynomial decrease i.e
in each epoch iteration <cite>self.lr = self.initial_lr * pow((1.0 - (current_iter / max_iter)),
0.9)</cite> ‘function’ refers to user defined learning rate scheduling function, that is passed through
<cite>lr_schedule_function</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_schedule_function</cite> : Union[callable,None]</p>
<blockquote>
<div><p>Learning rate scheduling function to be used when <cite>lr_mode</cite> is ‘function’.</p>
</div></blockquote>
</li>
<li><p><cite>lr_warmup_epochs</cite> : int (default=0)</p>
<blockquote>
<div><p>Number of epochs for learning rate warm up - see <a class="reference external" href="https://arxiv.org/pdf/1706.02677.pdf">https://arxiv.org/pdf/1706.02677.pdf</a> (Section 2.2).</p>
</div></blockquote>
</li>
<li><dl class="simple">
<dt><cite>cosine_final_lr_ratio</cite><span class="classifier">float (default=0.01)</span></dt><dd><dl class="simple">
<dt>Final learning rate ratio (only relevant when <a href="#id1"><span class="problematic" id="id2">`</span></a>lr_mode`=’cosine’). The cosine starts from initial_lr and reaches</dt><dd><p>initial_lr * cosine_final_lr_ratio in last epoch</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><p><cite>inital_lr</cite> : float</p>
<blockquote>
<div><p>Initial learning rate.</p>
</div></blockquote>
</li>
<li><p><cite>loss</cite> : Union[nn.module, str]</p>
<blockquote>
<div><blockquote>
<div><p>Loss function for training.
One of SuperGradient’s built in options:</p>
<blockquote>
<div><p>“cross_entropy”: LabelSmoothingCrossEntropyLoss,
“mse”: MSELoss,
“r_squared_loss”: RSquaredLoss,
“detection_loss”: YoLoV3DetectionLoss,
“shelfnet_ohem_loss”: ShelfNetOHEMLoss,
“shelfnet_se_loss”: ShelfNetSemanticEncodingLoss,
“ssd_loss”: SSDLoss,</p>
</div></blockquote>
<p>or user defined nn.module loss function.</p>
<p>IMPORTANT: forward(…) should return a (loss, loss_items) tuple where loss is the tensor used
for backprop (i.e what your original loss function returns), and loss_items should be a tensor of
shape (n_items), of values computed during the forward pass which we desire to log over the
entire epoch. For example- the loss itself should always be logged. Another example is a scenario
where the computed loss is the sum of a few components we would like to log- these entries in
loss_items).</p>
<p>IMPORTANT:When dealing with external loss classes, to logg/monitor the loss_items as described
above by specific string name:</p>
<dl>
<dt>Set a “component_names” property in the loss class, whos instance is passed through train_params,</dt><dd><p>to be a list of strings, of length n_items who’s ith element is the name of the ith entry in loss_items.
Then each item will be logged, rendered on tensorboard and “watched” (i.e saving model checkpoints
according to it) under &lt;LOSS_CLASS.__name__&gt;”/”&lt;COMPONENT_NAME&gt;. If a single item is returned rather then a
tuple, it would be logged under &lt;LOSS_CLASS.__name__&gt;. When there is no such attributed, the items
will be named &lt;LOSS_CLASS.__name__&gt;”/”<a href="#id6"><span class="problematic" id="id7">Loss_</span></a>”&lt;IDX&gt; according to the length of loss_items</p>
</dd>
<dt>For example:</dt><dd><dl>
<dt>class MyLoss(_Loss):</dt><dd><p>…
def forward(self, inputs, targets):</p>
<blockquote>
<div><p>…
total_loss = comp1 + comp2
loss_items = torch.cat((total_loss.unsqueeze(0),comp1.unsqueeze(0), comp2.unsqueeze(0)).detach()
return total_loss, loss_items</p>
</div></blockquote>
<p>…
&#64;property
def component_names(self):</p>
<blockquote>
<div><p>return [“total_loss”, “my_1st_component”, “my_2nd_component”]</p>
</div></blockquote>
</dd>
</dl>
</dd>
<dt>Trainer.train(…</dt><dd><blockquote>
<div><dl class="simple">
<dt>train_params={“loss”:MyLoss(),</dt><dd><p>…
“metric_to_watch”: “MyLoss/my_1st_component”}</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>This will write to log and monitor MyLoss/total_loss, MyLoss/my_1st_component,</dt><dd><p>MyLoss/my_2nd_component.</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>For example:</dt><dd><blockquote>
<div><dl>
<dt>class MyLoss2(_Loss):</dt><dd><p>…
def forward(self, inputs, targets):</p>
<blockquote>
<div><p>…
total_loss = comp1 + comp2
loss_items = torch.cat((total_loss.unsqueeze(0),comp1.unsqueeze(0), comp2.unsqueeze(0)).detach()
return total_loss, loss_items</p>
</div></blockquote>
<p>…</p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>Trainer.train(…</dt><dd><blockquote>
<div><dl class="simple">
<dt>train_params={“loss”:MyLoss(),</dt><dd><p>…
“metric_to_watch”: “MyLoss2/loss_0”}</p>
</dd>
</dl>
</div></blockquote>
<p>This will write to log and monitor MyLoss2/loss_0, MyLoss2/loss_1, MyLoss2/loss_2
as they have been named by their positional index in loss_items.</p>
</dd>
</dl>
<p>Since running logs will save the loss_items in some internal state, it is recommended that
loss_items are detached from their computational graph for memory efficiency.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>optimizer</cite> : Union[str, torch.optim.Optimizer]</p>
<blockquote>
<div><p>Optimization algorithm. One of [‘Adam’,’SGD’,’RMSProp’] corresponding to the torch.optim
optimzers implementations, or any object that implements torch.optim.Optimizer.</p>
</div></blockquote>
</li>
<li><p><cite>criterion_params</cite> : dict</p>
<blockquote>
<div><p>Loss function parameters.</p>
</div></blockquote>
</li>
<li><dl>
<dt><cite>optimizer_params</cite><span class="classifier">dict</span></dt><dd><p>When <cite>optimizer</cite> is one of [‘Adam’,’SGD’,’RMSProp’], it will be initialized with optimizer_params.</p>
<p>(see <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">https://pytorch.org/docs/stable/optim.html</a> for the full list of
parameters for each optimizer).</p>
</dd>
</dl>
</li>
<li><p><cite>train_metrics_list</cite> : list(torchmetrics.Metric)</p>
<blockquote>
<div><p>Metrics to log during training. For more information on torchmetrics see
<a class="reference external" href="https://torchmetrics.rtfd.io/en/latest/">https://torchmetrics.rtfd.io/en/latest/</a>.</p>
</div></blockquote>
</li>
<li><p><cite>valid_metrics_list</cite> : list(torchmetrics.Metric)</p>
<blockquote>
<div><p>Metrics to log during validation/testing. For more information on torchmetrics see
<a class="reference external" href="https://torchmetrics.rtfd.io/en/latest/">https://torchmetrics.rtfd.io/en/latest/</a>.</p>
</div></blockquote>
</li>
<li><p><cite>loss_logging_items_names</cite> : list(str)</p>
<blockquote>
<div><p>The list of names/titles for the outputs returned from the loss functions forward pass (reminder-
the loss function should return the tuple (loss, loss_items)). These names will be used for
logging their values.</p>
</div></blockquote>
</li>
<li><p><cite>metric_to_watch</cite> : str (default=”Accuracy”)</p>
<blockquote>
<div><p>will be the metric which the model checkpoint will be saved according to, and can be set to any
of the following:</p>
<blockquote>
<div><p>a metric name (str) of one of the metric objects from the valid_metrics_list</p>
<p>a “metric_name” if some metric in valid_metrics_list has an attribute component_names which
is a list referring to the names of each entry in the output metric (torch tensor of size n)</p>
<p>one of “loss_logging_items_names” i.e which will correspond to an item returned during the
loss function’s forward pass (see loss docs abov).</p>
</div></blockquote>
<p>At the end of each epoch, if a new best metric_to_watch value is achieved, the models checkpoint
is saved in YOUR_PYTHON_PATH/checkpoints/ckpt_best.pth</p>
</div></blockquote>
</li>
<li><p><cite>greater_metric_to_watch_is_better</cite> : bool</p>
<blockquote>
<div><dl class="simple">
<dt>When choosing a model’s checkpoint to be saved, the best achieved model is the one that maximizes the</dt><dd><p>metric_to_watch when this parameter is set to True, and a one that minimizes it otherwise.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ema</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to use Model Exponential Moving Average (see
<a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a> ema implementation)</p>
</div></blockquote>
</li>
<li><p><cite>batch_accumulate</cite> : int (default=1)</p>
<blockquote>
<div><p>Number of batches to accumulate before every backward pass.</p>
</div></blockquote>
</li>
<li><p><cite>ema_params</cite> : dict</p>
<blockquote>
<div><p>Parameters for the ema model.</p>
</div></blockquote>
</li>
<li><p><cite>zero_weight_decay_on_bias_and_bn</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to apply weight decay on batch normalization parameters or not (ignored when the passed
optimizer has already been initialized).</p>
</div></blockquote>
</li>
<li><p><cite>load_opt_params</cite> : bool (default=True)</p>
<blockquote>
<div><p>Whether to load the optimizers parameters as well when loading a model’s checkpoint.</p>
</div></blockquote>
</li>
<li><p><cite>run_validation_freq</cite> : int (default=1)</p>
<blockquote>
<div><dl class="simple">
<dt>The frequency in which validation is performed during training (i.e the validation is ran every</dt><dd><p><cite>run_validation_freq</cite> epochs.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>save_model</cite> : bool (default=True)</p>
<blockquote>
<div><p>Whether to save the model checkpoints.</p>
</div></blockquote>
</li>
<li><p><cite>silent_mode</cite> : bool</p>
<blockquote>
<div><p>Silents the print outs.</p>
</div></blockquote>
</li>
<li><p><cite>mixed_precision</cite> : bool</p>
<blockquote>
<div><p>Whether to use mixed precision or not.</p>
</div></blockquote>
</li>
<li><p><cite>save_ckpt_epoch_list</cite> : list(int) (default=[])</p>
<blockquote>
<div><p>List of fixed epoch indices the user wishes to save checkpoints in.</p>
</div></blockquote>
</li>
<li><p><cite>average_best_models</cite> : bool (default=False)</p>
<blockquote>
<div><p>If set, a snapshot dictionary file and the average model will be saved / updated at every epoch
and evaluated only when training is completed. The snapshot file will only be deleted upon
completing the training. The snapshot dict will be managed on cpu.</p>
</div></blockquote>
</li>
<li><p><cite>precise_bn</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to use precise_bn calculation during the training.</p>
</div></blockquote>
</li>
<li><p><cite>precise_bn_batch_size</cite> : int (default=None)</p>
<blockquote>
<div><p>The effective batch size we want to calculate the batchnorm on. For example, if we are training a model
on 8 gpus, with a batch of 128 on each gpu, a good rule of thumb would be to give it 8192
(ie: effective_batch_size * num_gpus = batch_per_gpu * num_gpus * num_gpus).
If precise_bn_batch_size is not provided in the training_params, the latter heuristic will be taken.</p>
</div></blockquote>
</li>
<li><p><cite>seed</cite> : int (default=42)</p>
<blockquote>
<div><p>Random seed to be set for torch, numpy, and random. When using DDP each process will have it’s seed
set to seed + rank.</p>
</div></blockquote>
</li>
<li><p><cite>log_installed_packages</cite> : bool (default=False)</p>
<blockquote>
<div><dl class="simple">
<dt>When set, the list of all installed packages (and their versions) will be written to the tensorboard</dt><dd><p>and logfile (useful when trying to reproduce results).</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>dataset_statistics</cite> : bool (default=False)</p>
<blockquote>
<div><p>Enable a statistic analysis of the dataset. If set to True the dataset will be analyzed and a report
will be added to the tensorboard along with some sample images from the dataset. Currently only
detection datasets are supported for analysis.</p>
</div></blockquote>
</li>
<li><p><cite>sg_logger</cite> : Union[AbstractSGLogger, str] (defauls=base_sg_logger)</p>
<blockquote>
<div><p>Define the SGLogger object for this training process. The SGLogger handles all disk writes, logs, TensorBoard, remote logging
and remote storage. By overriding the default base_sg_logger, you can change the storage location, support external monitoring and logging
or support remote storage.</p>
</div></blockquote>
</li>
<li><p><cite>sg_logger_params</cite> : dict</p>
<p>SGLogger parameters</p>
</li>
<li><p><cite>clip_grad_norm</cite> : float</p>
<p>Defines a maximal L2 norm of the gradients. Values which exceed the given value will be clipped</p>
</li>
<li><p><cite>lr_cooldown_epochs</cite> : int (default=0)</p>
<p>Number of epochs to cooldown LR (i.e the last epoch from scheduling view point=max_epochs-cooldown).</p>
</li>
<li><p><cite>pre_prediction_callback</cite> : Callable (default=None)</p>
<blockquote>
<div><dl class="simple">
<dt>When not None, this callback will be applied to images and targets, and returning them to be used</dt><dd><p>for the forward pass, and further computations. Args for this callable should be in the order
(inputs, targets, batch_idx) returning modified_inputs, modified_targets</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ckpt_best_name</cite> : str (default=’ckpt_best.pth’)</p>
<p>The best checkpoint (according to metric_to_watch) will be saved under this filename in the checkpoints directory.</p>
</li>
<li><p><cite>enable_qat</cite>: bool (default=False)</p>
<dl class="simple">
<dt>Adds a QATCallback to the phase callbacks, that triggers quantization aware training starting from</dt><dd><p>qat_params[“start_epoch”]</p>
</dd>
</dl>
</li>
<li><p><cite>qat_params</cite>: dict-like object with the following key/values:</p>
<blockquote>
<div><p>start_epoch: int, first epoch to start QAT.</p>
<dl class="simple">
<dt>quant_modules_calib_method: str, One of [percentile, mse, entropy, max]. Statistics method for amax</dt><dd><p>computation of the quantized modules (default=percentile).</p>
</dd>
</dl>
<p>per_channel_quant_modules: bool, whether quant modules should be per channel (default=False).</p>
<p>calibrate: bool, whether to perfrom calibration (default=False).</p>
<p>calibrated_model_path: str, path to a calibrated checkpoint (default=None).</p>
<dl class="simple">
<dt>calib_data_loader: torch.utils.data.DataLoader, data loader of the calibration dataset. When None,</dt><dd><p>context.train_loader will be used (default=None).</p>
</dd>
</dl>
<p>num_calib_batches: int, number of batches to collect the statistics from.</p>
<dl class="simple">
<dt>percentile: float, percentile value to use when Trainer,quant_modules_calib_method=’percentile’.</dt><dd><p>Discarded when other methods are used (Default=99.99).</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.get_arch_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_arch_params</span></span><a class="headerlink" href="#super_gradients.training.Trainer.get_arch_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.get_structure">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_structure</span></span><a class="headerlink" href="#super_gradients.training.Trainer.get_structure" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.get_architecture">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_architecture</span></span><a class="headerlink" href="#super_gradients.training.Trainer.get_architecture" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.set_experiment_name">
<span class="sig-name descname"><span class="pre">set_experiment_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_experiment_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.set_experiment_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.get_module">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_module</span></span><a class="headerlink" href="#super_gradients.training.Trainer.get_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.set_module">
<span class="sig-name descname"><span class="pre">set_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.set_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">_Loss</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_metrics_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_logging_items_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_progress_verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_phase_callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ema_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.test" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the model on given dataloader and metrics.
:param model: model to perfrom test on. When none is given, will try to use self.net (defalut=None).
:param test_loader: dataloader to perform test on.
:param test_metrics_list: (list(torchmetrics.Metric)) metrics list for evaluation.
:param silent_mode: (bool) controls verbosity
:param metrics_progress_verbose: (bool) controls the verbosity of metrics progress (default=False). Slows down the program.
:param use_ema_net (bool) whether to perform test on self.ema_model.ema (when self.ema_model.ema exists,</p>
<blockquote>
<div><p>otherwise self.net will be tested) (default=True)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>results tuple (tuple) containing the loss items and metric values.</p>
</dd>
</dl>
<dl class="simple">
<dt>All of the above args will override Trainer’s corresponding attribute when not equal to None. Then evaluation</dt><dd><p>is ran on self.test_loader with self.test_metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">MetricCollection</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#super_gradients.training.EvaluationType" title="super_gradients.common.data_types.enum.evaluation_type.EvaluationType"><span class="pre">EvaluationType</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_progress_verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the model on given dataloader and metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> – dataloader to perform evaluataion on</p></li>
<li><p><strong>metrics</strong> – (MetricCollection) metrics for evaluation</p></li>
<li><p><strong>evaluation_type</strong> – (EvaluationType) controls which phase callbacks will be used (for example, on batch end,
when evaluation_type=EvaluationType.VALIDATION the Phase.VALIDATION_BATCH_END callbacks will be triggered)</p></li>
<li><p><strong>epoch</strong> – (int) epoch idx</p></li>
<li><p><strong>silent_mode</strong> – (bool) controls verbosity</p></li>
<li><p><strong>metrics_progress_verbose</strong> – (bool) controls the verbosity of metrics progress (default=False).
Slows down the program significantly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>results tuple (tuple) containing the loss items and metric values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.get_net">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_net</span></span><a class="headerlink" href="#super_gradients.training.Trainer.get_net" title="Permalink to this definition"></a></dt>
<dd><p>Getter for network.
:return: torch.nn.Module, self.net</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.set_net">
<span class="sig-name descname"><span class="pre">set_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.set_net" title="Permalink to this definition"></a></dt>
<dd><p>Setter for network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>net</strong> – torch.nn.Module, value to set net</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.set_ckpt_best_name">
<span class="sig-name descname"><span class="pre">set_ckpt_best_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_best_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_ckpt_best_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.set_ckpt_best_name" title="Permalink to this definition"></a></dt>
<dd><p>Setter for best checkpoint filename.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ckpt_best_name</strong> – str, value to set ckpt_best_name</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.Trainer.set_ema">
<span class="sig-name descname"><span class="pre">set_ema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_ema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.Trainer.set_ema" title="Permalink to this definition"></a></dt>
<dd><p>Setter for self.ema</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>val</strong> – bool, value to set ema</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.KDTrainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">KDTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_gpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode" title="super_gradients.common.data_types.enum.multi_gpu_mode.MultiGPUMode"><span class="pre">MultiGPUMode</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">MultiGPUMode.OFF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.KDTrainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer" title="super_gradients.training.sg_trainer.sg_trainer.Trainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.KDTrainer.train_from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DictConfig</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer.train_from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.KDTrainer.train_from_config" title="Permalink to this definition"></a></dt>
<dd><p>Trains according to cfg recipe configuration.</p>
<p>&#64;param cfg: The parsed DictConfig from yaml recipe files
&#64;return: output of kd_trainer.train(…) (i.e results tuple)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.KDTrainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">KDModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">student</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">SgModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">teacher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kd_architecture</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kd_module'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kd_arch_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_teacher_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.KDTrainer.train" title="Permalink to this definition"></a></dt>
<dd><p>Trains the student network (wrapped in KDModule network).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – KDModule, network to train. When none is given will initialize KDModule according to kd_architecture,
student and teacher (default=None)</p></li>
<li><p><strong>training_params</strong> – dict, Same as in Trainer.train()</p></li>
<li><p><strong>student</strong> – SgModule - the student trainer</p></li>
<li><p><strong>teacher</strong> – torch.nn.Module- the teacher trainer</p></li>
<li><p><strong>kd_architecture</strong> – KDModule architecture to use, currently only ‘kd_module’ is supported (default=’kd_module’).</p></li>
<li><p><strong>kd_arch_params</strong> – architecture params to pas to kd_architecture constructor.</p></li>
<li><p><strong>run_teacher_on_eval</strong> – bool- whether to run self.teacher at eval mode regardless of self.train(mode)</p></li>
<li><p><strong>train_loader</strong> – Dataloader for train set.</p></li>
<li><p><strong>valid_loader</strong> – Dataloader for validation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">MultiGPUMode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/multi_gpu_mode.html#MultiGPUMode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.MultiGPUMode" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">OFF</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Single</span> <span class="pre">GPU</span> <span class="pre">Mode</span> <span class="pre">/</span> <span class="pre">CPU</span> <span class="pre">Mode</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">DATA_PARALLEL</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Multiple</span> <span class="pre">GPUs,</span> <span class="pre">Synchronous</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">DISTRIBUTED_DATA_PARALLEL</span> <span class="pre">-</span> <span class="pre">Multiple</span> <span class="pre">GPUs,</span> <span class="pre">Asynchronous</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode.OFF">
<span class="sig-name descname"><span class="pre">OFF</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Off'</span></em><a class="headerlink" href="#super_gradients.training.MultiGPUMode.OFF" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode.DATA_PARALLEL">
<span class="sig-name descname"><span class="pre">DATA_PARALLEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DP'</span></em><a class="headerlink" href="#super_gradients.training.MultiGPUMode.DATA_PARALLEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL">
<span class="sig-name descname"><span class="pre">DISTRIBUTED_DATA_PARALLEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DDP'</span></em><a class="headerlink" href="#super_gradients.training.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode.AUTO">
<span class="sig-name descname"><span class="pre">AUTO</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'AUTO'</span></em><a class="headerlink" href="#super_gradients.training.MultiGPUMode.AUTO" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.MultiGPUMode.dict">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/multi_gpu_mode.html#MultiGPUMode.dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.MultiGPUMode.dict" title="Permalink to this definition"></a></dt>
<dd><p>return dictionary mapping from the mode name (in call string cases) to the enum value</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.StrictLoad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">StrictLoad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/strict_load.html#StrictLoad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.StrictLoad" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>Wrapper for adding more functionality to torch’s strict_load parameter in load_state_dict().
.. attribute:: OFF              - Native torch “strict_load = off” behaviour. See nn.Module.load_state_dict() documentation for more details.</p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">ON</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Native</span> <span class="pre">torch</span> <span class="pre">&quot;strict_load</span> <span class="pre">=</span> <span class="pre">on&quot;</span> <span class="pre">behaviour.</span> <span class="pre">See</span> <span class="pre">nn.Module.load_state_dict()</span> <span class="pre">documentation</span> <span class="pre">for</span> <span class="pre">more</span> <span class="pre">details.</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">NO_KEY_MATCHING</span>&#160; <span class="pre">-</span> <span class="pre">Allows</span> <span class="pre">the</span> <span class="pre">usage</span> <span class="pre">of</span> <span class="pre">SuperGradient's</span> <span class="pre">adapt_checkpoint</span> <span class="pre">function,</span> <span class="pre">which</span> <span class="pre">loads</span> <span class="pre">a</span> <span class="pre">checkpoint</span> <span class="pre">by</span> <span class="pre">matching</span> <span class="pre">each</span></span></dt>
<dd><p>layer’s shapes (and bypasses the strict matching of the names of each layer (ie: disregards the state_dict key matching)).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.StrictLoad.OFF">
<span class="sig-name descname"><span class="pre">OFF</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#super_gradients.training.StrictLoad.OFF" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.StrictLoad.ON">
<span class="sig-name descname"><span class="pre">ON</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#super_gradients.training.StrictLoad.ON" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.StrictLoad.NO_KEY_MATCHING">
<span class="sig-name descname"><span class="pre">NO_KEY_MATCHING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'no_key_matching'</span></em><a class="headerlink" href="#super_gradients.training.StrictLoad.NO_KEY_MATCHING" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.EvaluationType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.</span></span><span class="sig-name descname"><span class="pre">EvaluationType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/evaluation_type.html#EvaluationType"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.EvaluationType" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>Passed to Trainer.evaluate(..), and controls which phase callbacks should be triggered (if at all).</p>
<blockquote>
<div><dl class="simple">
<dt>Attributes:</dt><dd><p>TEST
VALIDATION</p>
</dd>
</dl>
</div></blockquote>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.EvaluationType.TEST">
<span class="sig-name descname"><span class="pre">TEST</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'TEST'</span></em><a class="headerlink" href="#super_gradients.training.EvaluationType.TEST" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.EvaluationType.VALIDATION">
<span class="sig-name descname"><span class="pre">VALIDATION</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'VALIDATION'</span></em><a class="headerlink" href="#super_gradients.training.EvaluationType.VALIDATION" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="super-gradients-training-datasets-module">
<h2>super_gradients.training.datasets module<a class="headerlink" href="#super-gradients-training-datasets-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.datasets"></span><dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DataAugmentation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">DataAugmentation</span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DataAugmentation" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DataAugmentation.to_tensor">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DataAugmentation.to_tensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DataAugmentation.normalize">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">normalize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.normalize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DataAugmentation.normalize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DataAugmentation.cutout">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">cutout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutout_inside</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_color</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/data_augmentation.html#DataAugmentation.cutout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DataAugmentation.cutout" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.ListDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">ListDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_loader:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">default_loader&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_loader:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_extensions:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">('.jpg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.jpeg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.ppm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.bmp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.pgm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.tif'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.tiff'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.webp')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_transform:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_transform:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_extension='.npy'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#ListDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.ListDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseSgVisionDataset</span></code></p>
<dl>
<dt>ListDataset - A PyTorch Vision Data Set extension that receives a file with FULL PATH to each of the samples.</dt><dd><p>Then, the assumption is that for every sample, there is a * matching target * in the same
path but with a different extension, i.e:</p>
<blockquote>
<div><dl class="simple">
<dt>for the samples paths:  (That appear in the list file)</dt><dd><p>/root/dataset/class_x/sample1.png
/root/dataset/class_y/sample123.png</p>
</dd>
<dt>the matching labels paths:  (That DO NOT appear in the list file)</dt><dd><p>/root/dataset/class_x/sample1.ext
/root/dataset/class_y/sample123.ext</p>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DirectoryDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">DirectoryDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_sub_directory:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets_sub_directory:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_extension:</span> <span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_loader:</span> <span class="pre">~typing.Callable</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">default_loader&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_loader:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_extensions:</span> <span class="pre">tuple</span> <span class="pre">=</span> <span class="pre">('.jpg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.jpeg'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.ppm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.bmp'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.pgm'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.tif'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.tiff'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">'.webp')</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_transform:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_transform:</span> <span class="pre">~typing.Optional[~typing.Callable]</span> <span class="pre">=</span> <span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/sg_dataset.html#DirectoryDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DirectoryDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">BaseSgVisionDataset</span></code></p>
<dl class="simple">
<dt>DirectoryDataSet - A PyTorch Vision Data Set extension that receives a root Dir and two separate sub directories:</dt><dd><ul class="simple">
<li><p>Sub-Directory for Samples</p></li>
<li><p>Sub-Directory for Targets</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SegmentationDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">SegmentationDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples_sub_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets_sub_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_images</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collate_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_extension</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/segmentation_dataset.html#SegmentationDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SegmentationDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.DirectoryDataSet" title="super_gradients.training.datasets.sg_dataset.DirectoryDataSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">DirectoryDataSet</span></code></a>, <a class="reference internal" href="#super_gradients.training.datasets.ListDataset" title="super_gradients.training.datasets.sg_dataset.ListDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">ListDataset</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SegmentationDataSet.sample_loader">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">&lt;module</span> <span class="pre">'PIL.Image'</span> <span class="pre">from</span> <span class="pre">'/home/ofri/.conda/envs/sg/lib/python3.8/site-packages/PIL/Image.py'&gt;</span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/segmentation_dataset.html#SegmentationDataSet.sample_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SegmentationDataSet.sample_loader" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>sample_loader - Loads a dataset image from path using PIL</dt><dd><dl class="field-list simple">
<dt class="field-odd">param sample_path</dt>
<dd class="field-odd"><p>The path to the sample image</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The loaded Image</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SegmentationDataSet.sample_transform">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">sample_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/segmentation_dataset.html#SegmentationDataSet.sample_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SegmentationDataSet.sample_transform" title="Permalink to this definition"></a></dt>
<dd><p>sample_transform - Transforms the sample image</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param image</dt>
<dd class="field-odd"><p>The input image to transform</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The transformed image</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SegmentationDataSet.target_loader">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">&lt;module</span> <span class="pre">'PIL.Image'</span> <span class="pre">from</span> <span class="pre">'/home/ofri/.conda/envs/sg/lib/python3.8/site-packages/PIL/Image.py'&gt;</span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/segmentation_dataset.html#SegmentationDataSet.target_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SegmentationDataSet.target_loader" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_path</strong> – The path to the sample image</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The loaded Image</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SegmentationDataSet.target_transform">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/segmentation_dataset.html#SegmentationDataSet.target_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SegmentationDataSet.target_transform" title="Permalink to this definition"></a></dt>
<dd><p>target_transform - Transforms the sample image</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param target</dt>
<dd class="field-odd"><p>The target mask to transform</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The transformed target mask</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOC2012SegmentationDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">PascalVOC2012SegmentationDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_suffix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalVOC2012SegmentationDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet" title="super_gradients.training.datasets.segmentation_datasets.segmentation_dataset.SegmentationDataSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">SegmentationDataSet</span></code></a></p>
<p>PascalVOC2012SegmentationDataSet - Segmentation Data Set Class for Pascal VOC 2012 Data Set</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.IGNORE_LABEL">
<span class="sig-name descname"><span class="pre">IGNORE_LABEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">21</span></em><a class="headerlink" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.IGNORE_LABEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.target_transform">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalVOC2012SegmentationDataSet.target_transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.target_transform" title="Permalink to this definition"></a></dt>
<dd><p>target_transform - Transforms the label mask
This function overrides the original function from SegmentationDataSet and changes target pixels with value
255 to value = IGNORE_LABEL. This was done since current IoU metric from torchmetrics does not
support such a high ignore label value (crashed on OOM)</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param target</dt>
<dd class="field-odd"><p>The target mask to transform</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The transformed target mask</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.decode_segmentation_mask">
<span class="sig-name descname"><span class="pre">decode_segmentation_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ndarray</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalVOC2012SegmentationDataSet.decode_segmentation_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet.decode_segmentation_mask" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>decode_segmentation_mask - Decodes the colors for the Segmentation Mask</dt><dd><dl class="field-list simple">
<dt class="field-odd">param</dt>
<dd class="field-odd"><p>label_mask:  an (M,N) array of integer values denoting
the class label at each spatial location.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalAUG2012SegmentationDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">PascalAUG2012SegmentationDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalAUG2012SegmentationDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalAUG2012SegmentationDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.PascalVOC2012SegmentationDataSet" title="super_gradients.training.datasets.segmentation_datasets.pascal_voc_segmentation.PascalVOC2012SegmentationDataSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">PascalVOC2012SegmentationDataSet</span></code></a></p>
<p>PascalAUG2012SegmentationDataSet - Segmentation Data Set Class for Pascal AUG 2012 Data Set</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalAUG2012SegmentationDataSet.target_loader">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">target_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">&lt;module</span> <span class="pre">'PIL.Image'</span> <span class="pre">from</span> <span class="pre">'/home/ofri/.conda/envs/sg/lib/python3.8/site-packages/PIL/Image.py'&gt;</span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalAUG2012SegmentationDataSet.target_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalAUG2012SegmentationDataSet.target_loader" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target_path</strong> – The path to the target data</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The loaded target</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">PascalVOCAndAUGUnifiedDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/pascal_voc_segmentation.html#PascalVOCAndAUGUnifiedDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ConcatDataset</span></code></p>
<p>Pascal VOC + AUG train dataset, aka <cite>SBD</cite> dataset contributed in “Semantic contours from inverse detectors”.
This is class implement the common usage of the SBD and PascalVOC datasets as a unified augmented trainset.
The unified dataset includes a total of 10,582 samples and don’t contains duplicate samples from the PascalVOC
validation set.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.datasets">
<span class="sig-name descname"><span class="pre">datasets</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dataset</span><span class="p"><span class="pre">[</span></span><span class="pre">T_co</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.datasets" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.cumulative_sizes">
<span class="sig-name descname"><span class="pre">cumulative_sizes</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.datasets.PascalVOCAndAUGUnifiedDataset.cumulative_sizes" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.CoCoSegmentationDataSet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">CoCoSegmentationDataSet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_classes_inclusion_tuples_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/coco_segmentation.html#CoCoSegmentationDataSet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.CoCoSegmentationDataSet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet" title="super_gradients.training.datasets.segmentation_datasets.segmentation_dataset.SegmentationDataSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">SegmentationDataSet</span></code></a></p>
<p>CoCoSegmentationDataSet - Segmentation Data Set Class for COCO 2017 Segmentation Data Set</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.CoCoSegmentationDataSet.target_loader">
<span class="sig-name descname"><span class="pre">target_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mask_metadata_tuple</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">&lt;module</span> <span class="pre">'PIL.Image'</span> <span class="pre">from</span> <span class="pre">'/home/ofri/.conda/envs/sg/lib/python3.8/site-packages/PIL/Image.py'&gt;</span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/coco_segmentation.html#CoCoSegmentationDataSet.target_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.CoCoSegmentationDataSet.target_loader" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mask_metadata_tuple</strong> – A tuple of (coco_image_id, original_image_height, original_image_width)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The mask image created from the array</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">DetectionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">original_target_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DetectionTargetsFormat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">DetectionTransform</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_classes_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_inclusion_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_empty_annotations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_fields</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_fields</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dataset</span></code></p>
<p>Detection dataset.</p>
<p>This is a boilerplate class to facilitate the implementation of datasets.</p>
<dl>
<dt>HOW TO CREATE A DATASET THAT INHERITS FROM DetectionDataSet ?</dt><dd><ul class="simple">
<li><p>Inherit from DetectionDataSet</p></li>
<li><p>implement the method self._load_annotation to return at least the fields “target” and “img_path”</p></li>
<li><dl class="simple">
<dt>Call super().__init__ with the required params.</dt><dd><dl class="simple">
<dt>//!super().__init__ will call self._load_annotation, so make sure that every required</dt><dd><p>attributes are set up before calling super().__init__ (ideally just call it last)</p>
</dd>
</dl>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>WORKFLOW:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>On instantiation:</dt><dd><ul>
<li><p>All annotations are cached. If class_inclusion_list was specified, there is also subclassing at this step.</p></li>
<li><p>If cache is True, the images are also cached</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>On call (__getitem__) for a specific image index:</dt><dd><ul>
<li><p>The image and annotations are grouped together in a dict called SAMPLE</p></li>
<li><p>the sample is processed according to th transform</p></li>
<li><p>Only the specified fields are returned by __getitem__</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>TERMINOLOGY</dt><dd><ul>
<li><p>TARGET:       Groundtruth, made of bboxes. The format can vary from one dataset to another</p></li>
<li><dl class="simple">
<dt>ANNOTATION:   Combination of targets (groundtruth) and metadata of the image, but without the image itself.</dt><dd><p>&gt; Has to include the fields “target” and “img_path”
&gt; Can include other fields like “crowd_target”, “image_info”, “segmentation”, …</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>SAMPLE:       Outout of the dataset:</dt><dd><p>&gt; Has to include the fields “target” and “image”
&gt; Can include other fields like “crowd_target”, “image_info”, “segmentation”, …</p>
</dd>
</dl>
</li>
<li><p>INDEX:        Refers to the index in the dataset.</p></li>
<li><dl>
<dt>SAMPLE ID:    Refers to the id of sample before droping any annotaion.</dt><dd><p>Let’s imagine a situation where the downloaded data is made of 120 images but 20 were drop
because they had no annotation. In that case:</p>
<blockquote>
<div><p>&gt; We have 120 samples so sample_id will be between 0 and 119
&gt; But only 100 will be indexed so index will be between 0 and 99
&gt; Therefore, we also have len(self) = 100</p>
</div></blockquote>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.get_random_item">
<span class="sig-name descname"><span class="pre">get_random_item</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.get_random_item"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.get_random_item" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.get_sample">
<span class="sig-name descname"><span class="pre">get_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.get_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.get_sample" title="Permalink to this definition"></a></dt>
<dd><p>Get raw sample, before any transform (beside subclassing).
:param index:   Image index
:return:        Sample, i.e. a dictionary including at least “image” and “target”</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.get_resized_image">
<span class="sig-name descname"><span class="pre">get_resized_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ndarray</span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.get_resized_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.get_resized_image" title="Permalink to this definition"></a></dt>
<dd><p>Get the resized image (i.e. either width or height reaches its input_dim) at a specific sample_id,
either from cache or by loading from disk, based on self.cached_imgs_padded
:param index:  Image index
:return:       Resized image</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.apply_transforms">
<span class="sig-name descname"><span class="pre">apply_transforms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.apply_transforms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.apply_transforms" title="Permalink to this definition"></a></dt>
<dd><p>Applies self.transforms sequentially to sample</p>
<dl class="simple">
<dt>If a transforms has the attribute ‘additional_samples_count’, additional samples will be loaded and stored in</dt><dd><p>sample[“additional_samples”] prior to applying it. Combining with the attribute “non_empty_annotations” will load
only additional samples with objects in them.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>sample</strong> – Sample to apply the transforms on to (loaded with self.get_sample)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Transformed sample</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.get_random_samples">
<span class="sig-name descname"><span class="pre">get_random_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">count</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_empty_annotations_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">ndarray</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.get_random_samples"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.get_random_samples" title="Permalink to this definition"></a></dt>
<dd><p>Load random samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>count</strong> – The number of samples wanted</p></li>
<li><p><strong>non_empty_annotations_only</strong> – If true, only return samples with at least 1 annotation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of samples satisfying input params</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.get_random_sample">
<span class="sig-name descname"><span class="pre">get_random_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">non_empty_annotations_only</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.get_random_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.get_random_sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.output_target_format">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">output_target_format</span></span><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.output_target_format" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.DetectionDataset.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_samples_per_plot</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_plots</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_transformed_data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/detection_dataset.html#DetectionDataset.plot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.DetectionDataset.plot" title="Permalink to this definition"></a></dt>
<dd><p>Combine samples of images with bbox into plots and display the result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>max_samples_per_plot</strong> – Maximum number of images to be displayed per plot</p></li>
<li><p><strong>n_plots</strong> – Number of plots to display (each plot being a combination of img with bbox)</p></li>
<li><p><strong>plot_transformed_data</strong> – If True, the plot will be over samples after applying transforms (i.e. on __getitem__).
If False, the plot will be over the raw samples (i.e. on get_sample)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.COCODetectionDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">COCODetectionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">json_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'instances_train2017.json'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subdir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'images/train2017'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tight_box_rotation</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_crowd</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/coco_detection.html#COCODetectionDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.COCODetectionDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset" title="super_gradients.training.datasets.detection_datasets.detection_dataset.DetectionDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionDataset</span></code></a></p>
<p>Dataset for COCO object detection.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOCDetectionDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">PascalVOCDetectionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">images_sub_directory</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/pascal_voc_detection.html#PascalVOCDetectionDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOCDetectionDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.DetectionDataset" title="super_gradients.training.datasets.detection_datasets.detection_dataset.DetectionDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionDataset</span></code></a></p>
<p>Dataset for Pascal VOC object detection</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.datasets.PascalVOCDetectionDataset.download">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">download</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/detection_datasets/pascal_voc_detection.html#PascalVOCDetectionDataset.download"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.PascalVOCDetectionDataset.download" title="Permalink to this definition"></a></dt>
<dd><p>Download Pascal dataset in XYXY_LABEL format.</p>
<p>Data extracted form <a class="reference external" href="http://host.robots.ox.ac.uk/pascal/VOC/">http://host.robots.ox.ac.uk/pascal/VOC/</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.ImageNetDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">ImageNetDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/classification_datasets/imagenet_dataset.html#ImageNetDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.ImageNetDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ImageFolder</span></code></p>
<p>ImageNetDataset dataset</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.Cifar10">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">Cifar10</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/classification_datasets/cifar.html#Cifar10"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.Cifar10" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">CIFAR10</span></code></p>
<p>CIFAR10 Dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Path for the data to be extracted</p></li>
<li><p><strong>train</strong> – Bool to load training (True) or validation (False) part of the dataset</p></li>
<li><p><strong>transforms</strong> – List of transforms to apply sequentially on sample. Wrapped internally with torchvision.Compose</p></li>
<li><p><strong>target_transform</strong> – Transform to apply to target output</p></li>
<li><p><strong>download</strong> – Download (True) the dataset from source</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.Cifar100">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">Cifar100</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/classification_datasets/cifar.html#Cifar100"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.Cifar100" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">CIFAR100</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SuperviselyPersonsDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.datasets.</span></span><span class="sig-name descname"><span class="pre">SuperviselyPersonsDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/datasets/segmentation_datasets/supervisely_persons_segmentation.html#SuperviselyPersonsDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.datasets.SuperviselyPersonsDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.datasets.SegmentationDataSet" title="super_gradients.training.datasets.segmentation_datasets.segmentation_dataset.SegmentationDataSet"><code class="xref py py-class docutils literal notranslate"><span class="pre">SegmentationDataSet</span></code></a></p>
<p>SuperviselyPersonsDataset - Segmentation Data Set Class for Supervisely Persons Segmentation Data Set,
main resolution of dataset: (600 x 800).
This dataset is a subset of the original dataset (see below) and contains filtered samples
For more details about the ORIGINAL dataset see: <a class="reference external" href="https://app.supervise.ly/ecosystem/projects/persons">https://app.supervise.ly/ecosystem/projects/persons</a>
For more details about the FILTERED dataset see:
<a class="reference external" href="https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.3/contrib/PP-HumanSeg">https://github.com/PaddlePaddle/PaddleSeg/tree/release/2.3/contrib/PP-HumanSeg</a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.datasets.SuperviselyPersonsDataset.CLASS_LABELS">
<span class="sig-name descname"><span class="pre">CLASS_LABELS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">{0:</span> <span class="pre">'background',</span> <span class="pre">1:</span> <span class="pre">'person'}</span></em><a class="headerlink" href="#super_gradients.training.datasets.SuperviselyPersonsDataset.CLASS_LABELS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="super-gradients-training-dataloaders-module">
<h2>super_gradients.training.dataloaders module<a class="headerlink" href="#super-gradients-training-dataloaders-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.dataloaders"></span><dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_train_yolox">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_train_yolox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_train_yolox"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_train_yolox" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_val_yolox">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_val_yolox</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_val_yolox"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_val_yolox" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_train_ssd_lite_mobilenet_v2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_train_ssd_lite_mobilenet_v2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_train_ssd_lite_mobilenet_v2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_train_ssd_lite_mobilenet_v2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco2017_val_ssd_lite_mobilenet_v2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco2017_val_ssd_lite_mobilenet_v2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco2017_val_ssd_lite_mobilenet_v2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco2017_val_ssd_lite_mobilenet_v2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'imagenet_dataset_params'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'imagenet_dataset_params'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_efficientnet_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_efficientnet_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_efficientnet_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_efficientnet_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_efficientnet_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_efficientnet_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_efficientnet_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_efficientnet_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_mobilenetv2_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv2_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_mobilenetv2_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_mobilenetv2_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_mobilenetv2_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv2_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_mobilenetv2_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_mobilenetv2_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_mobilenetv3_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv3_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_mobilenetv3_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_mobilenetv3_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_mobilenetv3_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv3_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_mobilenetv3_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_mobilenetv3_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_regnetY_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_regnetY_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_regnetY_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_regnetY_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_regnetY_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_regnetY_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_regnetY_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_regnetY_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_resnet50_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_resnet50_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_resnet50_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_resnet50_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_resnet50_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_resnet50_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_resnet50_kd_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_kd_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_resnet50_kd_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_resnet50_kd_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_resnet50_kd_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_kd_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_resnet50_kd_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_resnet50_kd_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_vit_base_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_vit_base_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_vit_base_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_vit_base_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.imagenet_vit_base_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">imagenet_vit_base_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#imagenet_vit_base_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.imagenet_vit_base_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.tiny_imagenet_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">tiny_imagenet_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tiny_imagenet_dataset_params'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#tiny_imagenet_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.tiny_imagenet_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.tiny_imagenet_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">tiny_imagenet_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">config_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'tiny_imagenet_dataset_params'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#tiny_imagenet_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.tiny_imagenet_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cifar10_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cifar10_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cifar10_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cifar10_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cifar10_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cifar10_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cifar10_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cifar10_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cifar100_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cifar100_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cifar100_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cifar100_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cifar100_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cifar100_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cifar100_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cifar100_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_stdc_seg50_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg50_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_stdc_seg50_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg50_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_stdc_seg50_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg50_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_stdc_seg50_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg50_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_stdc_seg75_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg75_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_stdc_seg75_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg75_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_stdc_seg75_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg75_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_stdc_seg75_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_stdc_seg75_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_regseg48_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_regseg48_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_regseg48_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_regseg48_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_regseg48_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_regseg48_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_regseg48_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_regseg48_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_ddrnet_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_ddrnet_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_ddrnet_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_ddrnet_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.cityscapes_ddrnet_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">cityscapes_ddrnet_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#cityscapes_ddrnet_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.cityscapes_ddrnet_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco_segmentation_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco_segmentation_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco_segmentation_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco_segmentation_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.coco_segmentation_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">coco_segmentation_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#coco_segmentation_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.coco_segmentation_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_aug_segmentation_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_aug_segmentation_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_aug_segmentation_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_aug_segmentation_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_aug_segmentation_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_aug_segmentation_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_aug_segmentation_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_aug_segmentation_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_voc_segmentation_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_voc_segmentation_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_voc_segmentation_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_voc_segmentation_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_voc_segmentation_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_voc_segmentation_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_voc_segmentation_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_voc_segmentation_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.supervisely_persons_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">supervisely_persons_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#supervisely_persons_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.supervisely_persons_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.supervisely_persons_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">supervisely_persons_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#supervisely_persons_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.supervisely_persons_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_voc_detection_train">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_voc_detection_train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_voc_detection_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_voc_detection_train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.pascal_voc_detection_val">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">pascal_voc_detection_val</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#pascal_voc_detection_val"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.pascal_voc_detection_val" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.get_data_loader">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">get_data_loader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_cls</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#get_data_loader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.get_data_loader" title="Permalink to this definition"></a></dt>
<dd><p>Class for creating dataloaders for taking defaults from yaml files in src/super_gradients/recipes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config_name</strong> – yaml config filename in recipes (for example coco2017_yolox).</p></li>
<li><p><strong>dataset_cls</strong> – torch dataset uninitialized class.</p></li>
<li><p><strong>train</strong> – <dl class="simple">
<dt>controls whether to take</dt><dd><p>cfg.dataset_params.train_dataloader_params or cfg.dataset_params.valid_dataloader_params as defaults for the dataset constructor</p>
</dd>
<dt>and</dt><dd><p>cfg.dataset_params.train_dataset_params or cfg.dataset_params.valid_dataset_params as defaults for DataLoader contructor.</p>
</dd>
</dl>
</p></li>
<li><p><strong>dataset_params</strong> – dataset params that override the yaml configured defaults, then passed to the dataset_cls.__init__.</p></li>
<li><p><strong>dataloader_params</strong> – DataLoader params that override the yaml configured defaults, then passed to the DataLoader.__init__</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DataLoader</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.dataloaders.get">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.dataloaders.</span></span><span class="sig-name descname"><span class="pre">get</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataloader_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dataset</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">DataLoader</span></span></span><a class="reference internal" href="_modules/super_gradients/training/dataloaders/dataloaders.html#get"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.dataloaders.get" title="Permalink to this definition"></a></dt>
<dd><p>Get DataLoader of the recipe-configured dataset defined by name in ALL_DATALOADERS.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – dataset name in ALL_DATALOADERS.</p></li>
<li><p><strong>dataset_params</strong> – dataset params that override the yaml configured defaults, then passed to the dataset_cls.__init__.</p></li>
<li><p><strong>dataloader_params</strong> – DataLoader params that override the yaml configured defaults, then passed to the DataLoader.__init__</p></li>
<li><p><strong>dataset</strong> – torch.utils.data.Dataset to be used instead of passing “name” (i.e for external dataset objects).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>initialized DataLoader.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="super-gradients-training-exceptions-module">
<h2>super_gradients.training.exceptions module<a class="headerlink" href="#super-gradients-training-exceptions-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.exceptions"></span></div>
<div class="section" id="super-gradients-training-kd-trainer-module">
<h2>super_gradients.training.kd_trainer module<a class="headerlink" href="#super-gradients-training-kd-trainer-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.kd_trainer"></span><dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.kd_trainer.KDTrainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.kd_trainer.</span></span><span class="sig-name descname"><span class="pre">KDTrainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_gpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode" title="super_gradients.common.data_types.enum.multi_gpu_mode.MultiGPUMode"><span class="pre">MultiGPUMode</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">MultiGPUMode.OFF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.kd_trainer.KDTrainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.sg_trainer.Trainer" title="super_gradients.training.sg_trainer.sg_trainer.Trainer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.kd_trainer.KDTrainer.train_from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DictConfig</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer.train_from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.kd_trainer.KDTrainer.train_from_config" title="Permalink to this definition"></a></dt>
<dd><p>Trains according to cfg recipe configuration.</p>
<p>&#64;param cfg: The parsed DictConfig from yaml recipe files
&#64;return: output of kd_trainer.train(…) (i.e results tuple)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.kd_trainer.KDTrainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">KDModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">student</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">SgModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">teacher</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kd_architecture</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kd_module'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kd_arch_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run_teacher_on_eval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/kd_trainer/kd_trainer.html#KDTrainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.kd_trainer.KDTrainer.train" title="Permalink to this definition"></a></dt>
<dd><p>Trains the student network (wrapped in KDModule network).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – KDModule, network to train. When none is given will initialize KDModule according to kd_architecture,
student and teacher (default=None)</p></li>
<li><p><strong>training_params</strong> – dict, Same as in Trainer.train()</p></li>
<li><p><strong>student</strong> – SgModule - the student trainer</p></li>
<li><p><strong>teacher</strong> – torch.nn.Module- the teacher trainer</p></li>
<li><p><strong>kd_architecture</strong> – KDModule architecture to use, currently only ‘kd_module’ is supported (default=’kd_module’).</p></li>
<li><p><strong>kd_arch_params</strong> – architecture params to pas to kd_architecture constructor.</p></li>
<li><p><strong>run_teacher_on_eval</strong> – bool- whether to run self.teacher at eval mode regardless of self.train(mode)</p></li>
<li><p><strong>train_loader</strong> – Dataloader for train set.</p></li>
<li><p><strong>valid_loader</strong> – Dataloader for validation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-super_gradients.training.legacy">
<span id="super-gradients-training-legacy-module"></span><h2>super_gradients.training.legacy module<a class="headerlink" href="#module-super_gradients.training.legacy" title="Permalink to this heading"></a></h2>
</div>
<div class="section" id="module-super_gradients.training.losses">
<span id="super-gradients-training-losses-models-module"></span><h2>super_gradients.training.losses_models module<a class="headerlink" href="#module-super_gradients.training.losses" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">Losses</span></span><a class="reference internal" href="_modules/super_gradients/common/object_names.html#Losses"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.Losses" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Static class holding all the supported loss names</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.CROSS_ENTROPY">
<span class="sig-name descname"><span class="pre">CROSS_ENTROPY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'cross_entropy'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.CROSS_ENTROPY" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.MSE">
<span class="sig-name descname"><span class="pre">MSE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'mse'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.MSE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.R_SQUARED_LOSS">
<span class="sig-name descname"><span class="pre">R_SQUARED_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'r_squared_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.R_SQUARED_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.SHELFNET_OHEM_LOSS">
<span class="sig-name descname"><span class="pre">SHELFNET_OHEM_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'shelfnet_ohem_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.SHELFNET_OHEM_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.SHELFNET_SE_LOSS">
<span class="sig-name descname"><span class="pre">SHELFNET_SE_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'shelfnet_se_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.SHELFNET_SE_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.YOLOX_LOSS">
<span class="sig-name descname"><span class="pre">YOLOX_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'yolox_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.YOLOX_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.YOLOX_FAST_LOSS">
<span class="sig-name descname"><span class="pre">YOLOX_FAST_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'yolox_fast_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.YOLOX_FAST_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.SSD_LOSS">
<span class="sig-name descname"><span class="pre">SSD_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'ssd_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.SSD_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.STDC_LOSS">
<span class="sig-name descname"><span class="pre">STDC_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'stdc_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.STDC_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.BCE_DICE_LOSS">
<span class="sig-name descname"><span class="pre">BCE_DICE_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'bce_dice_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.BCE_DICE_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.KD_LOSS">
<span class="sig-name descname"><span class="pre">KD_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'kd_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.KD_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.Losses.DICE_CE_EDGE_LOSS">
<span class="sig-name descname"><span class="pre">DICE_CE_EDGE_LOSS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'dice_ce_edge_loss'</span></em><a class="headerlink" href="#super_gradients.training.losses.Losses.DICE_CE_EDGE_LOSS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.FocalLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">FocalLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_fcn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BCEWithLogitsLoss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/focal_loss.html#FocalLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.FocalLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<p>Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.FocalLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.FocalLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.FocalLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">true</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/focal_loss.html#FocalLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.FocalLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.LabelSmoothingCrossEntropyLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">LabelSmoothingCrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smooth_eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smooth_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">from_logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/label_smoothing_cross_entropy_loss.html#LabelSmoothingCrossEntropyLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code></p>
<p>CrossEntropyLoss - with ability to recieve distrbution as targets, and optional label smoothing</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smooth_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/label_smoothing_cross_entropy_loss.html#LabelSmoothingCrossEntropyLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.ignore_index">
<span class="sig-name descname"><span class="pre">ignore_index</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.ignore_index" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.label_smoothing">
<span class="sig-name descname"><span class="pre">label_smoothing</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#super_gradients.training.losses.LabelSmoothingCrossEntropyLoss.label_smoothing" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetOHEMLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">ShelfNetOHEMLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.7</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mining_percent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_lb</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">255</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/shelfnet_ohem_loss.html#ShelfNetOHEMLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.ShelfNetOHEMLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">OhemCELoss</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetOHEMLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions_list</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/shelfnet_ohem_loss.html#ShelfNetOHEMLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.ShelfNetOHEMLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetOHEMLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.ShelfNetOHEMLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetOHEMLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.ShelfNetOHEMLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetSemanticEncodingLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">ShelfNetSemanticEncodingLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">se_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nclass</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">21</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/shelfnet_semantic_encoding_loss.html#ShelfNetSemanticEncodingLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code></p>
<p>2D Cross Entropy Loss with Auxilary Loss</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetSemanticEncodingLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logits</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/shelfnet_semantic_encoding_loss.html#ShelfNetSemanticEncodingLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetSemanticEncodingLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetSemanticEncodingLoss.ignore_index">
<span class="sig-name descname"><span class="pre">ignore_index</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.ignore_index" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.ShelfNetSemanticEncodingLoss.label_smoothing">
<span class="sig-name descname"><span class="pre">label_smoothing</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#super_gradients.training.losses.ShelfNetSemanticEncodingLoss.label_smoothing" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">YoloXDetectionLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_l1</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center_sampling_radius</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'iou'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<p>Calculate YOLOX loss:
L = L_objectivness + L_iou + L_classification + 1[use_l1]*L_l1</p>
<dl>
<dt>where:</dt><dd><ul class="simple">
<li><p>L_iou, L_classification and L_l1 are calculated only between cells and targets that suit them;</p></li>
<li><p>L_objectivness is calculated for all cells.</p></li>
</ul>
<dl class="simple">
<dt>L_classification:</dt><dd><p>for cells that have suitable ground truths in their grid locations add BCEs
to force a prediction of IoU with a GT in a multi-label way
Coef: 1.</p>
</dd>
<dt>L_iou:</dt><dd><p>for cells that have suitable ground truths in their grid locations
add (1 - IoU^2), IoU between a predicted box and each GT box, force maximum IoU
Coef: 5.</p>
</dd>
<dt>L_l1:</dt><dd><p>for cells that have suitable ground truths in their grid locations
l1 distance between the logits and GTs in “logits” format (the inverse of “logits to predictions” ops)
Coef: 1[use_l1]</p>
</dd>
<dt>L_objectness:</dt><dd><p>for each cell add BCE with a label of 1 if there is GT assigned to the cell
Coef: 1</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.strides">
<span class="sig-name descname"><span class="pre">strides</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.strides" title="Permalink to this definition"></a></dt>
<dd><p>list: List of Yolo levels output grid sizes (i.e [8, 16, 32]).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.num_classes">
<span class="sig-name descname"><span class="pre">num_classes</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.num_classes" title="Permalink to this definition"></a></dt>
<dd><p>int: Number of classes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.use_l1">
<span class="sig-name descname"><span class="pre">use_l1</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.use_l1" title="Permalink to this definition"></a></dt>
<dd><p>bool: Controls the L_l1 Coef as discussed above (default=False).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.center_sampling_radius">
<span class="sig-name descname"><span class="pre">center_sampling_radius</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.center_sampling_radius" title="Permalink to this definition"></a></dt>
<dd><p>float: Sampling radius used for center sampling when creating the fg mask (default=2.5).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.iou_type">
<span class="sig-name descname"><span class="pre">iou_type</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.iou_type" title="Permalink to this definition"></a></dt>
<dd><p>str: Iou loss type, one of [“iou”,”giou”] (deafult=”iou”).</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_output</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_output</strong> – <p>Union[list, Tuple[torch.Tensor, List]]:
When list-</p>
<blockquote>
<div><p>output from all Yolo levels, each of shape [Batch x 1 x GridSizeY x GridSizeX x (4 + 1 + Num_classes)]</p>
</div></blockquote>
<p>And when tuple- the second item is the described list (first item is discarded)</p>
</p></li>
<li><p><strong>targets</strong> – torch.Tensor: Num_targets x (4 + 2)], values on dim 1 are: image id in a batch, class, box x y w h</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>loss, all losses separately in a detached tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.prepare_predictions">
<span class="sig-name descname"><span class="pre">prepare_predictions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.prepare_predictions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.prepare_predictions" title="Permalink to this definition"></a></dt>
<dd><p>Convert raw outputs of the network into a format that merges outputs from all levels
:param predictions:     output from all Yolo levels, each of shape</p>
<blockquote>
<div><p>[Batch x 1 x GridSizeY x GridSizeX x (4 + 1 + Num_classes)]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><p>5 tensors representing predictions:
* x_shifts: shape [1 x * num_cells x 1],</p>
<blockquote>
<div><p>where num_cells = grid1X * grid1Y + grid2X * grid2Y + grid3X * grid3Y,
x coordinate on the grid cell the prediction is coming from</p>
</div></blockquote>
<ul class="simple">
<li><p>y_shifts: shape [1 x  num_cells x 1],
y coordinate on the grid cell the prediction is coming from</p></li>
<li><p>expanded_strides: shape [1 x num_cells x 1],
stride of the output grid the prediction is coming from</p></li>
<li><p>transformed_outputs: shape [batch_size x num_cells x (num_classes + 5)],
predictions with boxes in real coordinates and logprobabilities</p></li>
<li><p>raw_outputs: shape [batch_size x num_cells x (num_classes + 5)],
raw predictions with boxes and confidences as logits</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.get_l1_target">
<span class="sig-name descname"><span class="pre">get_l1_target</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l1_target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-08</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.get_l1_target"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.get_l1_target" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>l1_target</strong> – tensor of zeros of shape [Num_cell_gt_pairs x 4]</p></li>
<li><p><strong>gt</strong> – targets in coordinates [Num_cell_gt_pairs x (4 + 1 + num_classes)]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>targets in the format corresponding to logits</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.get_assignments">
<span class="sig-name descname"><span class="pre">get_assignments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_num_anchors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_bboxes_per_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bboxes_preds_per_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expanded_strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cls_preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj_preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'gpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ious_loss_cost_coeff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outside_boxes_and_center_cost_coeff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.get_assignments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.get_assignments" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Match cells to ground truth:</dt><dd><ul class="simple">
<li><p>at most 1 GT per cell</p></li>
<li><p>dynamic number of cells per GT</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>outside_boxes_and_center_cost_coeff</strong> – float: Cost coefficiant of cells the radius and bbox of gts in dynamic
matching (default=100000).</p></li>
<li><p><strong>ious_loss_cost_coeff</strong> – float: Cost coefficiant for iou loss in dynamic matching (default=3).</p></li>
<li><p><strong>image_idx</strong> – int: Image index in batch.</p></li>
<li><p><strong>num_gt</strong> – int: Number of ground trunth targets in the image.</p></li>
<li><p><strong>total_num_anchors</strong> – int: Total number of possible bboxes = sum of all grid cells.</p></li>
<li><p><strong>gt_bboxes_per_image</strong> – torch.Tensor: Tensor of gt bboxes for  the image, shape: (num_gt, 4).</p></li>
<li><p><strong>gt_classes</strong> – torch.Tesnor: Tensor of the classes in the image, shape: (num_preds,4).</p></li>
<li><p><strong>bboxes_preds_per_image</strong> – Tensor of the classes in the image, shape: (num_preds).</p></li>
<li><p><strong>expanded_strides</strong> – torch.Tensor: Stride of the output grid the prediction is coming from,
shape (1 x num_cells x 1).</p></li>
<li><p><strong>x_shifts</strong> – torch.Tensor: X’s in cell coordinates, shape (1,num_cells,1).</p></li>
<li><p><strong>y_shifts</strong> – torch.Tensor: Y’s in cell coordinates, shape (1,num_cells,1).</p></li>
<li><p><strong>cls_preds</strong> – torch.Tensor: Class predictions in all cells, shape (batch_size, num_cells).</p></li>
<li><p><strong>obj_preds</strong> – torch.Tensor: Objectness predictions in all cells, shape (batch_size, num_cells).</p></li>
<li><p><strong>mode</strong> – str: One of [“gpu”,”cpu”], Controls the device the assignment operation should be taken place on (deafult=”gpu”)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.get_in_boxes_info">
<span class="sig-name descname"><span class="pre">get_in_boxes_info</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gt_bboxes_per_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expanded_strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_shifts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_num_anchors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gt</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.get_in_boxes_info"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.get_in_boxes_info" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>Create a mask for all cells, mask in only foreground: cells that have a center located:</dt><dd><ul class="simple">
<li><p>withing a GT box;</p></li>
</ul>
<p>OR
* within a fixed radius around a GT box (center sampling);</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_gt</strong> – int: Number of ground trunth targets in the image.</p></li>
<li><p><strong>total_num_anchors</strong> – int: Sum of all grid cells.</p></li>
<li><p><strong>gt_bboxes_per_image</strong> – torch.Tensor: Tensor of gt bboxes for  the image, shape: (num_gt, 4).</p></li>
<li><p><strong>expanded_strides</strong> – torch.Tensor: Stride of the output grid the prediction is coming from,
shape (1 x num_cells x 1).</p></li>
<li><p><strong>x_shifts</strong> – torch.Tensor: X’s in cell coordinates, shape (1,num_cells,1).</p></li>
<li><p><strong>y_shifts</strong> – torch.Tensor: Y’s in cell coordinates, shape (1,num_cells,1).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>:return is_in_boxes_anchor, is_in_boxes_and_center</dt><dd><dl class="simple">
<dt>where:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>is_in_boxes_anchor masks the cells that their cell center is  inside a gt bbox and within</dt><dd><p>self.center_sampling_radius cells away, without reduction (i.e shape=(num_gts, num_fgs))</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>is_in_boxes_and_center masks the cells that their center is either inside a gt bbox or within</dt><dd><p>self.center_sampling_radius cells away, shape (num_fgs)</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.dynamic_k_matching">
<span class="sig-name descname"><span class="pre">dynamic_k_matching</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cost</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pair_wise_ious</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gt_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fg_mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXDetectionLoss.dynamic_k_matching"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.dynamic_k_matching" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cost</strong> – pairwise cost, [num_FGs x num_GTs]</p></li>
<li><p><strong>pair_wise_ious</strong> – pairwise IoUs, [num_FGs x num_GTs]</p></li>
<li><p><strong>gt_classes</strong> – class of each GT</p></li>
<li><p><strong>num_gt</strong> – number of GTs</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>:return num_fg, (number of foregrounds)</dt><dd><p>gt_matched_classes, (the classes that have been matched with fgs)
pred_ious_this_matching
matched_gt_inds</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXDetectionLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.YoloXDetectionLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXFastDetectionLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">YoloXFastDetectionLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">strides</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_l1</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">center_sampling_radius</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'iou'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_ks_bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sync_num_fgs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj_loss_fix</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/yolox_loss.html#YoloXFastDetectionLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.YoloXFastDetectionLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.losses.YoloXDetectionLoss" title="super_gradients.training.losses.yolox_loss.YoloXDetectionLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">YoloXDetectionLoss</span></code></a></p>
<p>A completely new implementation of YOLOX loss.
This is NOT an equivalent implementation to the regular yolox loss.</p>
<ul class="simple">
<li><dl class="simple">
<dt>Completely avoids using loops compared to the nested loops in the original implementation.</dt><dd><p>As a result runs much faster (speedup depends on the type of GPUs, their count, the batch size, etc.).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Tensors format is very different the original implementation.</dt><dd><p>Tensors contain image ids, ground truth ids and anchor ids as values to support variable length data.</p>
</dd>
</dl>
</li>
<li><p>There are differences in terms of the algorithm itself:</p></li>
</ul>
<ol class="arabic simple">
<li><dl class="simple">
<dt>When computing a dynamic k for a ground truth,</dt><dd><p>in the original implementation they consider the sum of top 10 predictions sorted by ious among the initial
foregrounds of any ground truth in the image,
while in our implementation we consider only the initial foreground of that particular ground truth.
To compensate for that difference we introduce the dynamic_ks_bias hyperparamter which makes the dynamic ks larger.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>When computing the k matched detections for a ground truth,</dt><dd><p>in the original implementation they consider the initial foregrounds of any ground truth in the image as candidates,
while in our implementation we consider only the initial foreground of that particular ground truth as candidates.
We believe that this difference is minor.</p>
</dd>
</dl>
</li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dynamic_ks_bias</strong> – hyperparameter to compensate for the discrepancies between the regular loss and this loss.</p></li>
<li><p><strong>sync_num_fgs</strong> – sync num of fgs.
Can be used for DDP training.</p></li>
<li><p><strong>obj_loss_fix</strong> – devide by total of num anchors instead num of matching fgs.
Can be used for objectness loss.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXFastDetectionLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.YoloXFastDetectionLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.YoloXFastDetectionLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.losses.YoloXFastDetectionLoss.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.RSquaredLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">RSquaredLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size_average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduce</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/r_squared_loss.html#RSquaredLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.RSquaredLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.RSquaredLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/r_squared_loss.html#RSquaredLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.RSquaredLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Computes the R-squared for the output and target values
:param output: Tensor / Numpy / List</p>
<blockquote>
<div><p>The prediction</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> – Tensor / Numpy / List
The corresponding lables</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.RSquaredLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.RSquaredLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.SSDLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">SSDLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dboxes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DefaultBoxes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_thresh</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_pos_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/ssd_loss.html#SSDLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.SSDLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<blockquote>
<div><p>Implements the loss as the sum of the followings:
1. Confidence Loss: All labels, with hard negative mining
2. Localization Loss: Only on positive labels</p>
</div></blockquote>
<dl class="simple">
<dt>L = (2 - alpha) * L_l1 + alpha * L_cls, where</dt><dd><ul class="simple">
<li><p>L_cls is HardMiningCrossEntropyLoss</p></li>
<li><p>L_l1 = [SmoothL1Loss for all positives]</p></li>
</ul>
</dd>
</dl>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.SSDLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.SSDLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.SSDLoss.match_dboxes">
<span class="sig-name descname"><span class="pre">match_dboxes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/ssd_loss.html#SSDLoss.match_dboxes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.SSDLoss.match_dboxes" title="Permalink to this definition"></a></dt>
<dd><p>creates tensors with target boxes and labels for each dboxes, so with the same len as dboxes.</p>
<ul class="simple">
<li><p>Each GT is assigned with a grid cell with the highest IoU, this creates a pair for each GT and some cells;</p></li>
<li><p>The rest of grid cells are assigned to a GT with the highest IoU, assuming it’s &gt; self.iou_thresh;
If this condition is not met the grid cell is marked as background</p></li>
</ul>
<p>GT-wise: one to many
Grid-cell-wise: one to one</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>targets</strong> – a tensor containing the boxes for a single image;
shape [num_boxes, 6] (image_id, label, x, y, w, h)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>two tensors
boxes - shape of dboxes [4, num_dboxes] (x,y,w,h)
labels - sahpe [num_dboxes]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.SSDLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/ssd_loss.html#SSDLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.SSDLoss.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Compute the loss</dt><dd><p>:param predictions - predictions tensor coming from the network,
tuple with shapes ([Batch Size, 4, num_dboxes], [Batch Size, num_classes + 1, num_dboxes])
were predictions have logprobs for background and other classes
:param targets - targets for the batch. [num targets, 6] (index in batch, label, x,y,w,h)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.SSDLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.SSDLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.BCEDiceLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">BCEDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">loss_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.5,</span> <span class="pre">0.5]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/bce_dice_loss.html#BCEDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.BCEDiceLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Binary Cross Entropy + Dice Loss</p>
<p>Weighted average of BCE and Dice loss</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.BCEDiceLoss.loss_weights">
<span class="sig-name descname"><span class="pre">loss_weights</span></span><a class="headerlink" href="#super_gradients.training.losses.BCEDiceLoss.loss_weights" title="Permalink to this definition"></a></dt>
<dd><p>list of size 2 s.t loss_weights[0], loss_weights[1] are the weights for BCE, Dice</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">respectively.</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.BCEDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/super_gradients/training/losses/bce_dice_loss.html#BCEDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.BCEDiceLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>&#64;param input: Network’s raw output shaped (N,1,H,W)
&#64;param target: Ground truth shaped (N,H,W)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.BCEDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.losses.BCEDiceLoss.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.KDLogitsLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">KDLogitsLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_loss_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_Loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distillation_loss_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">_Loss</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">KDklDivLoss()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distillation_loss_coeff</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/kd_losses.html#KDLogitsLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.KDLogitsLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<p>Knowledge distillation loss, wraps the task loss and distillation loss</p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.KDLogitsLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.KDLogitsLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.KDLogitsLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kd_module_output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/kd_losses.html#KDLogitsLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.KDLogitsLoss.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.KDLogitsLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.KDLogitsLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.losses.DiceCEEdgeLoss">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.losses.</span></span><span class="sig-name descname"><span class="pre">DiceCEEdgeLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_aux_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_detail_heads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(1,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dice_ce_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(1,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">edge_kernel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ce_edge_weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">(0.5,</span> <span class="pre">0.5)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/dice_ce_edge_loss.html#DiceCEEdgeLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.DiceCEEdgeLoss" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">_Loss</span></code></p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.losses.DiceCEEdgeLoss.component_names">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">component_names</span></span><a class="headerlink" href="#super_gradients.training.losses.DiceCEEdgeLoss.component_names" title="Permalink to this definition"></a></dt>
<dd><p>Component names for logging during training.
These correspond to 2nd item in the tuple returned in self.forward(…).
See super_gradients.Trainer.train() docs for more info.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.losses.DiceCEEdgeLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/losses/dice_ce_edge_loss.html#DiceCEEdgeLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.losses.DiceCEEdgeLoss.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>preds</strong> – Model output predictions, must be in the followed format:
[Main-feats, Aux-feats[0], …, Aux-feats[num_auxs-1], Detail-feats[0], …, Detail-feats[num_details-1]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.losses.DiceCEEdgeLoss.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.losses.DiceCEEdgeLoss.reduction" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-super_gradients.training.metrics">
<span id="super-gradients-training-metrics-module"></span><h2>super_gradients.training.metrics module<a class="headerlink" href="#module-super_gradients.training.metrics" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">Metrics</span></span><a class="reference internal" href="_modules/super_gradients/common/object_names.html#Metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Metrics" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Static class holding all the supported metric names</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.ACCURACY">
<span class="sig-name descname"><span class="pre">ACCURACY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Accuracy'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.ACCURACY" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.TOP5">
<span class="sig-name descname"><span class="pre">TOP5</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Top5'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.TOP5" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.DETECTION_METRICS">
<span class="sig-name descname"><span class="pre">DETECTION_METRICS</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMetrics'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.DETECTION_METRICS_050_095">
<span class="sig-name descname"><span class="pre">DETECTION_METRICS_050_095</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMetrics_050_095'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_050_095" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.DETECTION_METRICS_050">
<span class="sig-name descname"><span class="pre">DETECTION_METRICS_050</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMetrics_050'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_050" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.DETECTION_METRICS_075">
<span class="sig-name descname"><span class="pre">DETECTION_METRICS_075</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMetrics_075'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.DETECTION_METRICS_075" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.IOU">
<span class="sig-name descname"><span class="pre">IOU</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'IoU'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.IOU" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.BINARY_IOU">
<span class="sig-name descname"><span class="pre">BINARY_IOU</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'BinaryIOU'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.BINARY_IOU" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.DICE">
<span class="sig-name descname"><span class="pre">DICE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Dice'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.DICE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.BINARY_DICE">
<span class="sig-name descname"><span class="pre">BINARY_DICE</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'BinaryDice'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.BINARY_DICE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Metrics.PIXEL_ACCURACY">
<span class="sig-name descname"><span class="pre">PIXEL_ACCURACY</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'PixelAccuracy'</span></em><a class="headerlink" href="#super_gradients.training.metrics.Metrics.PIXEL_ACCURACY" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.metrics.accuracy">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">topk</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(1,)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.accuracy" title="Permalink to this definition"></a></dt>
<dd><p>Computes the precision&#64;k for the specified values of k
:param output: Tensor / Numpy / List</p>
<blockquote>
<div><p>The prediction</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> – Tensor / Numpy / List
The corresponding lables</p></li>
<li><p><strong>topk</strong> – tuple
The type of accuracy to calculate, e.g. topk=(1,5) returns accuracy for top-1 and top-5</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Accuracy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">Accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#Accuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Accuracy" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Accuracy</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Accuracy.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#Accuracy.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Accuracy.update" title="Permalink to this definition"></a></dt>
<dd><p>Update state with predictions and targets. See
<span class="xref std std-ref">pages/classification:input types</span> for more information on input
types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preds</strong> – Predictions from model (logits, probabilities, or labels)</p></li>
<li><p><strong>target</strong> – Ground truth labels</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Accuracy.correct">
<span class="sig-name descname"><span class="pre">correct</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.Accuracy.correct" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Accuracy.total">
<span class="sig-name descname"><span class="pre">total</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.Accuracy.total" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Top5">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">Top5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#Top5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Top5" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Top5.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#Top5.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Top5.update" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to update the state variables of your metric class.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Top5.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#Top5.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Top5.compute" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to compute the final metric value from state variables synchronized across the
distributed backend.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.ToyTestClassificationMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">ToyTestClassificationMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#ToyTestClassificationMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.ToyTestClassificationMetric" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></p>
<p>Dummy classification Mettric object returning 0 always (for testing).</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.ToyTestClassificationMetric.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#ToyTestClassificationMetric.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.ToyTestClassificationMetric.update" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to update the state variables of your metric class.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.ToyTestClassificationMetric.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/classification_metrics.html#ToyTestClassificationMetric.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.ToyTestClassificationMetric.compute" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to compute the final metric value from state variables synchronized across the
distributed backend.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">DetectionMetrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_prediction_callback</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DetectionPostPredictionCallback</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">IouThreshold</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">IouThreshold.MAP_05_TO_095</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accumulate_on_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></p>
<p>Metric class for computing F1, Precision, Recall and Mean Average Precision.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.num_cls">
<span class="sig-name descname"><span class="pre">num_cls</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.num_cls" title="Permalink to this definition"></a></dt>
<dd><p>Number of classes.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.post_prediction_callback">
<span class="sig-name descname"><span class="pre">post_prediction_callback</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.post_prediction_callback" title="Permalink to this definition"></a></dt>
<dd><p>DetectionPostPredictionCallback to be applied on net’s output prior
to the metric computation (NMS).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.normalize_targets">
<span class="sig-name descname"><span class="pre">normalize_targets</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.normalize_targets" title="Permalink to this definition"></a></dt>
<dd><p>Whether to normalize bbox coordinates by image size (default=False).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.iou_thresholds">
<span class="sig-name descname"><span class="pre">iou_thresholds</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.iou_thresholds" title="Permalink to this definition"></a></dt>
<dd><p>IoU threshold to compute the mAP (default=torch.linspace(0.5, 0.95, 10)).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.recall_thresholds">
<span class="sig-name descname"><span class="pre">recall_thresholds</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.recall_thresholds" title="Permalink to this definition"></a></dt>
<dd><p>Recall threshold to compute the mAP (default=torch.linspace(0, 1, 101)).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.score_threshold">
<span class="sig-name descname"><span class="pre">score_threshold</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.score_threshold" title="Permalink to this definition"></a></dt>
<dd><p>Score threshold to compute Recall, Precision and F1 (default=0.1)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.top_k_predictions">
<span class="sig-name descname"><span class="pre">top_k_predictions</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.top_k_predictions" title="Permalink to this definition"></a></dt>
<dd><p>Number of predictions per class used to compute metrics, ordered by confidence score
(default=100)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.dist_sync_on_step">
<span class="sig-name descname"><span class="pre">dist_sync_on_step</span></span><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.dist_sync_on_step" title="Permalink to this definition"></a></dt>
<dd><p>Synchronize metric state across processes at each <code class="docutils literal notranslate"><span class="pre">forward()</span></code>
before returning the value at the step. (default=False)</p>
<blockquote>
<div><dl class="simple">
<dt>accumulate_on_cpu:     Run on CPU regardless of device used in other parts.</dt><dd><p>This is to avoid “CUDA out of memory” that might happen on GPU (default False)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crowd_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.update" title="Permalink to this definition"></a></dt>
<dd><p>Apply NMS and match all the predictions and targets of a given batch, and update the metric state accordingly.</p>
<dl class="simple">
<dt>:param preds<span class="classifier">Raw output of the model, the format might change from one model to another, but has to fit</span></dt><dd><p>the input format of the post_prediction_callback</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> – Targets for all images of shape (total_num_targets, 6)
format:  (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
<li><p><strong>device</strong> – Device to run on</p></li>
<li><p><strong>inputs</strong> – Input image tensor of shape (batch_size, n_img, height, width)</p></li>
<li><p><strong>crowd_targets</strong> – Crowd targets for all images of shape (total_num_targets, 6)
format:  (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics.compute" title="Permalink to this definition"></a></dt>
<dd><p>Compute the metrics for all the accumulated results.
:return: Metrics of interest</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.PreprocessSegmentationMetricsArgs">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">PreprocessSegmentationMetricsArgs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">apply_arg_max</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">apply_sigmoid</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#PreprocessSegmentationMetricsArgs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.PreprocessSegmentationMetricsArgs" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractMetricsArgsPrepFn</span></code></p>
<p>Default segmentation inputs preprocess function before updating segmentation metrics, handles multiple inputs and
apply normalizations.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.PixelAccuracy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">PixelAccuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_args_prep_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractMetricsArgsPrepFn</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#PixelAccuracy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.PixelAccuracy" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Metric</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.PixelAccuracy.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#PixelAccuracy.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.PixelAccuracy.update" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to update the state variables of your metric class.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.PixelAccuracy.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#PixelAccuracy.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.PixelAccuracy.compute" title="Permalink to this definition"></a></dt>
<dd><p>Override this method to compute the final metric value from state variables synchronized across the
distributed backend.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.IoU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">IoU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'elementwise_mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_args_prep_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractMetricsArgsPrepFn</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#IoU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.IoU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">JaccardIndex</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.IoU.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#IoU.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.IoU.update" title="Permalink to this definition"></a></dt>
<dd><p>Update state with predictions and targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preds</strong> – Predictions from model</p></li>
<li><p><strong>target</strong> – Ground truth values</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.IoU.confmat">
<span class="sig-name descname"><span class="pre">confmat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.IoU.confmat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Dice">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">Dice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'elementwise_mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_args_prep_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractMetricsArgsPrepFn</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#Dice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Dice" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">JaccardIndex</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Dice.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#Dice.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Dice.update" title="Permalink to this definition"></a></dt>
<dd><p>Update state with predictions and targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preds</strong> – Predictions from model</p></li>
<li><p><strong>target</strong> – Ground truth values</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Dice.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#Dice.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.Dice.compute" title="Permalink to this definition"></a></dt>
<dd><p>Computes Dice coefficient</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.Dice.confmat">
<span class="sig-name descname"><span class="pre">confmat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.Dice.confmat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryIOU">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">BinaryIOU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_args_prep_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractMetricsArgsPrepFn</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#BinaryIOU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.BinaryIOU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.metrics.IoU" title="super_gradients.training.metrics.segmentation_metrics.IoU"><code class="xref py py-class docutils literal notranslate"><span class="pre">IoU</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryIOU.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#BinaryIOU.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.BinaryIOU.compute" title="Permalink to this definition"></a></dt>
<dd><p>Computes intersection over union (IoU)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryIOU.confmat">
<span class="sig-name descname"><span class="pre">confmat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.BinaryIOU.confmat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryIOU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.metrics.BinaryIOU.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryDice">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">BinaryDice</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_args_prep_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">AbstractMetricsArgsPrepFn</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#BinaryDice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.BinaryDice" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.metrics.Dice" title="super_gradients.training.metrics.segmentation_metrics.Dice"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dice</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryDice.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/segmentation_metrics.html#BinaryDice.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.BinaryDice.compute" title="Permalink to this definition"></a></dt>
<dd><p>Computes Dice coefficient</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryDice.confmat">
<span class="sig-name descname"><span class="pre">confmat</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Tensor</span></em><a class="headerlink" href="#super_gradients.training.metrics.BinaryDice.confmat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.metrics.BinaryDice.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.metrics.BinaryDice.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics_050">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">DetectionMetrics_050</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_prediction_callback</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DetectionPostPredictionCallback</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accumulate_on_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics_050"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics_050" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics" title="super_gradients.training.metrics.detection_metrics.DetectionMetrics"><code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionMetrics</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics_075">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">DetectionMetrics_075</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_prediction_callback</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DetectionPostPredictionCallback</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accumulate_on_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics_075"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics_075" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics" title="super_gradients.training.metrics.detection_metrics.DetectionMetrics"><code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionMetrics</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.metrics.DetectionMetrics_050_095">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.metrics.</span></span><span class="sig-name descname"><span class="pre">DetectionMetrics_050_095</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_prediction_callback</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DetectionPostPredictionCallback</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_thres</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist_sync_on_step</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accumulate_on_cpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/metrics/detection_metrics.html#DetectionMetrics_050_095"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.metrics.DetectionMetrics_050_095" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.metrics.DetectionMetrics" title="super_gradients.training.metrics.detection_metrics.DetectionMetrics"><code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionMetrics</span></code></a></p>
</dd></dl>

</div>
<div class="section" id="module-super_gradients.training.models">
<span id="super-gradients-training-models-module"></span><h2>super_gradients.training.models module<a class="headerlink" href="#module-super_gradients.training.models" title="Permalink to this heading"></a></h2>
</div>
<div class="section" id="module-super_gradients.training.sg_trainer">
<span id="super-gradients-training-sg-model-module"></span><h2>super_gradients.training.sg_model module<a class="headerlink" href="#module-super_gradients.training.sg_trainer" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.sg_trainer.</span></span><span class="sig-name descname"><span class="pre">Trainer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_gpu</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#super_gradients.training.sg_trainer.MultiGPUMode" title="super_gradients.common.data_types.enum.multi_gpu_mode.MultiGPUMode"><span class="pre">MultiGPUMode</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">MultiGPUMode.OFF</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>SuperGradient Model - Base Class for Sg Models</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.train" title="Permalink to this definition"></a></dt>
<dd><p>the main function used for the training, h.p. updating, logging etc.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.predict" title="Permalink to this definition"></a></dt>
<dd><p>returns the predictions and label of the current inputs</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">test(epoch</span> <span class="pre">:</span> <span class="pre">int,</span> <span class="pre">idx</span> <span class="pre">:</span> <span class="pre">int,</span> <span class="pre">save</span> <span class="pre">:</span> <span class="pre">bool):</span></span></dt>
<dd><p>returns the test loss, accuracy and runtime</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.train_from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">train_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">DictConfig</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train_from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.train_from_config" title="Permalink to this definition"></a></dt>
<dd><p>Trains according to cfg recipe configuration.</p>
<p>&#64;param cfg: The parsed DictConfig from yaml recipe files or a dictionary
&#64;return: the model and the output of trainer.train(…) (i.e results tuple)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.resume_experiment">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">resume_experiment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.resume_experiment"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.resume_experiment" title="Permalink to this definition"></a></dt>
<dd><p>Resume a training that was run using our recipes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> – Name of the experiment to resume</p></li>
<li><p><strong>ckpt_root_dir</strong> – Directory including the checkpoints</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.evaluate_from_recipe">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate_from_recipe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DictConfig</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate_from_recipe"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.evaluate_from_recipe" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate according to a cfg recipe configuration.</p>
<dl class="simple">
<dt>Note:   This script does NOT run training, only validation.</dt><dd><p>Please make sure that the config refers to a PRETRAINED MODEL either from one of your checkpoint or from pretrained weights from model zoo.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>cfg</strong> – The parsed DictConfig from yaml recipe files or a dictionary</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.evaluate_checkpoint">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">evaluate_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'ckpt_latest.pth'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_root_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.evaluate_checkpoint" title="Permalink to this definition"></a></dt>
<dd><p>Evaluate a checkpoint resulting from one of your previous experiment, using the same parameters (dataset, valid_metrics,…)
as used during the training of the experiment</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The parameters will be unchanged even if the recipe used for that experiment was changed since then.
This is to ensure that validation of the experiment will remain exactly the same as during training.</p>
</div>
<dl class="simple">
<dt>Example, evaluate the checkpoint “average_model.pth” from experiment “my_experiment_name”:</dt><dd><p>&gt;&gt; evaluate_checkpoint(experiment_name=”my_experiment_name”, ckpt_name=”average_model.pth”)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>experiment_name</strong> – Name of the experiment to validate</p></li>
<li><p><strong>ckpt_name</strong> – Name of the checkpoint to test (“ckpt_latest.pth”, “average_model.pth” or “ckpt_best.pth” for instance)</p></li>
<li><p><strong>ckpt_root_dir</strong> – Directory including the checkpoints</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_configs_to_log</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id3" title="Permalink to this definition"></a></dt>
<dd><p>train - Trains the Model</p>
<dl>
<dt>IMPORTANT NOTE: Additional batch parameters can be added as a third item (optional) if a tuple is returned by</dt><dd><p>the data loaders, as dictionary. The phase context will hold the additional items, under an attribute with
the same name as the key in this dictionary. Then such items can be accessed through phase callbacks.</p>
<blockquote>
<div><dl class="field-list">
<dt class="field-odd">param additional_configs_to_log</dt>
<dd class="field-odd"><p>Dict, dictionary containing configs that will be added to the training’s
sg_logger. Format should be {“Config_title_1”: {…}, “Config_title_2”:{..}}.</p>
</dd>
<dt class="field-even">param model</dt>
<dd class="field-even"><p>torch.nn.Module, model to train.</p>
</dd>
<dt class="field-odd">param train_loader</dt>
<dd class="field-odd"><p>Dataloader for train set.</p>
</dd>
<dt class="field-even">param valid_loader</dt>
<dd class="field-even"><p>Dataloader for validation.</p>
</dd>
<dt class="field-odd">param training_params</dt>
<dd class="field-odd"><ul>
<li><p><cite>resume</cite> : bool (default=False)</p>
<blockquote>
<div><dl class="simple">
<dt>Whether to continue training from ckpt with the same experiment name</dt><dd><p>(i.e resume from CKPT_ROOT_DIR/EXPERIMENT_NAME/CKPT_NAME)</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ckpt_name</cite> : str (default=ckpt_latest.pth)</p>
<blockquote>
<div><dl class="simple">
<dt>The checkpoint (.pth file) filename in CKPT_ROOT_DIR/EXPERIMENT_NAME/ to use when resume=True and</dt><dd><p>resume_path=None</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>resume_path</cite>: str (default=None)</p>
<blockquote>
<div><p>Explicit checkpoint path (.pth file) to use to resume training.</p>
</div></blockquote>
</li>
<li><p><cite>max_epochs</cite> : int</p>
<blockquote>
<div><p>Number of epochs to run training.</p>
</div></blockquote>
</li>
<li><p><cite>lr_updates</cite> : list(int)</p>
<blockquote>
<div><p>List of fixed epoch numbers to perform learning rate updates when <cite>lr_mode=’step’</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_decay_factor</cite> : float</p>
<blockquote>
<div><p>Decay factor to apply to the learning rate at each update when <cite>lr_mode=’step’</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_mode</cite> : str</p>
<blockquote>
<div><p>Learning rate scheduling policy, one of [‘step’,’poly’,’cosine’,’function’]. ‘step’ refers to
constant updates at epoch numbers passed through <cite>lr_updates</cite>. ‘cosine’ refers to Cosine Anealing
policy as mentioned in <a class="reference external" href="https://arxiv.org/abs/1608.03983">https://arxiv.org/abs/1608.03983</a>. ‘poly’ refers to polynomial decrease i.e
in each epoch iteration <cite>self.lr = self.initial_lr * pow((1.0 - (current_iter / max_iter)),
0.9)</cite> ‘function’ refers to user defined learning rate scheduling function, that is passed through
<cite>lr_schedule_function</cite>.</p>
</div></blockquote>
</li>
<li><p><cite>lr_schedule_function</cite> : Union[callable,None]</p>
<blockquote>
<div><p>Learning rate scheduling function to be used when <cite>lr_mode</cite> is ‘function’.</p>
</div></blockquote>
</li>
<li><p><cite>lr_warmup_epochs</cite> : int (default=0)</p>
<blockquote>
<div><p>Number of epochs for learning rate warm up - see <a class="reference external" href="https://arxiv.org/pdf/1706.02677.pdf">https://arxiv.org/pdf/1706.02677.pdf</a> (Section 2.2).</p>
</div></blockquote>
</li>
<li><dl class="simple">
<dt><cite>cosine_final_lr_ratio</cite><span class="classifier">float (default=0.01)</span></dt><dd><dl class="simple">
<dt>Final learning rate ratio (only relevant when <a href="#id4"><span class="problematic" id="id5">`</span></a>lr_mode`=’cosine’). The cosine starts from initial_lr and reaches</dt><dd><p>initial_lr * cosine_final_lr_ratio in last epoch</p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><p><cite>inital_lr</cite> : float</p>
<blockquote>
<div><p>Initial learning rate.</p>
</div></blockquote>
</li>
<li><p><cite>loss</cite> : Union[nn.module, str]</p>
<blockquote>
<div><blockquote>
<div><p>Loss function for training.
One of SuperGradient’s built in options:</p>
<blockquote>
<div><p>“cross_entropy”: LabelSmoothingCrossEntropyLoss,
“mse”: MSELoss,
“r_squared_loss”: RSquaredLoss,
“detection_loss”: YoLoV3DetectionLoss,
“shelfnet_ohem_loss”: ShelfNetOHEMLoss,
“shelfnet_se_loss”: ShelfNetSemanticEncodingLoss,
“ssd_loss”: SSDLoss,</p>
</div></blockquote>
<p>or user defined nn.module loss function.</p>
<p>IMPORTANT: forward(…) should return a (loss, loss_items) tuple where loss is the tensor used
for backprop (i.e what your original loss function returns), and loss_items should be a tensor of
shape (n_items), of values computed during the forward pass which we desire to log over the
entire epoch. For example- the loss itself should always be logged. Another example is a scenario
where the computed loss is the sum of a few components we would like to log- these entries in
loss_items).</p>
<p>IMPORTANT:When dealing with external loss classes, to logg/monitor the loss_items as described
above by specific string name:</p>
<dl>
<dt>Set a “component_names” property in the loss class, whos instance is passed through train_params,</dt><dd><p>to be a list of strings, of length n_items who’s ith element is the name of the ith entry in loss_items.
Then each item will be logged, rendered on tensorboard and “watched” (i.e saving model checkpoints
according to it) under &lt;LOSS_CLASS.__name__&gt;”/”&lt;COMPONENT_NAME&gt;. If a single item is returned rather then a
tuple, it would be logged under &lt;LOSS_CLASS.__name__&gt;. When there is no such attributed, the items
will be named &lt;LOSS_CLASS.__name__&gt;”/”<a href="#id8"><span class="problematic" id="id9">Loss_</span></a>”&lt;IDX&gt; according to the length of loss_items</p>
</dd>
<dt>For example:</dt><dd><dl>
<dt>class MyLoss(_Loss):</dt><dd><p>…
def forward(self, inputs, targets):</p>
<blockquote>
<div><p>…
total_loss = comp1 + comp2
loss_items = torch.cat((total_loss.unsqueeze(0),comp1.unsqueeze(0), comp2.unsqueeze(0)).detach()
return total_loss, loss_items</p>
</div></blockquote>
<p>…
&#64;property
def component_names(self):</p>
<blockquote>
<div><p>return [“total_loss”, “my_1st_component”, “my_2nd_component”]</p>
</div></blockquote>
</dd>
</dl>
</dd>
<dt>Trainer.train(…</dt><dd><blockquote>
<div><dl class="simple">
<dt>train_params={“loss”:MyLoss(),</dt><dd><p>…
“metric_to_watch”: “MyLoss/my_1st_component”}</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>This will write to log and monitor MyLoss/total_loss, MyLoss/my_1st_component,</dt><dd><p>MyLoss/my_2nd_component.</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>For example:</dt><dd><blockquote>
<div><dl>
<dt>class MyLoss2(_Loss):</dt><dd><p>…
def forward(self, inputs, targets):</p>
<blockquote>
<div><p>…
total_loss = comp1 + comp2
loss_items = torch.cat((total_loss.unsqueeze(0),comp1.unsqueeze(0), comp2.unsqueeze(0)).detach()
return total_loss, loss_items</p>
</div></blockquote>
<p>…</p>
</dd>
</dl>
</div></blockquote>
<dl>
<dt>Trainer.train(…</dt><dd><blockquote>
<div><dl class="simple">
<dt>train_params={“loss”:MyLoss(),</dt><dd><p>…
“metric_to_watch”: “MyLoss2/loss_0”}</p>
</dd>
</dl>
</div></blockquote>
<p>This will write to log and monitor MyLoss2/loss_0, MyLoss2/loss_1, MyLoss2/loss_2
as they have been named by their positional index in loss_items.</p>
</dd>
</dl>
<p>Since running logs will save the loss_items in some internal state, it is recommended that
loss_items are detached from their computational graph for memory efficiency.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>optimizer</cite> : Union[str, torch.optim.Optimizer]</p>
<blockquote>
<div><p>Optimization algorithm. One of [‘Adam’,’SGD’,’RMSProp’] corresponding to the torch.optim
optimzers implementations, or any object that implements torch.optim.Optimizer.</p>
</div></blockquote>
</li>
<li><p><cite>criterion_params</cite> : dict</p>
<blockquote>
<div><p>Loss function parameters.</p>
</div></blockquote>
</li>
<li><dl>
<dt><cite>optimizer_params</cite><span class="classifier">dict</span></dt><dd><p>When <cite>optimizer</cite> is one of [‘Adam’,’SGD’,’RMSProp’], it will be initialized with optimizer_params.</p>
<p>(see <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">https://pytorch.org/docs/stable/optim.html</a> for the full list of
parameters for each optimizer).</p>
</dd>
</dl>
</li>
<li><p><cite>train_metrics_list</cite> : list(torchmetrics.Metric)</p>
<blockquote>
<div><p>Metrics to log during training. For more information on torchmetrics see
<a class="reference external" href="https://torchmetrics.rtfd.io/en/latest/">https://torchmetrics.rtfd.io/en/latest/</a>.</p>
</div></blockquote>
</li>
<li><p><cite>valid_metrics_list</cite> : list(torchmetrics.Metric)</p>
<blockquote>
<div><p>Metrics to log during validation/testing. For more information on torchmetrics see
<a class="reference external" href="https://torchmetrics.rtfd.io/en/latest/">https://torchmetrics.rtfd.io/en/latest/</a>.</p>
</div></blockquote>
</li>
<li><p><cite>loss_logging_items_names</cite> : list(str)</p>
<blockquote>
<div><p>The list of names/titles for the outputs returned from the loss functions forward pass (reminder-
the loss function should return the tuple (loss, loss_items)). These names will be used for
logging their values.</p>
</div></blockquote>
</li>
<li><p><cite>metric_to_watch</cite> : str (default=”Accuracy”)</p>
<blockquote>
<div><p>will be the metric which the model checkpoint will be saved according to, and can be set to any
of the following:</p>
<blockquote>
<div><p>a metric name (str) of one of the metric objects from the valid_metrics_list</p>
<p>a “metric_name” if some metric in valid_metrics_list has an attribute component_names which
is a list referring to the names of each entry in the output metric (torch tensor of size n)</p>
<p>one of “loss_logging_items_names” i.e which will correspond to an item returned during the
loss function’s forward pass (see loss docs abov).</p>
</div></blockquote>
<p>At the end of each epoch, if a new best metric_to_watch value is achieved, the models checkpoint
is saved in YOUR_PYTHON_PATH/checkpoints/ckpt_best.pth</p>
</div></blockquote>
</li>
<li><p><cite>greater_metric_to_watch_is_better</cite> : bool</p>
<blockquote>
<div><dl class="simple">
<dt>When choosing a model’s checkpoint to be saved, the best achieved model is the one that maximizes the</dt><dd><p>metric_to_watch when this parameter is set to True, and a one that minimizes it otherwise.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ema</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to use Model Exponential Moving Average (see
<a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a> ema implementation)</p>
</div></blockquote>
</li>
<li><p><cite>batch_accumulate</cite> : int (default=1)</p>
<blockquote>
<div><p>Number of batches to accumulate before every backward pass.</p>
</div></blockquote>
</li>
<li><p><cite>ema_params</cite> : dict</p>
<blockquote>
<div><p>Parameters for the ema model.</p>
</div></blockquote>
</li>
<li><p><cite>zero_weight_decay_on_bias_and_bn</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to apply weight decay on batch normalization parameters or not (ignored when the passed
optimizer has already been initialized).</p>
</div></blockquote>
</li>
<li><p><cite>load_opt_params</cite> : bool (default=True)</p>
<blockquote>
<div><p>Whether to load the optimizers parameters as well when loading a model’s checkpoint.</p>
</div></blockquote>
</li>
<li><p><cite>run_validation_freq</cite> : int (default=1)</p>
<blockquote>
<div><dl class="simple">
<dt>The frequency in which validation is performed during training (i.e the validation is ran every</dt><dd><p><cite>run_validation_freq</cite> epochs.</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>save_model</cite> : bool (default=True)</p>
<blockquote>
<div><p>Whether to save the model checkpoints.</p>
</div></blockquote>
</li>
<li><p><cite>silent_mode</cite> : bool</p>
<blockquote>
<div><p>Silents the print outs.</p>
</div></blockquote>
</li>
<li><p><cite>mixed_precision</cite> : bool</p>
<blockquote>
<div><p>Whether to use mixed precision or not.</p>
</div></blockquote>
</li>
<li><p><cite>save_ckpt_epoch_list</cite> : list(int) (default=[])</p>
<blockquote>
<div><p>List of fixed epoch indices the user wishes to save checkpoints in.</p>
</div></blockquote>
</li>
<li><p><cite>average_best_models</cite> : bool (default=False)</p>
<blockquote>
<div><p>If set, a snapshot dictionary file and the average model will be saved / updated at every epoch
and evaluated only when training is completed. The snapshot file will only be deleted upon
completing the training. The snapshot dict will be managed on cpu.</p>
</div></blockquote>
</li>
<li><p><cite>precise_bn</cite> : bool (default=False)</p>
<blockquote>
<div><p>Whether to use precise_bn calculation during the training.</p>
</div></blockquote>
</li>
<li><p><cite>precise_bn_batch_size</cite> : int (default=None)</p>
<blockquote>
<div><p>The effective batch size we want to calculate the batchnorm on. For example, if we are training a model
on 8 gpus, with a batch of 128 on each gpu, a good rule of thumb would be to give it 8192
(ie: effective_batch_size * num_gpus = batch_per_gpu * num_gpus * num_gpus).
If precise_bn_batch_size is not provided in the training_params, the latter heuristic will be taken.</p>
</div></blockquote>
</li>
<li><p><cite>seed</cite> : int (default=42)</p>
<blockquote>
<div><p>Random seed to be set for torch, numpy, and random. When using DDP each process will have it’s seed
set to seed + rank.</p>
</div></blockquote>
</li>
<li><p><cite>log_installed_packages</cite> : bool (default=False)</p>
<blockquote>
<div><dl class="simple">
<dt>When set, the list of all installed packages (and their versions) will be written to the tensorboard</dt><dd><p>and logfile (useful when trying to reproduce results).</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>dataset_statistics</cite> : bool (default=False)</p>
<blockquote>
<div><p>Enable a statistic analysis of the dataset. If set to True the dataset will be analyzed and a report
will be added to the tensorboard along with some sample images from the dataset. Currently only
detection datasets are supported for analysis.</p>
</div></blockquote>
</li>
<li><p><cite>sg_logger</cite> : Union[AbstractSGLogger, str] (defauls=base_sg_logger)</p>
<blockquote>
<div><p>Define the SGLogger object for this training process. The SGLogger handles all disk writes, logs, TensorBoard, remote logging
and remote storage. By overriding the default base_sg_logger, you can change the storage location, support external monitoring and logging
or support remote storage.</p>
</div></blockquote>
</li>
<li><p><cite>sg_logger_params</cite> : dict</p>
<p>SGLogger parameters</p>
</li>
<li><p><cite>clip_grad_norm</cite> : float</p>
<p>Defines a maximal L2 norm of the gradients. Values which exceed the given value will be clipped</p>
</li>
<li><p><cite>lr_cooldown_epochs</cite> : int (default=0)</p>
<p>Number of epochs to cooldown LR (i.e the last epoch from scheduling view point=max_epochs-cooldown).</p>
</li>
<li><p><cite>pre_prediction_callback</cite> : Callable (default=None)</p>
<blockquote>
<div><dl class="simple">
<dt>When not None, this callback will be applied to images and targets, and returning them to be used</dt><dd><p>for the forward pass, and further computations. Args for this callable should be in the order
(inputs, targets, batch_idx) returning modified_inputs, modified_targets</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><cite>ckpt_best_name</cite> : str (default=’ckpt_best.pth’)</p>
<p>The best checkpoint (according to metric_to_watch) will be saved under this filename in the checkpoints directory.</p>
</li>
<li><p><cite>enable_qat</cite>: bool (default=False)</p>
<dl class="simple">
<dt>Adds a QATCallback to the phase callbacks, that triggers quantization aware training starting from</dt><dd><p>qat_params[“start_epoch”]</p>
</dd>
</dl>
</li>
<li><p><cite>qat_params</cite>: dict-like object with the following key/values:</p>
<blockquote>
<div><p>start_epoch: int, first epoch to start QAT.</p>
<dl class="simple">
<dt>quant_modules_calib_method: str, One of [percentile, mse, entropy, max]. Statistics method for amax</dt><dd><p>computation of the quantized modules (default=percentile).</p>
</dd>
</dl>
<p>per_channel_quant_modules: bool, whether quant modules should be per channel (default=False).</p>
<p>calibrate: bool, whether to perfrom calibration (default=False).</p>
<p>calibrated_model_path: str, path to a calibrated checkpoint (default=None).</p>
<dl class="simple">
<dt>calib_data_loader: torch.utils.data.DataLoader, data loader of the calibration dataset. When None,</dt><dd><p>context.train_loader will be used (default=None).</p>
</dd>
</dl>
<p>num_calib_batches: int, number of batches to collect the statistics from.</p>
<dl class="simple">
<dt>percentile: float, percentile value to use when Trainer,quant_modules_calib_method=’percentile’.</dt><dd><p>Discarded when other methods are used (Default=99.99).</p>
</dd>
</dl>
</div></blockquote>
</li>
</ul>
</dd>
</dl>
</div></blockquote>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.get_arch_params">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_arch_params</span></span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.get_arch_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.get_structure">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_structure</span></span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.get_structure" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.get_architecture">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_architecture</span></span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.get_architecture" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.set_experiment_name">
<span class="sig-name descname"><span class="pre">set_experiment_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_experiment_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.set_experiment_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.get_module">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_module</span></span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.get_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.set_module">
<span class="sig-name descname"><span class="pre">set_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.set_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">DataLoader</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">_Loss</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_metrics_list</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_logging_items_names</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_progress_verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_phase_callbacks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_ema_net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span></span></span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.test" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the model on given dataloader and metrics.
:param model: model to perfrom test on. When none is given, will try to use self.net (defalut=None).
:param test_loader: dataloader to perform test on.
:param test_metrics_list: (list(torchmetrics.Metric)) metrics list for evaluation.
:param silent_mode: (bool) controls verbosity
:param metrics_progress_verbose: (bool) controls the verbosity of metrics progress (default=False). Slows down the program.
:param use_ema_net (bool) whether to perform test on self.ema_model.ema (when self.ema_model.ema exists,</p>
<blockquote>
<div><p>otherwise self.net will be tested) (default=True)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>results tuple (tuple) containing the loss items and metric values.</p>
</dd>
</dl>
<dl class="simple">
<dt>All of the above args will override Trainer’s corresponding attribute when not equal to None. Then evaluation</dt><dd><p>is ran on self.test_loader with self.test_metrics.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_loader</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">MetricCollection</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#super_gradients.training.EvaluationType" title="super_gradients.common.data_types.enum.evaluation_type.EvaluationType"><span class="pre">EvaluationType</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">silent_mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_progress_verbose</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.evaluate" title="Permalink to this definition"></a></dt>
<dd><p>Evaluates the model on given dataloader and metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_loader</strong> – dataloader to perform evaluataion on</p></li>
<li><p><strong>metrics</strong> – (MetricCollection) metrics for evaluation</p></li>
<li><p><strong>evaluation_type</strong> – (EvaluationType) controls which phase callbacks will be used (for example, on batch end,
when evaluation_type=EvaluationType.VALIDATION the Phase.VALIDATION_BATCH_END callbacks will be triggered)</p></li>
<li><p><strong>epoch</strong> – (int) epoch idx</p></li>
<li><p><strong>silent_mode</strong> – (bool) controls verbosity</p></li>
<li><p><strong>metrics_progress_verbose</strong> – (bool) controls the verbosity of metrics progress (default=False).
Slows down the program significantly.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>results tuple (tuple) containing the loss items and metric values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.get_net">
<em class="property"><span class="pre">property</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_net</span></span><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.get_net" title="Permalink to this definition"></a></dt>
<dd><p>Getter for network.
:return: torch.nn.Module, self.net</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.set_net">
<span class="sig-name descname"><span class="pre">set_net</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_net"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.set_net" title="Permalink to this definition"></a></dt>
<dd><p>Setter for network.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>net</strong> – torch.nn.Module, value to set net</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.set_ckpt_best_name">
<span class="sig-name descname"><span class="pre">set_ckpt_best_name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_best_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_ckpt_best_name"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.set_ckpt_best_name" title="Permalink to this definition"></a></dt>
<dd><p>Setter for best checkpoint filename.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>ckpt_best_name</strong> – str, value to set ckpt_best_name</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.Trainer.set_ema">
<span class="sig-name descname"><span class="pre">set_ema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/sg_trainer/sg_trainer.html#Trainer.set_ema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.Trainer.set_ema" title="Permalink to this definition"></a></dt>
<dd><p>Setter for self.ema</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>val</strong> – bool, value to set ema</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.sg_trainer.</span></span><span class="sig-name descname"><span class="pre">MultiGPUMode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/multi_gpu_mode.html#MultiGPUMode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">OFF</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Single</span> <span class="pre">GPU</span> <span class="pre">Mode</span> <span class="pre">/</span> <span class="pre">CPU</span> <span class="pre">Mode</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">DATA_PARALLEL</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Multiple</span> <span class="pre">GPUs,</span> <span class="pre">Synchronous</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">DISTRIBUTED_DATA_PARALLEL</span> <span class="pre">-</span> <span class="pre">Multiple</span> <span class="pre">GPUs,</span> <span class="pre">Asynchronous</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode.OFF">
<span class="sig-name descname"><span class="pre">OFF</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Off'</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode.OFF" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode.DATA_PARALLEL">
<span class="sig-name descname"><span class="pre">DATA_PARALLEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DP'</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode.DATA_PARALLEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL">
<span class="sig-name descname"><span class="pre">DISTRIBUTED_DATA_PARALLEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DDP'</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode.DISTRIBUTED_DATA_PARALLEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode.AUTO">
<span class="sig-name descname"><span class="pre">AUTO</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'AUTO'</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode.AUTO" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.MultiGPUMode.dict">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/multi_gpu_mode.html#MultiGPUMode.dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.MultiGPUMode.dict" title="Permalink to this definition"></a></dt>
<dd><p>return dictionary mapping from the mode name (in call string cases) to the enum value</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.StrictLoad">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.sg_trainer.</span></span><span class="sig-name descname"><span class="pre">StrictLoad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/common/data_types/enum/strict_load.html#StrictLoad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.sg_trainer.StrictLoad" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></p>
<p>Wrapper for adding more functionality to torch’s strict_load parameter in load_state_dict().
.. attribute:: OFF              - Native torch “strict_load = off” behaviour. See nn.Module.load_state_dict() documentation for more details.</p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">ON</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-</span> <span class="pre">Native</span> <span class="pre">torch</span> <span class="pre">&quot;strict_load</span> <span class="pre">=</span> <span class="pre">on&quot;</span> <span class="pre">behaviour.</span> <span class="pre">See</span> <span class="pre">nn.Module.load_state_dict()</span> <span class="pre">documentation</span> <span class="pre">for</span> <span class="pre">more</span> <span class="pre">details.</span></span></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">NO_KEY_MATCHING</span>&#160; <span class="pre">-</span> <span class="pre">Allows</span> <span class="pre">the</span> <span class="pre">usage</span> <span class="pre">of</span> <span class="pre">SuperGradient's</span> <span class="pre">adapt_checkpoint</span> <span class="pre">function,</span> <span class="pre">which</span> <span class="pre">loads</span> <span class="pre">a</span> <span class="pre">checkpoint</span> <span class="pre">by</span> <span class="pre">matching</span> <span class="pre">each</span></span></dt>
<dd><p>layer’s shapes (and bypasses the strict matching of the names of each layer (ie: disregards the state_dict key matching)).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.StrictLoad.OFF">
<span class="sig-name descname"><span class="pre">OFF</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.StrictLoad.OFF" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.StrictLoad.ON">
<span class="sig-name descname"><span class="pre">ON</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.StrictLoad.ON" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.sg_trainer.StrictLoad.NO_KEY_MATCHING">
<span class="sig-name descname"><span class="pre">NO_KEY_MATCHING</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'no_key_matching'</span></em><a class="headerlink" href="#super_gradients.training.sg_trainer.StrictLoad.NO_KEY_MATCHING" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="super-gradients-training-training-hyperparams-module">
<h2>super_gradients.training.training_hyperparams module<a class="headerlink" href="#super-gradients-training-training-hyperparams-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.training_hyperparams"></span><dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cifar10_resnet_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cifar10_resnet_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cifar10_resnet_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cifar10_resnet_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cityscapes_ddrnet_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cityscapes_ddrnet_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cityscapes_ddrnet_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cityscapes_ddrnet_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cityscapes_regseg48_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cityscapes_regseg48_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cityscapes_regseg48_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cityscapes_regseg48_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cityscapes_stdc_base_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_base_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cityscapes_stdc_base_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_base_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cityscapes_stdc_seg50_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg50_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cityscapes_stdc_seg50_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_seg50_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.cityscapes_stdc_seg75_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">cityscapes_stdc_seg75_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#cityscapes_stdc_seg75_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.cityscapes_stdc_seg75_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.coco2017_ssd_lite_mobilenet_v2_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">coco2017_ssd_lite_mobilenet_v2_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#coco2017_ssd_lite_mobilenet_v2_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.coco2017_ssd_lite_mobilenet_v2_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.coco2017_yolox_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">coco2017_yolox_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#coco2017_yolox_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.coco2017_yolox_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.coco_segmentation_shelfnet_lw_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">coco_segmentation_shelfnet_lw_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#coco_segmentation_shelfnet_lw_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.coco_segmentation_shelfnet_lw_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_efficientnet_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_efficientnet_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_efficientnet_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_efficientnet_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_mobilenetv2_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv2_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_mobilenetv2_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv2_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_mobilenetv3_base_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv3_base_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_mobilenetv3_base_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_base_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_mobilenetv3_large_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv3_large_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_mobilenetv3_large_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_large_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_mobilenetv3_small_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_mobilenetv3_small_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_mobilenetv3_small_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_mobilenetv3_small_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_regnetY_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_regnetY_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_regnetY_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_regnetY_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_repvgg_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_repvgg_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_repvgg_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_repvgg_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_resnet50_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_resnet50_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_resnet50_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_resnet50_kd_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_resnet50_kd_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_resnet50_kd_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_resnet50_kd_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_vit_base_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_vit_base_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_vit_base_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_vit_base_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.imagenet_vit_large_train_params">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">imagenet_vit_large_train_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#imagenet_vit_large_train_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.imagenet_vit_large_train_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.training_hyperparams.get">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.training_hyperparams.</span></span><span class="sig-name descname"><span class="pre">get</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overriding_params</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span></span></span><a class="reference internal" href="_modules/super_gradients/training/training_hyperparams/training_hyperparams.html#get"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.training_hyperparams.get" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Class for creating training hyper parameters dictionary, taking defaults from yaml</dt><dd><p>files in src/super_gradients/recipes.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>overriding_params</strong> – Dict, dictionary like object containing entries to override in the recipe’s training
hyper parameters dictionary.</p></li>
<li><p><strong>config_name</strong> – yaml config filename in recipes (for example coco2017_yolox).</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="super-gradients-training-transforms-module">
<h2>super_gradients.training.transforms module<a class="headerlink" href="#super-gradients-training-transforms-module" title="Permalink to this heading"></a></h2>
<span class="target" id="module-super_gradients.training.transforms"></span><dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">Transforms</span></span><a class="reference internal" href="_modules/super_gradients/common/object_names.html#Transforms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.Transforms" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Static class holding all the supported transform names</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegRandomFlip">
<span class="sig-name descname"><span class="pre">SegRandomFlip</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegRandomFlip'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegRandomFlip" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegResize">
<span class="sig-name descname"><span class="pre">SegResize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegResize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegResize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegRescale">
<span class="sig-name descname"><span class="pre">SegRescale</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegRescale'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegRescale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegRandomRescale">
<span class="sig-name descname"><span class="pre">SegRandomRescale</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegRandomRescale'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegRandomRescale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegRandomRotate">
<span class="sig-name descname"><span class="pre">SegRandomRotate</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegRandomRotate'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegRandomRotate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegCropImageAndMask">
<span class="sig-name descname"><span class="pre">SegCropImageAndMask</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegCropImageAndMask'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegCropImageAndMask" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegRandomGaussianBlur">
<span class="sig-name descname"><span class="pre">SegRandomGaussianBlur</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegRandomGaussianBlur'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegRandomGaussianBlur" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegPadShortToCropSize">
<span class="sig-name descname"><span class="pre">SegPadShortToCropSize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegPadShortToCropSize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegPadShortToCropSize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.SegColorJitter">
<span class="sig-name descname"><span class="pre">SegColorJitter</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'SegColorJitter'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.SegColorJitter" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionMosaic">
<span class="sig-name descname"><span class="pre">DetectionMosaic</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMosaic'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionMosaic" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionRandomAffine">
<span class="sig-name descname"><span class="pre">DetectionRandomAffine</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionRandomAffine'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionRandomAffine" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionMixup">
<span class="sig-name descname"><span class="pre">DetectionMixup</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionMixup'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionMixup" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionHSV">
<span class="sig-name descname"><span class="pre">DetectionHSV</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionHSV'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionHSV" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionHorizontalFlip">
<span class="sig-name descname"><span class="pre">DetectionHorizontalFlip</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionHorizontalFlip'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionHorizontalFlip" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionPaddedRescale">
<span class="sig-name descname"><span class="pre">DetectionPaddedRescale</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionPaddedRescale'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionPaddedRescale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionTargetsFormat">
<span class="sig-name descname"><span class="pre">DetectionTargetsFormat</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionTargetsFormat'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionTargetsFormat" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.DetectionTargetsFormatTransform">
<span class="sig-name descname"><span class="pre">DetectionTargetsFormatTransform</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'DetectionTargetsFormatTransform'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.DetectionTargetsFormatTransform" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomResizedCropAndInterpolation">
<span class="sig-name descname"><span class="pre">RandomResizedCropAndInterpolation</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomResizedCropAndInterpolation'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomResizedCropAndInterpolation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandAugmentTransform">
<span class="sig-name descname"><span class="pre">RandAugmentTransform</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandAugmentTransform'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandAugmentTransform" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Lighting">
<span class="sig-name descname"><span class="pre">Lighting</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Lighting'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Lighting" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomErase">
<span class="sig-name descname"><span class="pre">RandomErase</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomErase'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomErase" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Compose">
<span class="sig-name descname"><span class="pre">Compose</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Compose'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Compose" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.ToTensor">
<span class="sig-name descname"><span class="pre">ToTensor</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'ToTensor'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.ToTensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.PILToTensor">
<span class="sig-name descname"><span class="pre">PILToTensor</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'PILToTensor'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.PILToTensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.ConvertImageDtype">
<span class="sig-name descname"><span class="pre">ConvertImageDtype</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'ConvertImageDtype'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.ConvertImageDtype" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.ToPILImage">
<span class="sig-name descname"><span class="pre">ToPILImage</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'ToPILImage'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.ToPILImage" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Normalize">
<span class="sig-name descname"><span class="pre">Normalize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Normalize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Normalize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Resize">
<span class="sig-name descname"><span class="pre">Resize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Resize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Resize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.CenterCrop">
<span class="sig-name descname"><span class="pre">CenterCrop</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'CenterCrop'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.CenterCrop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Pad">
<span class="sig-name descname"><span class="pre">Pad</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Pad'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Pad" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Lambda">
<span class="sig-name descname"><span class="pre">Lambda</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Lambda'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Lambda" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomApply">
<span class="sig-name descname"><span class="pre">RandomApply</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomApply'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomApply" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomChoice">
<span class="sig-name descname"><span class="pre">RandomChoice</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomChoice'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomChoice" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomOrder">
<span class="sig-name descname"><span class="pre">RandomOrder</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomOrder'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomOrder" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomCrop">
<span class="sig-name descname"><span class="pre">RandomCrop</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomCrop'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomCrop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomHorizontalFlip">
<span class="sig-name descname"><span class="pre">RandomHorizontalFlip</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomHorizontalFlip'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomHorizontalFlip" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomVerticalFlip">
<span class="sig-name descname"><span class="pre">RandomVerticalFlip</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomVerticalFlip'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomVerticalFlip" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomResizedCrop">
<span class="sig-name descname"><span class="pre">RandomResizedCrop</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomResizedCrop'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomResizedCrop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.FiveCrop">
<span class="sig-name descname"><span class="pre">FiveCrop</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'FiveCrop'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.FiveCrop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.TenCrop">
<span class="sig-name descname"><span class="pre">TenCrop</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'TenCrop'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.TenCrop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.LinearTransformation">
<span class="sig-name descname"><span class="pre">LinearTransformation</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'LinearTransformation'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.LinearTransformation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.ColorJitter">
<span class="sig-name descname"><span class="pre">ColorJitter</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'ColorJitter'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.ColorJitter" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomRotation">
<span class="sig-name descname"><span class="pre">RandomRotation</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomRotation'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomRotation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomAffine">
<span class="sig-name descname"><span class="pre">RandomAffine</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomAffine'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomAffine" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.Grayscale">
<span class="sig-name descname"><span class="pre">Grayscale</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Grayscale'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.Grayscale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomGrayscale">
<span class="sig-name descname"><span class="pre">RandomGrayscale</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomGrayscale'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomGrayscale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomPerspective">
<span class="sig-name descname"><span class="pre">RandomPerspective</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomPerspective'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomPerspective" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomErasing">
<span class="sig-name descname"><span class="pre">RandomErasing</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomErasing'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomErasing" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.GaussianBlur">
<span class="sig-name descname"><span class="pre">GaussianBlur</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'GaussianBlur'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.GaussianBlur" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.InterpolationMode">
<span class="sig-name descname"><span class="pre">InterpolationMode</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'InterpolationMode'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.InterpolationMode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomInvert">
<span class="sig-name descname"><span class="pre">RandomInvert</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomInvert'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomInvert" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomPosterize">
<span class="sig-name descname"><span class="pre">RandomPosterize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomPosterize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomPosterize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomSolarize">
<span class="sig-name descname"><span class="pre">RandomSolarize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomSolarize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomSolarize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomAdjustSharpness">
<span class="sig-name descname"><span class="pre">RandomAdjustSharpness</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomAdjustSharpness'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomAdjustSharpness" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomAutocontrast">
<span class="sig-name descname"><span class="pre">RandomAutocontrast</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomAutocontrast'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomAutocontrast" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.Transforms.RandomEqualize">
<span class="sig-name descname"><span class="pre">RandomEqualize</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'RandomEqualize'</span></em><a class="headerlink" href="#super_gradients.training.transforms.Transforms.RandomEqualize" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionMosaic">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">DetectionMosaic</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">enable_mosaic</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionMosaic"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionMosaic" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionTransform</span></code></p>
<p>DetectionMosaic detection transform</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionMosaic.input_dim">
<span class="sig-name descname"><span class="pre">input_dim</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionMosaic.input_dim" title="Permalink to this definition"></a></dt>
<dd><p>(tuple) input dimension.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionMosaic.prob">
<span class="sig-name descname"><span class="pre">prob</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionMosaic.prob" title="Permalink to this definition"></a></dt>
<dd><p>(float) probability of applying mosaic.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionMosaic.enable_mosaic">
<span class="sig-name descname"><span class="pre">enable_mosaic</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionMosaic.enable_mosaic" title="Permalink to this definition"></a></dt>
<dd><p>(bool) whether to apply mosaic at all (regardless of prob) (default=True).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionMosaic.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionMosaic.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionMosaic.close" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">DetectionRandomAffine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">degrees</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">translate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shear</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(640,</span> <span class="pre">640)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_box_candidates</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">wh_thr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ar_thr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">area_thr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionRandomAffine"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionTransform</span></code></p>
<p>DetectionRandomAffine detection transform</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.target_size">
<span class="sig-name descname"><span class="pre">target_size</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.target_size" title="Permalink to this definition"></a></dt>
<dd><p>(tuple) desired output shape.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.degrees">
<span class="sig-name descname"><span class="pre">degrees</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.degrees" title="Permalink to this definition"></a></dt>
<dd><p>(Union[tuple, float]) degrees for random rotation, when float the random values are drawn uniformly
from (-degrees, degrees)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.translate">
<span class="sig-name descname"><span class="pre">translate</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.translate" title="Permalink to this definition"></a></dt>
<dd><p>(Union[tuple, float]) translate size (in pixels) for random translation, when float the random values
are drawn uniformly from (-translate, translate)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.scales">
<span class="sig-name descname"><span class="pre">scales</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.scales" title="Permalink to this definition"></a></dt>
<dd><p>(Union[tuple, float]) values for random rescale, when float the random values are drawn uniformly
from (0.1-scales, 0.1+scales)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.shear">
<span class="sig-name descname"><span class="pre">shear</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.shear" title="Permalink to this definition"></a></dt>
<dd><p>(Union[tuple, float]) degrees for random shear, when float the random values are drawn uniformly
from (shear, shear)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.enable">
<span class="sig-name descname"><span class="pre">enable</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.enable" title="Permalink to this definition"></a></dt>
<dd><p>(bool) whether to apply the below transform at all.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.filter_box_candidates">
<span class="sig-name descname"><span class="pre">filter_box_candidates</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.filter_box_candidates" title="Permalink to this definition"></a></dt>
<dd><p>(bool) whether to filter out transformed bboxes by edge size, area ratio, and aspect ratio (default=False).</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.wh_thr">
<span class="sig-name descname"><span class="pre">wh_thr</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.wh_thr" title="Permalink to this definition"></a></dt>
<dd><p>(float) edge size threshold when filter_box_candidates = True. Bounding oxes with edges smaller
then this values will be filtered out. (default=2)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.ar_thr">
<span class="sig-name descname"><span class="pre">ar_thr</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.ar_thr" title="Permalink to this definition"></a></dt>
<dd><p>(float) aspect ratio threshold filter_box_candidates = True. Bounding boxes with aspect ratio larger
then this values will be filtered out. (default=20)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.area_thr">
<span class="sig-name descname"><span class="pre">area_thr</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.area_thr" title="Permalink to this definition"></a></dt>
<dd><p>(float) threshold for area ratio between original image and the transformed one, when when filter_box_candidates = True.
Bounding boxes with such ratio smaller then this value will be filtered out. (default=0.1)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionRandomAffine.close">
<span class="sig-name descname"><span class="pre">close</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionRandomAffine.close"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionRandomAffine.close" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionHSV">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">DetectionHSV</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prob</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hgain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sgain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vgain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bgr_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">1,</span> <span class="pre">2)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionHSV"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionHSV" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionTransform</span></code></p>
<p>Detection HSV transform.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionPaddedRescale">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">DetectionPaddedRescale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">swap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(2,</span> <span class="pre">0,</span> <span class="pre">1)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_targets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pad_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">114</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionPaddedRescale"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionPaddedRescale" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionTransform</span></code></p>
<p>Preprocessing transform to be applied last of all transforms for validation.</p>
<p>Image- Rescales and pads to self.input_dim.
Targets- pads targets to max_targets, moves the class label to first index, converts boxes format- xyxy -&gt; cxcywh.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionPaddedRescale.input_dim">
<span class="sig-name descname"><span class="pre">input_dim</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionPaddedRescale.input_dim" title="Permalink to this definition"></a></dt>
<dd><p>(tuple) final input dimension (default=(640,640))</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionPaddedRescale.swap">
<span class="sig-name descname"><span class="pre">swap</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionPaddedRescale.swap" title="Permalink to this definition"></a></dt>
<dd><p>image axis’s to be rearranged.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionTargetsFormatTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.transforms.</span></span><span class="sig-name descname"><span class="pre">DetectionTargetsFormatTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DetectionTargetsFormat</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">DetectionTargetsFormat.XYXY_LABEL</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_format</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">DetectionTargetsFormat</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">DetectionTargetsFormat.LABEL_CXCYWH</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_bbox_edge_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">120</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/transforms/transforms.html#DetectionTargetsFormatTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">DetectionTransform</span></code></p>
<p>Detection targets format transform</p>
<p>Converts targets in input_format to output_format.
.. attribute:: input_format</p>
<blockquote>
<div><p>DetectionTargetsFormat: input target format</p>
</div></blockquote>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionTargetsFormatTransform.output_format">
<span class="sig-name descname"><span class="pre">output_format</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.output_format" title="Permalink to this definition"></a></dt>
<dd><p>DetectionTargetsFormat: output target format</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionTargetsFormatTransform.min_bbox_edge_size">
<span class="sig-name descname"><span class="pre">min_bbox_edge_size</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.min_bbox_edge_size" title="Permalink to this definition"></a></dt>
<dd><p>int: bboxes with edge size lower then this values will be removed.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.transforms.DetectionTargetsFormatTransform.max_targets">
<span class="sig-name descname"><span class="pre">max_targets</span></span><a class="headerlink" href="#super_gradients.training.transforms.DetectionTargetsFormatTransform.max_targets" title="Permalink to this definition"></a></dt>
<dd><p>int: max objects in single image, padding target to this size.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-super_gradients.training.utils">
<span id="super-gradients-training-utils-module"></span><h2>super_gradients.training.utils module<a class="headerlink" href="#module-super_gradients.training.utils" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">Timer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to measure time handling both GPU &amp; CPU processes
Returns time in milliseconds</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer.start">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.start"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer.start" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer.stop">
<span class="sig-name descname"><span class="pre">stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.stop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer.stop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">HpmStruct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.set_schema">
<span class="sig-name descname"><span class="pre">set_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.set_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.set_schema" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.override">
<span class="sig-name descname"><span class="pre">override</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.override" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">include_schema</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.to_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.to_dict" title="Permalink to this definition"></a></dt>
<dd><p>Convert this HpmStruct instance into a dict.
:param include_schema: If True, also return the field “schema”
:return: Dict representation of this HpmStruct instance.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.validate">
<span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.validate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.validate" title="Permalink to this definition"></a></dt>
<dd><p>Validate the current dict values according to the provided schema
:raises</p>
<blockquote>
<div><p><cite>AttributeError</cite> if schema was not set
<cite>jsonschema.exceptions.ValidationError</cite> if the instance is invalid
<cite>jsonschema.exceptions.SchemaError</cite> if the schema itselfis invalid</p>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">WrappedModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.WrappedModel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.WrappedModel.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.WrappedModel.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.convert_to_tensor">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">convert_to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#convert_to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.convert_to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts numpy arrays and lists to Torch tensors before calculation losses
:param array: torch.tensor / Numpy array / List</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.get_param">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.get_param" title="Permalink to this definition"></a></dt>
<dd><p>Retrieves a param from a parameter object/dict. If the parameter does not exist, will return default_val.
In case the default_val is of type dictionary, and a value is found in the params - the function
will return the default value dictionary with internal values overridden by the found value</p>
<p>i.e.
default_opt_params = {‘lr’:0.1, ‘momentum’:0.99, ‘alpha’:0.001}
training_params = {‘optimizer_params’: {‘lr’:0.0001}, ‘batch’: 32 …. }
get_param(training_params, name=’optimizer_params’, default_val=default_opt_params)
will return {‘lr’:0.0001, ‘momentum’:0.99, ‘alpha’:0.001}</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – an object (typically HpmStruct) or a dict holding the params</p></li>
<li><p><strong>name</strong> – name of the searched parameter</p></li>
<li><p><strong>default_val</strong> – assumed to be the same type as the value searched in the params</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the found value, or default if not found</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.tensor_container_to_device">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">tensor_container_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">tuple</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">list</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#tensor_container_to_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.tensor_container_to_device" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>recursively send compounded objects to device (sending all tensors to device and maintaining structure)</dt><dd><p>:param obj           the object to send to device (list / tuple / tensor / dict)
:param device:       device to send the tensors to
:param non_blocking: used for DistributedDataParallel
:returns        an object with the same structure (tensors, lists, tuples) with the device pointers (like</p>
<blockquote>
<div><p>the return value of Tensor.to(device)</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.adapt_state_dict_to_fit_model_layer_names">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">adapt_state_dict_to_fit_model_layer_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_ckpt</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">list</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#adapt_state_dict_to_fit_model_layer_names"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.adapt_state_dict_to_fit_model_layer_names" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method tries to correct the keys in the model_state_dict to fit
the ckpt in order to properly load the weights into the model. If unsuccessful - returns None</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param model_state_dict</dt>
<dd class="field-odd"><p>the model state_dict</p>
</dd>
<dt class="field-even">param source_ckpt</dt>
<dd class="field-even"><p>checkpoint dict</p>
</dd>
</dl>
<p>:param exclude                  optional list for excluded layers
:param solver:                  callable with signature (ckpt_key, ckpt_val, model_key, model_val)</p>
<blockquote>
<div><p>that returns a desired weight for ckpt_val.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>renamed checkpoint dict (if possible)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.raise_informative_runtime_error">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">raise_informative_runtime_error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exception_msg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#raise_informative_runtime_error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.raise_informative_runtime_error" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method calls “adapt_state_dict_to_fit_model_layer_names”
and enhances the exception_msg if loading the checkpoint_dict via the conversion method is possible</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.random_seed">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_ddp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#random_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Sets random seed of numpy, torch and random.</p>
<p>When using ddp a seed will be set for each process according to its local rank derived from the device number.
:param is_ddp: bool, will set different random seed for each process when using ddp.
:param device: ‘cuda’,’cpu’, ‘cuda:&lt;device_number&gt;’
:param seed: int, random seed to be set</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.torch_version_is_greater_or_equal">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">torch_version_is_greater_or_equal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">major</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minor</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/super_gradients/training/utils/version_utils.html#torch_version_is_greater_or_equal"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.torch_version_is_greater_or_equal" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-contents">
<h2>Module contents<a class="headerlink" href="#module-contents" title="Permalink to this heading"></a></h2>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="super_gradients.common.html" class="btn btn-neutral float-left" title="Common package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, SuperGradients team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
