<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>super_gradients.training.sg_model.sg_model &mdash; SuperGradients 1.0 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../../index.html" class="icon icon-home"> SuperGradients
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Welcome To SuperGradients</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../welcome.html">Fill our 4-question quick survey! We will raffle free SuperGradients swag between those who will participate -&gt; Fill Survey</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../welcome.html#supergradients">SuperGradients</a></li>
</ul>
<p class="caption"><span class="caption-text">Technical Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../super_gradients.common.html">Common package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../super_gradients.training.html">Training package</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html">What is SuperGradients?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#introducing-the-supergradients-library">Introducing the SuperGradients library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#integrating-your-training-code-complete-walkthrough">Integrating Your Training Code - Complete Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#training-parameters">Training Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#logs-and-checkpoints">Logs and Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#dataset-parameters">Dataset Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#network-architectures">Network Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#pretrained-models">Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#how-to-reproduce-our-training-recipes">How To Reproduce Our Training Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#professional-tools-integration">Professional Tools Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../user_guide.html#supergradients-faq">SuperGradients FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">SuperGradients</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../../index.html">Module code</a> &raquo;</li>
      <li>super_gradients.training.sg_model.sg_model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for super_gradients.training.sg_model.sg_model</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Mapping</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pkg_resources</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">deprecated</span> <span class="kn">import</span> <span class="n">deprecated</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.cuda.amp</span> <span class="kn">import</span> <span class="n">GradScaler</span><span class="p">,</span> <span class="n">autocast</span>
<span class="kn">from</span> <span class="nn">torchmetrics</span> <span class="kn">import</span> <span class="n">MetricCollection</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">piptools.scripts.sync</span> <span class="kn">import</span> <span class="n">_get_installed_distributions</span>

<span class="kn">from</span> <span class="nn">super_gradients.training.models.all_architectures</span> <span class="kn">import</span> <span class="n">ARCHITECTURES</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.decorators.factory_decorator</span> <span class="kn">import</span> <span class="n">resolve_param</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.environment</span> <span class="kn">import</span> <span class="n">env_helpers</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.abstractions.abstract_logger</span> <span class="kn">import</span> <span class="n">get_logger</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.factories.datasets_factory</span> <span class="kn">import</span> <span class="n">DatasetsFactory</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.factories.list_factory</span> <span class="kn">import</span> <span class="n">ListFactory</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.factories.losses_factory</span> <span class="kn">import</span> <span class="n">LossesFactory</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.factories.metrics_factory</span> <span class="kn">import</span> <span class="n">MetricsFactory</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.sg_loggers</span> <span class="kn">import</span> <span class="n">SG_LOGGERS</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.sg_loggers.abstract_sg_logger</span> <span class="kn">import</span> <span class="n">AbstractSGLogger</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.sg_loggers.base_sg_logger</span> <span class="kn">import</span> <span class="n">BaseSGLogger</span>
<span class="kn">from</span> <span class="nn">super_gradients.training</span> <span class="kn">import</span> <span class="n">utils</span> <span class="k">as</span> <span class="n">core_utils</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.models</span> <span class="kn">import</span> <span class="n">SgModule</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.pretrained_models</span> <span class="kn">import</span> <span class="n">PRETRAINED_NUM_CLASSES</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils</span> <span class="kn">import</span> <span class="n">sg_model_utils</span>
<span class="kn">from</span> <span class="nn">super_gradients.training</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.exceptions.sg_model_exceptions</span> <span class="kn">import</span> <span class="n">UnsupportedOptimizerFormat</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.datasets</span> <span class="kn">import</span> <span class="n">DatasetInterface</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.losses</span> <span class="kn">import</span> <span class="n">LOSSES</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.metrics.metric_utils</span> <span class="kn">import</span> <span class="n">get_metrics_titles</span><span class="p">,</span> <span class="n">get_metrics_results_tuple</span><span class="p">,</span> \
    <span class="n">get_logging_values</span><span class="p">,</span> \
    <span class="n">get_metrics_dict</span><span class="p">,</span> <span class="n">get_train_loop_description_dict</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.params</span> <span class="kn">import</span> <span class="n">TrainingParams</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.detection_utils</span> <span class="kn">import</span> <span class="n">DetectionPostPredictionCallback</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.distributed_training_utils</span> <span class="kn">import</span> <span class="n">MultiGPUModeAutocastWrapper</span><span class="p">,</span> \
    <span class="n">reduce_results_tuple_for_ddp</span><span class="p">,</span> <span class="n">compute_precise_bn_stats</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.ema</span> <span class="kn">import</span> <span class="n">ModelEMA</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.optimizer_utils</span> <span class="kn">import</span> <span class="n">build_optimizer</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.weight_averaging_utils</span> <span class="kn">import</span> <span class="n">ModelWeightAveraging</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.metrics</span> <span class="kn">import</span> <span class="n">Accuracy</span><span class="p">,</span> <span class="n">Top5</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils</span> <span class="kn">import</span> <span class="n">random_seed</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.checkpoint_utils</span> <span class="kn">import</span> <span class="n">get_ckpt_local_path</span><span class="p">,</span> <span class="n">read_ckpt_state_dict</span><span class="p">,</span> \
    <span class="n">load_checkpoint_to_model</span><span class="p">,</span> <span class="n">load_pretrained_weights</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.datasets.datasets_utils</span> <span class="kn">import</span> <span class="n">DatasetStatisticsTensorboardLogger</span>
<span class="kn">from</span> <span class="nn">super_gradients.training.utils.callbacks</span> <span class="kn">import</span> <span class="n">CallbackHandler</span><span class="p">,</span> <span class="n">Phase</span><span class="p">,</span> <span class="n">LR_SCHEDULERS_CLS_DICT</span><span class="p">,</span> <span class="n">PhaseContext</span><span class="p">,</span> \
    <span class="n">MetricsUpdateCallback</span><span class="p">,</span> <span class="n">LR_WARMUP_CLS_DICT</span>
<span class="kn">from</span> <span class="nn">super_gradients.common.environment</span> <span class="kn">import</span> <span class="n">environment_config</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<div class="viewcode-block" id="StrictLoad"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.StrictLoad">[docs]</a><span class="k">class</span> <span class="nc">StrictLoad</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper for adding more functionality to torch&#39;s strict_load parameter in load_state_dict().</span>
<span class="sd">        Attributes:</span>
<span class="sd">            OFF              - Native torch &quot;strict_load = off&quot; behaviour. See nn.Module.load_state_dict() documentation for more details.</span>
<span class="sd">            ON               - Native torch &quot;strict_load = on&quot; behaviour. See nn.Module.load_state_dict() documentation for more details.</span>
<span class="sd">            NO_KEY_MATCHING  - Allows the usage of SuperGradient&#39;s adapt_checkpoint function, which loads a checkpoint by matching each</span>
<span class="sd">                               layer&#39;s shapes (and bypasses the strict matching of the names of each layer (ie: disregards the state_dict key matching)).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">OFF</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">ON</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">NO_KEY_MATCHING</span> <span class="o">=</span> <span class="s1">&#39;no_key_matching&#39;</span></div>


<div class="viewcode-block" id="MultiGPUMode"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.MultiGPUMode">[docs]</a><span class="k">class</span> <span class="nc">MultiGPUMode</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    MultiGPUMode</span>

<span class="sd">        Attributes:</span>
<span class="sd">            OFF                       - Single GPU Mode / CPU Mode</span>
<span class="sd">            DATA_PARALLEL             - Multiple GPUs, Synchronous</span>
<span class="sd">            DISTRIBUTED_DATA_PARALLEL - Multiple GPUs, Asynchronous</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">OFF</span> <span class="o">=</span> <span class="s1">&#39;Off&#39;</span>
    <span class="n">DATA_PARALLEL</span> <span class="o">=</span> <span class="s1">&#39;DP&#39;</span>
    <span class="n">DISTRIBUTED_DATA_PARALLEL</span> <span class="o">=</span> <span class="s1">&#39;DDP&#39;</span>
    <span class="n">AUTO</span> <span class="o">=</span> <span class="s2">&quot;AUTO&quot;</span></div>


<div class="viewcode-block" id="EvaluationType"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.EvaluationType">[docs]</a><span class="k">class</span> <span class="nc">EvaluationType</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    EvaluationType</span>

<span class="sd">    Passed to SgModel.evaluate(..), and controls which phase callbacks should be triggered (if at all).</span>

<span class="sd">        Attributes:</span>
<span class="sd">            TEST</span>
<span class="sd">            VALIDATION</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">TEST</span> <span class="o">=</span> <span class="s1">&#39;TEST&#39;</span>
    <span class="n">VALIDATION</span> <span class="o">=</span> <span class="s1">&#39;VALIDATION&#39;</span></div>


<div class="viewcode-block" id="SgModel"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel">[docs]</a><span class="k">class</span> <span class="nc">SgModel</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    SuperGradient Model - Base Class for Sg Models</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    train(max_epochs : int, initial_epoch : int, save_model : bool)</span>
<span class="sd">        the main function used for the training, h.p. updating, logging etc.</span>

<span class="sd">    predict(idx : int)</span>
<span class="sd">        returns the predictions and label of the current inputs</span>

<span class="sd">    test(epoch : int, idx : int, save : bool):</span>
<span class="sd">        returns the test loss, accuracy and runtime</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">multi_gpu</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">MultiGPUMode</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">OFF</span><span class="p">,</span>
                 <span class="n">model_checkpoints_location</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;local&#39;</span><span class="p">,</span>
                 <span class="n">overwrite_local_checkpoint</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">ckpt_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;ckpt_latest.pth&#39;</span><span class="p">,</span>
                 <span class="n">post_prediction_callback</span><span class="p">:</span> <span class="n">DetectionPostPredictionCallback</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">ckpt_root_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        :param experiment_name:                      Used for logging and loading purposes</span>
<span class="sd">        :param device:                          If equal to &#39;cpu&#39; runs on the CPU otherwise on GPU</span>
<span class="sd">        :param multi_gpu:                       If True, runs on all available devices</span>
<span class="sd">        :param model_checkpoints_location:      If set to &#39;s3&#39; saves the Checkpoints in AWS S3</span>
<span class="sd">                                                otherwise saves the Checkpoints Locally</span>
<span class="sd">        :param overwrite_local_checkpoint:      If set to False keeps the current local checkpoint when importing</span>
<span class="sd">                                                checkpoint from cloud service, otherwise overwrites the local checkpoints file</span>
<span class="sd">        :param ckpt_name:                       The Checkpoint to Load</span>
<span class="sd">        :ckpt_root_dir:                         Local root directory path where all experiment logging directories will</span>
<span class="sd">                                                 reside. When none is give, it is assumed that</span>
<span class="sd">                                                 pkg_resources.resource_filename(&#39;checkpoints&#39;, &quot;&quot;) exists and will be used.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># SET THE EMPTY PROPERTIES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_param_groups</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_prediction_callback</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># SET THE DEFAULT PROPERTIES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">half_precision</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_backbone</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_only</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_ckpt_folder_name</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_weight_averaging</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">average_model_checkpoint_filename</span> <span class="o">=</span> <span class="s1">&#39;average_model.pth&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">external_checkpoint_path</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strict_load</span> <span class="o">=</span> <span class="n">StrictLoad</span><span class="o">.</span><span class="n">ON</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_ema_as_net</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># DETERMINE THE LOCATION OF THE LOSS AND ACCURACY IN THE RESULTS TUPLE OUTPUTED BY THE TEST</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_idx_in_results_tuple</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acc_idx_in_results_tuple</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="c1"># METRICS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># SETTING THE PROPERTIES FROM THE CONSTRUCTOR</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">experiment_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ckpt_name</span> <span class="o">=</span> <span class="n">ckpt_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">overwrite_local_checkpoint</span> <span class="o">=</span> <span class="n">overwrite_local_checkpoint</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_checkpoints_location</span> <span class="o">=</span> <span class="n">model_checkpoints_location</span>

        <span class="c1"># CREATING THE LOGGING DIR BASED ON THE INPUT PARAMS TO PREVENT OVERWRITE OF LOCAL VERSION</span>
        <span class="k">if</span> <span class="n">ckpt_root_dir</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_root_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">pkg_resources</span><span class="o">.</span><span class="n">resource_exists</span><span class="p">(</span><span class="s2">&quot;checkpoints&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span> <span class="o">=</span> <span class="n">pkg_resources</span><span class="o">.</span><span class="n">resource_filename</span><span class="p">(</span><span class="s1">&#39;checkpoints&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Illegal checkpoints directory: pass ckpt_root_dir that exists, or add &#39;checkpoints&#39; to&quot;</span>
                             <span class="s2">&quot;resources.&quot;</span><span class="p">)</span>

        <span class="c1"># INITIALIZE THE DEVICE FOR THE MODEL</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_device</span><span class="p">(</span><span class="n">requested_device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">requested_multi_gpu</span><span class="o">=</span><span class="n">multi_gpu</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">post_prediction_callback</span> <span class="o">=</span> <span class="n">post_prediction_callback</span>
        <span class="c1"># SET THE DEFAULTS</span>
        <span class="c1"># TODO: SET DEFAULT TRAINING PARAMS FOR EACH TASK</span>

        <span class="n">default_results_titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Train Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Train Acc&#39;</span><span class="p">,</span> <span class="s1">&#39;Train Top5&#39;</span><span class="p">,</span> <span class="s1">&#39;Valid Loss&#39;</span><span class="p">,</span> <span class="s1">&#39;Valid Acc&#39;</span><span class="p">,</span> <span class="s1">&#39;Valid Top5&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_titles</span> <span class="o">=</span> <span class="n">default_results_titles</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_idx_in_results_tuple</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acc_idx_in_results_tuple</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
        <span class="n">default_train_metrics</span><span class="p">,</span> <span class="n">default_valid_metrics</span> <span class="o">=</span> <span class="n">MetricCollection</span><span class="p">([</span><span class="n">Accuracy</span><span class="p">(),</span> <span class="n">Top5</span><span class="p">()]),</span> <span class="n">MetricCollection</span><span class="p">(</span>
            <span class="p">[</span><span class="n">Accuracy</span><span class="p">(),</span> <span class="n">Top5</span><span class="p">()])</span>

        <span class="n">default_loss_logging_items_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Loss&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span> <span class="o">=</span> <span class="n">default_train_metrics</span><span class="p">,</span> <span class="n">default_valid_metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">=</span> <span class="n">default_loss_logging_items_names</span>

<div class="viewcode-block" id="SgModel.connect_dataset_interface"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.connect_dataset_interface">[docs]</a>    <span class="nd">@resolve_param</span><span class="p">(</span><span class="s1">&#39;dataset_interface&#39;</span><span class="p">,</span> <span class="n">DatasetsFactory</span><span class="p">())</span>
    <span class="k">def</span> <span class="nf">connect_dataset_interface</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset_interface</span><span class="p">:</span> <span class="n">DatasetInterface</span><span class="p">,</span> <span class="n">data_loader_num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param dataset_interface: DatasetInterface object</span>
<span class="sd">        :param data_loader_num_workers: The number of threads to initialize the Data Loaders with</span>
<span class="sd">            The dataset to be connected</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span> <span class="o">=</span> <span class="n">dataset_interface</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span><span class="o">.</span><span class="n">get_data_loaders</span><span class="p">(</span><span class="n">batch_size_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span><span class="p">,</span>
                                                    <span class="n">num_workers</span><span class="o">=</span><span class="n">data_loader_num_workers</span><span class="p">,</span>
                                                    <span class="n">distributed_sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span><span class="o">.</span><span class="n">get_dataset_params</span><span class="p">()</span></div>

    <span class="c1"># FIXME - we need to resolve flake8&#39;s &#39;function is too complex&#39; for this function</span>
<div class="viewcode-block" id="SgModel.build_model"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.build_model">[docs]</a>    <span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>  <span class="c1"># noqa: C901 - too complex</span>
                    <span class="n">architecture</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">],</span>
                    <span class="n">arch_params</span><span class="o">=</span><span class="p">{},</span> <span class="n">checkpoint_params</span><span class="o">=</span><span class="p">{},</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param architecture:               Defines the network&#39;s architecture from models/ALL_ARCHITECTURES</span>
<span class="sd">        :param arch_params:                Architecture H.P. e.g.: block, num_blocks, num_classes, etc.</span>
<span class="sd">        :param checkpoint_params:          Dictionary like object with the following key:values:</span>

<span class="sd">            load_checkpoint:            Load a pre-trained checkpoint</span>
<span class="sd">            strict_load:                See StrictLoad class documentation for details.</span>
<span class="sd">            source_ckpt_folder_name:    folder name to load the checkpoint from (self.experiment_name if none is given)</span>
<span class="sd">            load_weights_only:          loads only the weight from the checkpoint and zeroize the training params</span>
<span class="sd">            load_backbone:              loads the provided checkpoint to self.net.backbone instead of self.net</span>
<span class="sd">            external_checkpoint_path:   The path to the external checkpoint to be loaded. Can be absolute or relative</span>
<span class="sd">                                               (ie: path/to/checkpoint.pth). If provided, will automatically attempt to</span>
<span class="sd">                                               load the checkpoint even if the load_checkpoint flag is not provided.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s1">&#39;num_classes&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">arch_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">,</span> <span class="s1">&#39;Number of classes not defined in arch params and dataset is not defined&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">arch_params</span><span class="p">[</span><span class="s1">&#39;num_classes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">HpmStruct</span><span class="p">(</span><span class="o">**</span><span class="n">arch_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">HpmStruct</span><span class="p">(</span><span class="o">**</span><span class="n">checkpoint_params</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instantiate_net</span><span class="p">(</span><span class="n">architecture</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="p">,</span> <span class="n">checkpoint_params</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># SAVE THE ARCHITECTURE FOR NEURAL ARCHITECTURE SEARCH</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">structure</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="s1">&#39;structure&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">architecture</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_net_to_device</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_load_checkpoint_to_model</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_set_ckpt_loading_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets checkpoint loading related attributes according to self.checkpoint_params</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">strict_load</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;strict_load&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="n">StrictLoad</span><span class="o">.</span><span class="n">ON</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_ema_as_net</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;load_ema_as_net&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_ckpt_folder_name</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;source_ckpt_folder_name&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;load_checkpoint&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_backbone</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;load_backbone&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">external_checkpoint_path</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;external_checkpoint_path&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_checkpoint_path</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_only</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;load_weights_only&#39;</span><span class="p">,</span>
                                                          <span class="n">default_val</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_net_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Manipulates self.net according to self.multi_gpu</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># FOR MULTI-GPU TRAINING (not distributed)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="n">sync_bn</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="p">,</span> <span class="s1">&#39;sync_bn&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="n">sync_bn</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;DDP - Using Sync Batch Norm... Training time will be affected accordingly&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="o">.</span><span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="n">local_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span>
                                                                 <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">local_rank</span><span class="p">],</span>
                                                                 <span class="n">output_device</span><span class="o">=</span><span class="n">local_rank</span><span class="p">,</span>
                                                                 <span class="n">find_unused_parameters</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">WrappedModel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">silent_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        train_epoch - A single epoch training procedure</span>
<span class="sd">            :param optimizer:   The optimizer for the network</span>
<span class="sd">            :param epoch:       The current epoch</span>
<span class="sd">            :param silent_mode: No verbosity</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># SET THE MODEL IN training STATE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="c1"># THE DISABLE FLAG CONTROLS WHETHER THE PROGRESS BAR IS SILENT OR PRINTS THE LOGS</span>
        <span class="n">progress_bar_train_loader</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">bar_format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{l_bar}{bar:10}{r_bar}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dynamic_ncols</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">disable</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">)</span>
        <span class="n">progress_bar_train_loader</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># RESET/INIT THE METRIC LOGGERS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss_avg_meter</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">AverageMeter</span><span class="p">()</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">PhaseContext</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                               <span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span>
                               <span class="n">metrics_compute_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span>
                               <span class="n">loss_avg_meter</span><span class="o">=</span><span class="n">loss_avg_meter</span><span class="p">,</span>
                               <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">,</span>
                               <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                               <span class="n">lr_warmup_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">lr_warmup_epochs</span><span class="p">,</span>
                               <span class="n">sg_logger</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch_items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">progress_bar_train_loader</span><span class="p">):</span>
            <span class="n">batch_items</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">tensor_container_to_device</span><span class="p">(</span><span class="n">batch_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">additional_batch_items</span> <span class="o">=</span> <span class="n">sg_model_utils</span><span class="o">.</span><span class="n">unpack_batch_items</span><span class="p">(</span><span class="n">batch_items</span><span class="p">)</span>
            <span class="c1"># AUTOCAST IS ENABLED ONLY IF self.training_params.mixed_precision - IF enabled=False AUTOCAST HAS NO EFFECT</span>
            <span class="k">with</span> <span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">mixed_precision</span><span class="p">):</span>
                <span class="c1"># FORWARD PASS TO GET NETWORK&#39;S PREDICTIONS</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

                <span class="c1"># COMPUTE THE LOSS FOR BACK PROP + EXTRA METRICS COMPUTED DURING THE LOSS FORWARD PASS</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">loss_log_items</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_losses</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>

            <span class="n">context</span><span class="o">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                                   <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                   <span class="n">preds</span><span class="o">=</span><span class="n">outputs</span><span class="p">,</span>
                                   <span class="n">target</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span>
                                   <span class="n">loss_log_items</span><span class="o">=</span><span class="n">loss_log_items</span><span class="p">,</span>
                                   <span class="o">**</span><span class="n">additional_batch_items</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TRAIN_BATCH_END</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

            <span class="c1"># LOG LR THAT WILL BE USED IN CURRENT EPOCH AND AFTER FIRST WARMUP/LR_SCHEDULER UPDATE BEFORE WEIGHT UPDATE</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span> <span class="ow">and</span> <span class="n">batch_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_write_lrs</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">backward_step</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

            <span class="c1"># COMPUTE THE RUNNING USER METRICS AND LOSS RUNNING ITEMS. RESULT TUPLE IS THEIR CONCATENATION.</span>
            <span class="n">logging_values</span> <span class="o">=</span> <span class="n">loss_avg_meter</span><span class="o">.</span><span class="n">average</span> <span class="o">+</span> <span class="n">get_metrics_results_tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">)</span>
            <span class="n">gpu_memory_utilization</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_cached</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1E9</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>

            <span class="c1"># RENDER METRICS PROGRESS</span>
            <span class="n">pbar_message_dict</span> <span class="o">=</span> <span class="n">get_train_loop_description_dict</span><span class="p">(</span><span class="n">logging_values</span><span class="p">,</span>
                                                                <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span>
                                                                <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">,</span>
                                                                <span class="n">gpu_mem</span><span class="o">=</span><span class="n">gpu_memory_utilization</span><span class="p">)</span>

            <span class="n">progress_bar_train_loader</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="o">**</span><span class="n">pbar_message_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">logging_values</span>

    <span class="k">def</span> <span class="nf">_get_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">targets</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">]:</span>
        <span class="c1"># GET THE OUTPUT OF THE LOSS FUNCTION</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">loss_logging_items</span> <span class="o">=</span> <span class="n">loss</span>
            <span class="c1"># IF ITS NOT A TUPLE THE LOGGING ITEMS CONTAIN ONLY THE LOSS FOR BACKPROP (USER DEFINED LOSS RETURNS SCALAR)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_logging_items</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">loss_logging_items</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Loss output length must match loss_logging_items_names. Got &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">loss_logging_items</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;, and &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">)))</span>
        <span class="c1"># RETURN AND THE LOSS LOGGING ITEMS COMPUTED DURING LOSS FORWARD PASS</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">loss_logging_items</span>

<div class="viewcode-block" id="SgModel.backward_step"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.backward_step">[docs]</a>    <span class="k">def</span> <span class="nf">backward_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context</span><span class="p">:</span> <span class="n">PhaseContext</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run backprop on the loss and perform a step</span>
<span class="sd">        :param loss: The value computed by the loss function</span>
<span class="sd">        :param optimizer: An object that can perform a gradient step and zeroize model gradient</span>
<span class="sd">        :param epoch: number of epoch the training is on</span>
<span class="sd">        :param batch_idx: number of iteration inside the current epoch</span>
<span class="sd">        :param context: current phase context</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># SCALER IS ENABLED ONLY IF self.training_params.mixed_precision=True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># APPLY GRADIENT CLIPPING IF REQUIRED</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">clip_grad_norm</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">clip_grad_norm</span><span class="p">)</span>

        <span class="c1"># ACCUMULATE GRADIENT FOR X BATCHES BEFORE OPTIMIZING</span>
        <span class="n">integrated_batches_num</span> <span class="o">=</span> <span class="n">batch_idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">integrated_batches_num</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_accumulate</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># SCALER IS ENABLED ONLY IF self.training_params.mixed_precision=True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="n">integrated_batches_num</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">))</span>

            <span class="c1"># RUN PHASE CALLBACKS</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TRAIN_BATCH_STEP</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span></div>

<div class="viewcode-block" id="SgModel.save_checkpoint"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.save_checkpoint">[docs]</a>    <span class="k">def</span> <span class="nf">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">validation_results_tuple</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                        <span class="n">context</span><span class="p">:</span> <span class="n">PhaseContext</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the current state dict as latest (always), best (if metric was improved), epoch# (if determined in training</span>
<span class="sd">        params)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># WHEN THE validation_results_tuple IS NONE WE SIMPLY SAVE THE state_dict AS LATEST AND Return</span>
        <span class="k">if</span> <span class="n">validation_results_tuple</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;ckpt_latest_weights_only.pth&#39;</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;net&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()},</span>
                                          <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># COMPUTE THE CURRENT metric</span>
        <span class="c1"># IF idx IS A LIST - SUM ALL THE VALUES STORED IN THE LIST&#39;S INDICES</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">validation_results_tuple</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_idx_in_results_tuple</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">metric_idx_in_results_tuple</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> \
            <span class="nb">sum</span><span class="p">([</span><span class="n">validation_results_tuple</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_idx_in_results_tuple</span><span class="p">])</span>

        <span class="c1"># BUILD THE state_dict</span>
        <span class="n">state</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;net&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">&#39;acc&#39;</span><span class="p">:</span> <span class="n">metric</span><span class="p">,</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">}</span>
        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s1">&#39;scaler_state_dict&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
            <span class="n">state</span><span class="p">[</span><span class="s1">&#39;ema_net&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="c1"># SAVES CURRENT MODEL AS ckpt_latest</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;ckpt_latest.pth&#39;</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="c1"># SAVE MODEL AT SPECIFIC EPOCHS DETERMINED BY save_ckpt_epoch_list</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">save_ckpt_epoch_list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;ckpt_epoch_</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">.pth&#39;</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="c1"># OVERRIDE THE BEST CHECKPOINT AND best_metric IF metric GOT BETTER THAN THE PREVIOUS BEST</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">metric</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">metric</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span><span class="p">):</span>
            <span class="c1"># STORE THE CURRENT metric AS BEST</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="n">metric</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s1">&#39;ckpt_best.pth&#39;</span><span class="p">,</span> <span class="n">state_dict</span><span class="o">=</span><span class="n">state</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

            <span class="c1"># RUN PHASE CALLBACKS</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">VALIDATION_END_BEST_EPOCH</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Best checkpoint overriden: validation &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_to_watch</span> <span class="o">+</span> <span class="s2">&quot;: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">metric</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">average_best_models</span><span class="p">:</span>
            <span class="n">net_for_averaging</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span>
            <span class="n">averaged_model_sd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_weight_averaging</span><span class="o">.</span><span class="n">get_average_model</span><span class="p">(</span><span class="n">net_for_averaging</span><span class="p">,</span>
                                                                              <span class="n">validation_results_tuple</span><span class="o">=</span><span class="n">validation_results_tuple</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_checkpoint</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">average_model_checkpoint_filename</span><span class="p">,</span>
                                          <span class="n">state_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;net&#39;</span><span class="p">:</span> <span class="n">averaged_model_sd</span><span class="p">},</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span></div>

    <span class="c1"># FIXME - we need to resolve flake8&#39;s &#39;function is too complex&#39; for this function</span>
<div class="viewcode-block" id="SgModel.train"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">training_params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()):</span>  <span class="c1"># noqa: C901</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        train - Trains the Model</span>

<span class="sd">        IMPORTANT NOTE: Additional batch parameters can be added as a third item (optional) if a tuple is returned by</span>
<span class="sd">          the data loaders, as dictionary. The phase context will hold the additional items, under an attribute with</span>
<span class="sd">          the same name as the key in this dictionary. Then such items can be accessed through phase callbacks.</span>


<span class="sd">            :param training_params:</span>
<span class="sd">                - `max_epochs` : int</span>

<span class="sd">                    Number of epochs to run training.</span>

<span class="sd">                - `lr_updates` : list(int)</span>

<span class="sd">                    List of fixed epoch numbers to perform learning rate updates when `lr_mode=&#39;step&#39;`.</span>

<span class="sd">                - `lr_decay_factor` : float</span>

<span class="sd">                    Decay factor to apply to the learning rate at each update when `lr_mode=&#39;step&#39;`.</span>


<span class="sd">                -  `lr_mode` : str</span>

<span class="sd">                    Learning rate scheduling policy, one of [&#39;step&#39;,&#39;poly&#39;,&#39;cosine&#39;,&#39;function&#39;]. &#39;step&#39; refers to</span>
<span class="sd">                    constant updates at epoch numbers passed through `lr_updates`. &#39;cosine&#39; refers to Cosine Anealing</span>
<span class="sd">                    policy as mentioned in https://arxiv.org/abs/1608.03983. &#39;poly&#39; refers to polynomial decrease i.e</span>
<span class="sd">                    in each epoch iteration `self.lr = self.initial_lr * pow((1.0 - (current_iter / max_iter)),</span>
<span class="sd">                    0.9)` &#39;function&#39; refers to user defined learning rate scheduling function, that is passed through</span>
<span class="sd">                    `lr_schedule_function`.</span>

<span class="sd">                - `lr_schedule_function` : Union[callable,None]</span>

<span class="sd">                    Learning rate scheduling function to be used when `lr_mode` is &#39;function&#39;.</span>

<span class="sd">                - `lr_warmup_epochs` : int (default=0)</span>

<span class="sd">                    Number of epochs for learning rate warm up - see https://arxiv.org/pdf/1706.02677.pdf (Section 2.2).</span>

<span class="sd">                - `cosine_final_lr_ratio` : float (default=0.01)</span>
<span class="sd">                    Final learning rate ratio (only relevant when `lr_mode`=&#39;cosine&#39;). The cosine starts from initial_lr and reaches</span>
<span class="sd">                     initial_lr * cosine_final_lr_ratio in last epoch</span>

<span class="sd">                - `inital_lr` : float</span>

<span class="sd">                    Initial learning rate.</span>

<span class="sd">                - `loss` : Union[nn.module, str]</span>

<span class="sd">                    Loss function for training.</span>
<span class="sd">                    One of SuperGradient&#39;s built in options:</span>

<span class="sd">                              &quot;cross_entropy&quot;: LabelSmoothingCrossEntropyLoss,</span>
<span class="sd">                              &quot;mse&quot;: MSELoss,</span>
<span class="sd">                              &quot;r_squared_loss&quot;: RSquaredLoss,</span>
<span class="sd">                              &quot;detection_loss&quot;: YoLoV3DetectionLoss,</span>
<span class="sd">                              &quot;shelfnet_ohem_loss&quot;: ShelfNetOHEMLoss,</span>
<span class="sd">                              &quot;shelfnet_se_loss&quot;: ShelfNetSemanticEncodingLoss,</span>
<span class="sd">                              &quot;yolo_v5_loss&quot;: YoLoV5DetectionLoss,</span>
<span class="sd">                              &quot;ssd_loss&quot;: SSDLoss,</span>


<span class="sd">                    or user defined nn.module loss function.</span>

<span class="sd">                    IMPORTANT: forward(...) should return a (loss, loss_items) tuple where loss is the tensor used</span>
<span class="sd">                    for backprop (i.e what your original loss function returns), and loss_items should be a tensor of</span>
<span class="sd">                    shape (n_items), of values computed during the forward pass which we desire to log over the</span>
<span class="sd">                    entire epoch. For example- the loss itself should always be logged. Another example is a scenario</span>
<span class="sd">                    where the computed loss is the sum of a few components we would like to log- these entries in</span>
<span class="sd">                    loss_items).</span>

<span class="sd">                    When training, set the loss_logging_items_names parameter in train_params to be a list of</span>
<span class="sd">                    strings, of length n_items who&#39;s ith element is the name of the ith entry in loss_items. Then</span>
<span class="sd">                    each item will be logged, rendered on tensorboard and &quot;watched&quot; (i.e saving model checkpoints</span>
<span class="sd">                    according to it).</span>

<span class="sd">                    Since running logs will save the loss_items in some internal state, it is recommended that</span>
<span class="sd">                    loss_items are detached from their computational graph for memory efficiency.</span>

<span class="sd">                - `optimizer` : Union[str, torch.optim.Optimizer]</span>

<span class="sd">                    Optimization algorithm. One of [&#39;Adam&#39;,&#39;SGD&#39;,&#39;RMSProp&#39;] corresponding to the torch.optim</span>
<span class="sd">                    optimzers implementations, or any object that implements torch.optim.Optimizer.</span>

<span class="sd">                - `criterion_params` : dict</span>

<span class="sd">                    Loss function parameters.</span>

<span class="sd">                - `optimizer_params` : dict</span>
<span class="sd">                    When `optimizer` is one of [&#39;Adam&#39;,&#39;SGD&#39;,&#39;RMSProp&#39;], it will be initialized with optimizer_params.</span>

<span class="sd">                    (see https://pytorch.org/docs/stable/optim.html for the full list of</span>
<span class="sd">                    parameters for each optimizer).</span>

<span class="sd">                - `train_metrics_list` : list(torchmetrics.Metric)</span>

<span class="sd">                    Metrics to log during training. For more information on torchmetrics see</span>
<span class="sd">                    https://torchmetrics.rtfd.io/en/latest/.</span>


<span class="sd">                - `valid_metrics_list` : list(torchmetrics.Metric)</span>

<span class="sd">                    Metrics to log during validation/testing. For more information on torchmetrics see</span>
<span class="sd">                    https://torchmetrics.rtfd.io/en/latest/.</span>


<span class="sd">                - `loss_logging_items_names` : list(str)</span>

<span class="sd">                    The list of names/titles for the outputs returned from the loss functions forward pass (reminder-</span>
<span class="sd">                    the loss function should return the tuple (loss, loss_items)). These names will be used for</span>
<span class="sd">                    logging their values.</span>

<span class="sd">                - `metric_to_watch` : str (default=&quot;Accuracy&quot;)</span>

<span class="sd">                    will be the metric which the model checkpoint will be saved according to, and can be set to any</span>
<span class="sd">                    of the following:</span>

<span class="sd">                        a metric name (str) of one of the metric objects from the valid_metrics_list</span>

<span class="sd">                        a &quot;metric_name&quot; if some metric in valid_metrics_list has an attribute component_names which</span>
<span class="sd">                        is a list referring to the names of each entry in the output metric (torch tensor of size n)</span>

<span class="sd">                        one of &quot;loss_logging_items_names&quot; i.e which will correspond to an item returned during the</span>
<span class="sd">                        loss function&#39;s forward pass.</span>

<span class="sd">                    At the end of each epoch, if a new best metric_to_watch value is achieved, the models checkpoint</span>
<span class="sd">                    is saved in YOUR_PYTHON_PATH/checkpoints/ckpt_best.pth</span>

<span class="sd">                - `greater_metric_to_watch_is_better` : bool</span>

<span class="sd">                    When choosing a model&#39;s checkpoint to be saved, the best achieved model is the one that maximizes the</span>
<span class="sd">                     metric_to_watch when this parameter is set to True, and a one that minimizes it otherwise.</span>

<span class="sd">                - `ema` : bool (default=False)</span>

<span class="sd">                    Whether to use Model Exponential Moving Average (see</span>
<span class="sd">                    https://github.com/rwightman/pytorch-image-models ema implementation)</span>

<span class="sd">                - `batch_accumulate` : int (default=1)</span>

<span class="sd">                    Number of batches to accumulate before every backward pass.</span>

<span class="sd">                - `ema_params` : dict</span>

<span class="sd">                    Parameters for the ema model.</span>

<span class="sd">                - `zero_weight_decay_on_bias_and_bn` : bool (default=False)</span>

<span class="sd">                    Whether to apply weight decay on batch normalization parameters or not (ignored when the passed</span>
<span class="sd">                    optimizer has already been initialized).</span>


<span class="sd">                - `load_opt_params` : bool (default=True)</span>

<span class="sd">                    Whether to load the optimizers parameters as well when loading a model&#39;s checkpoint.</span>

<span class="sd">                - `run_validation_freq` : int (default=1)</span>

<span class="sd">                    The frequency in which validation is performed during training (i.e the validation is ran every</span>
<span class="sd">                     `run_validation_freq` epochs.</span>

<span class="sd">                - `save_model` : bool (default=True)</span>

<span class="sd">                    Whether to save the model checkpoints.</span>

<span class="sd">                - `silent_mode` : bool</span>

<span class="sd">                    Silents the print outs.</span>

<span class="sd">                - `mixed_precision` : bool</span>

<span class="sd">                    Whether to use mixed precision or not.</span>

<span class="sd">                - `save_ckpt_epoch_list` : list(int) (default=[])</span>

<span class="sd">                    List of fixed epoch indices the user wishes to save checkpoints in.</span>

<span class="sd">                - `average_best_models` : bool (default=False)</span>

<span class="sd">                    If set, a snapshot dictionary file and the average model will be saved / updated at every epoch</span>
<span class="sd">                    and evaluated only when training is completed. The snapshot file will only be deleted upon</span>
<span class="sd">                    completing the training. The snapshot dict will be managed on cpu.</span>

<span class="sd">                - `precise_bn` : bool (default=False)</span>

<span class="sd">                    Whether to use precise_bn calculation during the training.</span>

<span class="sd">                - `precise_bn_batch_size` : int (default=None)</span>

<span class="sd">                    The effective batch size we want to calculate the batchnorm on. For example, if we are training a model</span>
<span class="sd">                    on 8 gpus, with a batch of 128 on each gpu, a good rule of thumb would be to give it 8192</span>
<span class="sd">                    (ie: effective_batch_size * num_gpus = batch_per_gpu * num_gpus * num_gpus).</span>
<span class="sd">                    If precise_bn_batch_size is not provided in the training_params, the latter heuristic will be taken.</span>

<span class="sd">                - `seed` : int (default=42)</span>

<span class="sd">                    Random seed to be set for torch, numpy, and random. When using DDP each process will have it&#39;s seed</span>
<span class="sd">                    set to seed + rank.</span>


<span class="sd">                - `log_installed_packages` : bool (default=False)</span>

<span class="sd">                    When set, the list of all installed packages (and their versions) will be written to the tensorboard</span>
<span class="sd">                     and logfile (useful when trying to reproduce results).</span>

<span class="sd">                - `dataset_statistics` : bool (default=False)</span>

<span class="sd">                    Enable a statistic analysis of the dataset. If set to True the dataset will be analyzed and a report</span>
<span class="sd">                    will be added to the tensorboard along with some sample images from the dataset. Currently only</span>
<span class="sd">                    detection datasets are supported for analysis.</span>

<span class="sd">                -  `save_full_train_log` : bool (default=False)</span>

<span class="sd">                    When set, a full log (of all super_gradients modules, including uncaught exceptions from any other</span>
<span class="sd">                     module) of the training will be saved in the checkpoint directory under full_train_log.log</span>

<span class="sd">                -  `sg_logger` : Union[AbstractSGLogger, str] (defauls=base_sg_logger)</span>

<span class="sd">                    Define the SGLogger object for this training process. The SGLogger handles all disk writes, logs, TensorBoard, remote logging</span>
<span class="sd">                    and remote storage. By overriding the default base_sg_logger, you can change the storage location, support external monitoring and logging</span>
<span class="sd">                    or support remote storage.</span>

<span class="sd">                -   `sg_logger_params` : dict</span>

<span class="sd">                    SGLogger parameters</span>

<span class="sd">                -   `clip_grad_norm` : float</span>

<span class="sd">                    Defines a maximal L2 norm of the gradients. Values which exceed the given value will be clipped</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">global</span> <span class="n">logger</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;No model found&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Data&#39;</span><span class="p">,</span> <span class="s1">&#39;No dataset found&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="o">=</span> <span class="n">TrainingParams</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">override</span><span class="p">(</span><span class="o">**</span><span class="n">training_params</span><span class="p">)</span>

        <span class="c1"># SET RANDOM SEED</span>
        <span class="n">random_seed</span><span class="p">(</span><span class="n">is_ddp</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">silent_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">silent_mode</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span>
        <span class="c1"># METRICS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_train_metrics</span><span class="p">(</span><span class="n">train_metrics_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">train_metrics_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_valid_metrics</span><span class="p">(</span><span class="n">valid_metrics_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">valid_metrics_list</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss_logging_items_names</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">results_titles</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Train_&quot;</span> <span class="o">+</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">+</span> <span class="n">get_metrics_titles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">)]</span> <span class="o">+</span> \
                              <span class="p">[</span><span class="s2">&quot;Valid_&quot;</span> <span class="o">+</span> <span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">+</span> <span class="n">get_metrics_titles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="p">)]</span>

        <span class="c1"># Store the metric to follow (loss\accuracy) and initialize as the worst value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_to_watch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">metric_to_watch</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_idx_in_results_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">+</span> <span class="n">get_metrics_titles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="p">))</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_to_watch</span><span class="p">)</span>

        <span class="c1"># Allowing loading instantiated loss or string</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">criterion_cls</span> <span class="o">=</span> <span class="n">LOSSES</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion_cls</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">criterion_params</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">LossesFactory</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">loss</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">max_epochs</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">ema</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">precise_bn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">precise_bn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">precise_bn_batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">precise_bn_batch_size</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_accumulate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">batch_accumulate</span>
        <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
            <span class="n">ema_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">ema_params</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Using EMA with params </span><span class="si">{</span><span class="n">ema_params</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span> <span class="o">=</span> <span class="n">ModelEMA</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="o">**</span><span class="n">ema_params</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">updates</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">*</span> <span class="n">num_batches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_accumulate</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;ema_net&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;ema_net&#39;</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ema</span> <span class="o">=</span> <span class="kc">False</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;[Warning] Checkpoint does not include EMA weights, continuing training without EMA.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">run_validation_freq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">run_validation_freq</span>
        <span class="n">validation_results_tuple</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">inf_time</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">timer</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># IF THE LR MODE IS NOT DEFAULT TAKE IT FROM THE TRAINING PARAMS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">lr_mode</span>
        <span class="n">load_opt_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">load_opt_params</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="ow">or</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sg_lr_callback_cls</span> <span class="o">=</span> <span class="n">LR_SCHEDULERS_CLS_DICT</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_mode</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sg_lr_callback_cls</span><span class="p">(</span><span class="n">train_loader_len</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">),</span>
                                                           <span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span>
                                                           <span class="n">training_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">,</span>
                                                           <span class="n">update_param_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">update_param_groups</span><span class="p">,</span>
                                                           <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">lr_warmup_epochs</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warmup_callback_cls</span> <span class="o">=</span> <span class="n">LR_WARMUP_CLS_DICT</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">warmup_mode</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">warmup_callback_cls</span><span class="p">(</span><span class="n">train_loader_len</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">),</span>
                                                            <span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span>
                                                            <span class="n">training_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">,</span>
                                                            <span class="n">update_param_groups</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">update_param_groups</span><span class="p">,</span>
                                                            <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_add_metrics_update_callback</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TRAIN_BATCH_END</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_metrics_update_callback</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">VALIDATION_BATCH_END</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span><span class="n">callbacks</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_sg_logger_objects</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">dataset_statistics</span><span class="p">:</span>
                <span class="n">dataset_statistics_logger</span> <span class="o">=</span> <span class="n">DatasetStatisticsTensorboardLogger</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="p">)</span>
                <span class="n">dataset_statistics_logger</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">dataset_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_params</span><span class="p">,</span>
                                                  <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Train-set&quot;</span><span class="p">,</span> <span class="n">anchors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="n">anchors</span><span class="p">)</span>
                <span class="n">dataset_statistics_logger</span><span class="o">.</span><span class="n">analyze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_loader</span><span class="p">,</span> <span class="n">dataset_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_params</span><span class="p">,</span>
                                                  <span class="n">title</span><span class="o">=</span><span class="s2">&quot;val-set&quot;</span><span class="p">)</span>
            <span class="c1"># AVERAGE BEST 10 MODELS PARAMS</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">average_best_models</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_weight_averaging</span> <span class="o">=</span> <span class="n">ModelWeightAveraging</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span><span class="p">,</span>
                                                                   <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span><span class="p">,</span>
                                                                   <span class="n">source_ckpt_folder_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">source_ckpt_folder_name</span><span class="p">,</span>
                                                                   <span class="n">metric_to_watch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_to_watch</span><span class="p">,</span>
                                                                   <span class="n">metric_idx</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_idx_in_results_tuple</span><span class="p">,</span>
                                                                   <span class="n">load_checkpoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">,</span>
                                                                   <span class="n">model_checkpoints_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_checkpoints_location</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">save_full_train_log</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
            <span class="n">logger</span> <span class="o">=</span> <span class="n">get_logger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">,</span>
                                <span class="n">training_log_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">log_file_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;full_train_log.log&#39;</span><span class="p">))</span>
            <span class="n">sg_model_utils</span><span class="o">.</span><span class="n">log_uncaught_exceptions</span><span class="p">(</span><span class="n">logger</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_only</span><span class="p">:</span>
            <span class="c1"># WHEN STARTING TRAINING FROM SCRATCH, DO NOT LOAD OPTIMIZER PARAMS (EVEN IF LOADING BACKBONE)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">greater_metric_to_watch_is_better</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="n">load_opt_params</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">build_optimizer</span><span class="p">(</span><span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">initial_lr</span><span class="p">,</span>
                                             <span class="n">training_params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">optimizer</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">UnsupportedOptimizerFormat</span><span class="p">()</span>

        <span class="c1"># VERIFY GRADIENT CLIPPING VALUE</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">clip_grad_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">clip_grad_norm</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Params&#39;</span><span class="p">,</span> <span class="s1">&#39;Invalid clip_grad_norm&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="ow">and</span> <span class="n">load_opt_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_mixed_precision</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">mixed_precision</span><span class="p">)</span>

        <span class="n">context</span> <span class="o">=</span> <span class="n">PhaseContext</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
                               <span class="n">ckpt_dir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">,</span>
                               <span class="n">lr_warmup_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">lr_warmup_epochs</span><span class="p">,</span> <span class="n">sg_logger</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">PRE_TRAINING</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># HEADERS OF THE TRAINING PROGRESS</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">silent_mode</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Started training for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="si">}</span><span class="s1"> epochs (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="si">}</span><span class="s1">/&#39;</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s1">)</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Request to stop training has been received, stopping training&quot;</span><span class="p">)</span>
                    <span class="k">break</span>

                <span class="c1"># Phase.TRAIN_EPOCH_START</span>
                <span class="c1"># RUN PHASE CALLBACKS</span>
                <span class="n">context</span><span class="o">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TRAIN_EPOCH_START</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

                <span class="c1"># IN DDP- SET_EPOCH WILL CAUSE EVERY PROCESS TO BE EXPOSED TO THE ENTIRE DATASET BY SHUFFLING WITH A</span>
                <span class="c1"># DIFFERENT SEED EACH EPOCH START</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

                <span class="n">train_metrics_tuple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">silent_mode</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">)</span>

                <span class="c1"># Phase.TRAIN_EPOCH_END</span>
                <span class="c1"># RUN PHASE CALLBACKS</span>
                <span class="n">train_metrics_dict</span> <span class="o">=</span> <span class="n">get_metrics_dict</span><span class="p">(</span><span class="n">train_metrics_tuple</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">)</span>

                <span class="n">context</span><span class="o">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">metrics_dict</span><span class="o">=</span><span class="n">train_metrics_dict</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TRAIN_EPOCH_END</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

                <span class="c1"># CALCULATE PRECISE BATCHNORM STATS</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">precise_bn</span><span class="p">:</span>
                    <span class="n">compute_precise_bn_stats</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span>
                                             <span class="n">precise_bn_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">precise_bn_batch_size</span><span class="p">,</span>
                                             <span class="n">num_gpus</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span><span class="p">)</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                        <span class="n">compute_precise_bn_stats</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span><span class="p">,</span> <span class="n">loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_loader</span><span class="p">,</span>
                                                 <span class="n">precise_bn_batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">precise_bn_batch_size</span><span class="p">,</span>
                                                 <span class="n">num_gpus</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span><span class="p">)</span>

                <span class="c1"># model switch - we replace self.net.module with the ema model for the testing and saving part</span>
                <span class="c1"># and then switch it back before the next training epoch</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">update_attr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span>
                    <span class="n">keep_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span>

                <span class="c1"># RUN TEST ON VALIDATION SET EVERY self.run_validation_freq EPOCHS</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_validation_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                    <span class="n">validation_results_tuple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">silent_mode</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">)</span>
                    <span class="n">inf_time</span> <span class="o">=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

                    <span class="c1"># Phase.VALIDATION_EPOCH_END</span>
                    <span class="c1"># RUN PHASE CALLBACKS</span>
                    <span class="n">valid_metrics_dict</span> <span class="o">=</span> <span class="n">get_metrics_dict</span><span class="p">(</span><span class="n">validation_results_tuple</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="p">,</span>
                                                          <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">)</span>

                    <span class="n">context</span><span class="o">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">metrics_dict</span><span class="o">=</span><span class="n">valid_metrics_dict</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">VALIDATION_EPOCH_END</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">keep_model</span>

                <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
                    <span class="c1"># SAVING AND LOGGING OCCURS ONLY IN THE MAIN PROCESS (IN CASES THERE ARE SEVERAL PROCESSES - DDP)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_write_to_disk_operations</span><span class="p">(</span><span class="n">train_metrics_tuple</span><span class="p">,</span> <span class="n">validation_results_tuple</span><span class="p">,</span> <span class="n">inf_time</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span>
                                                   <span class="n">context</span><span class="p">)</span>

            <span class="c1"># Evaluating the average model and removing snapshot averaging file if training is completed</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">average_best_models</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_validate_final_average_model</span><span class="p">(</span><span class="n">cleanup_snapshots_pkl_file</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">[MODEL TRAINING EXECUTION HAS BEEN INTERRUPTED]... Please wait until SOFT-TERMINATION process &#39;</span>
                <span class="s1">&#39;finishes and saves all of the Model Checkpoints and log files before terminating...&#39;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;For HARD Termination - Stop the process again&#39;</span><span class="p">)</span>

        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
                <span class="c1"># CLEAN UP THE MULTI-GPU PROCESS GROUP WHEN DONE</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>

            <span class="c1"># PHASE.TRAIN_END</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">POST_TRAINING</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_checkpoints_location</span> <span class="o">!=</span> <span class="s1">&#39;local&#39;</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;[CLEANUP] - Saving Checkpoint files&#39;</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">upload</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>

    <span class="nd">@resolve_param</span><span class="p">(</span><span class="s1">&#39;train_metrics_list&#39;</span><span class="p">,</span> <span class="n">ListFactory</span><span class="p">(</span><span class="n">MetricsFactory</span><span class="p">()))</span>
    <span class="k">def</span> <span class="nf">_set_train_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_metrics_list</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">MetricCollection</span><span class="p">(</span><span class="n">train_metrics_list</span><span class="p">)</span>

    <span class="nd">@resolve_param</span><span class="p">(</span><span class="s1">&#39;valid_metrics_list&#39;</span><span class="p">,</span> <span class="n">ListFactory</span><span class="p">(</span><span class="n">MetricsFactory</span><span class="p">()))</span>
    <span class="k">def</span> <span class="nf">_set_valid_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">valid_metrics_list</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span> <span class="o">=</span> <span class="n">MetricCollection</span><span class="p">(</span><span class="n">valid_metrics_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_mixed_precision</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mixed_precision_enabled</span><span class="p">:</span> <span class="nb">bool</span><span class="p">):</span>
        <span class="c1"># SCALER IS ALWAYS INITIALIZED BUT IS DISABLED IF MIXED PRECISION WAS NOT SET</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span> <span class="o">=</span> <span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="n">mixed_precision_enabled</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mixed_precision_enabled</span><span class="p">:</span>
            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span> <span class="s2">&quot;mixed precision is not available for CPU&quot;</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">:</span>
                <span class="c1"># IN DATAPARALLEL MODE WE NEED TO WRAP THE FORWARD FUNCTION OF OUR MODEL SO IT WILL RUN WITH AUTOCAST.</span>
                <span class="c1"># BUT SINCE THE MODULE IS CLONED TO THE DEVICES ON EACH FORWARD CALL OF A DATAPARALLEL MODEL,</span>
                <span class="c1"># WE HAVE TO REGISTER THE WRAPPER BEFORE EVERY FORWARD CALL</span>
                <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
                    <span class="n">module</span><span class="o">.</span><span class="n">forward</span> <span class="o">=</span> <span class="n">MultiGPUModeAutocastWrapper</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">forward</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span><span class="n">hook</span><span class="o">=</span><span class="n">hook</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">:</span>
                <span class="n">scaler_state_dict</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">,</span> <span class="s1">&#39;scaler_state_dict&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">scaler_state_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s1">&#39;Mixed Precision - scaler state_dict not found in loaded model. This may case issues &#39;</span>
                        <span class="s1">&#39;with loss scaling&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">scaler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">scaler_state_dict</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_validate_final_average_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cleanup_snapshots_pkl_file</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Testing the averaged model by loading the last saved average checkpoint and running test.</span>
<span class="sd">        Will be loaded to each of DDP processes</span>
<span class="sd">        :param cleanup_pkl_file: a flag for deleting the 10 best snapshots dictionary</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;RUNNING ADDITIONAL TEST ON THE AVERAGED MODEL...&#39;</span><span class="p">)</span>

        <span class="n">keep_state_dict</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="c1"># SETTING STATE DICT TO THE AVERAGE MODEL FOR EVALUATION</span>
        <span class="n">average_model_ckpt_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">average_model_checkpoint_filename</span><span class="p">)</span>
        <span class="n">average_model_sd</span> <span class="o">=</span> <span class="n">read_ckpt_state_dict</span><span class="p">(</span><span class="n">average_model_ckpt_path</span><span class="p">)[</span><span class="s1">&#39;net&#39;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">average_model_sd</span><span class="p">)</span>
        <span class="c1"># testing the averaged model and save instead of best model if needed</span>
        <span class="n">averaged_model_results_tuple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">)</span>

        <span class="c1"># Reverting the current model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">keep_state_dict</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span><span class="p">:</span>
            <span class="c1"># Adding values to sg_logger</span>
            <span class="c1"># looping over last titles which corresponds to validation (and average model) metrics.</span>
            <span class="n">all_titles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_titles</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">averaged_model_results_tuple</span><span class="p">):]</span>
            <span class="n">result_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">all_titles</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">averaged_model_results_tuple</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span>
                           <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">averaged_model_results_tuple</span><span class="p">))}</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">tag_scalar_dict</span><span class="o">=</span><span class="n">result_dict</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">)</span>

            <span class="n">average_model_tb_titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Averaged Model &#39;</span> <span class="o">+</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">results_titles</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">averaged_model_results_tuple</span><span class="p">):]]</span>
            <span class="n">write_struct</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">average_model_tb_titles</span><span class="p">):</span>
                <span class="n">write_struct</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">: </span><span class="si">%.3f</span><span class="s1">  </span><span class="se">\n</span><span class="s1">  &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">averaged_model_results_tuple</span><span class="p">[</span><span class="n">ind</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_scalar</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">averaged_model_results_tuple</span><span class="p">[</span><span class="n">ind</span><span class="p">],</span> <span class="n">global_step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_text</span><span class="p">(</span><span class="s2">&quot;Averaged_Model_Performance&quot;</span><span class="p">,</span> <span class="n">write_struct</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cleanup_snapshots_pkl_file</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model_weight_averaging</span><span class="o">.</span><span class="n">cleanup</span><span class="p">()</span>

    <span class="c1"># FIXME - we need to resolve flake8&#39;s &#39;function is too complex&#39; for this function</span>
<div class="viewcode-block" id="SgModel.predict"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.predict">[docs]</a>    <span class="nd">@deprecated</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s1">&#39;0.1&#39;</span><span class="p">,</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;directly predict using the nn_module&quot;</span><span class="p">)</span>  <span class="c1"># noqa: C901</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">half</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">move_outputs_to_cpu</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A fast predictor for a batch of inputs</span>
<span class="sd">        :param inputs: torch.tensor or numpy.array</span>
<span class="sd">            a batch of inputs</span>
<span class="sd">        :param targets: torch.tensor()</span>
<span class="sd">            corresponding labels - if non are given - accuracy will not be computed</span>
<span class="sd">        :param verbose: bool</span>
<span class="sd">            print the results to screen</span>
<span class="sd">        :param normalize: bool</span>
<span class="sd">            If true, normalizes the tensor according to the dataloader&#39;s normalization values</span>
<span class="sd">        :param half:</span>
<span class="sd">            Performs half precision evaluation</span>
<span class="sd">        :param move_outputs_to_cpu:</span>
<span class="sd">            Moves the results from the GPU to the CPU</span>
<span class="sd">        :return: outputs, acc, net_time, gross_time</span>
<span class="sd">            networks predictions, accuracy calculation, forward pass net time, function gross time</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">transform_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Create a &#39;to_tensor&#39; transformation and a place holder of input_t</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="n">inputs_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">transform_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
            <span class="n">inputs_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>

        <span class="c1"># Create a normalization transformation</span>
        <span class="k">if</span> <span class="n">normalize</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span><span class="o">.</span><span class="n">lib_dataset_params</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span><span class="o">.</span><span class="n">lib_dataset_params</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;In </span><span class="se">\&#39;</span><span class="s1">predict()</span><span class="se">\&#39;</span><span class="s1">, Normalization is set to True while the dataset has no default &#39;</span>
                                     <span class="s1">&#39;mean &amp; std =&gt; deactivate normalization or inject it to the datasets library.&#39;</span><span class="p">)</span>
            <span class="n">transform_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">))</span>

        <span class="c1"># Compose all transformations into one</span>
        <span class="n">transformation</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">transform_list</span><span class="p">)</span>

        <span class="c1"># Transform the input</span>
        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs_t</span><span class="p">)):</span>
            <span class="n">inputs_t</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">transformation</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>

        <span class="c1"># Timer instances</span>
        <span class="n">gross_timer</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
        <span class="n">gross_timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="n">net_timer</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Set network in eval mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="c1"># Half is not supported on CPU</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">and</span> <span class="n">half</span><span class="p">:</span>
            <span class="n">half</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;NOTICE: half is set to True but is not supported on CPU ==&gt; using full precision&#39;</span><span class="p">)</span>

        <span class="c1"># Apply half precision to network and input</span>
        <span class="k">if</span> <span class="n">half</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>
            <span class="n">inputs_t</span> <span class="o">=</span> <span class="n">inputs_t</span><span class="o">.</span><span class="n">half</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># Move input to compute device</span>
            <span class="n">inputs_t</span> <span class="o">=</span> <span class="n">inputs_t</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Forward pass (timed...)</span>
            <span class="n">net_timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs_t</span><span class="p">)</span>
            <span class="n">net_time</span> <span class="o">=</span> <span class="n">net_timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">move_outputs_to_cpu</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

        <span class="n">gross_time</span> <span class="o">=</span> <span class="n">gross_timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

        <span class="c1"># Convert targets to tensor</span>
        <span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">and</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="k">else</span> <span class="n">targets</span>

        <span class="c1"># Compute accuracy</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">targets</span><span class="o">.</span><span class="n">cpu</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">acc_str</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">acc</span> <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s1">&#39;N/A&#39;</span>

        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="se">\n</span><span class="s1">Predicted </span><span class="si">%d</span><span class="s1"> examples: </span><span class="se">\n\t</span><span class="si">%.2f</span><span class="s1"> ms (gross) --&gt; </span><span class="si">%.2f</span><span class="s1"> ms (net)</span><span class="se">\n\t</span><span class="s1">With accuracy </span><span class="si">%s</span><span class="se">\n</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>
                        <span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">,</span> <span class="n">inputs_t</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">gross_time</span><span class="p">,</span> <span class="n">net_time</span><span class="p">,</span> <span class="n">acc_str</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">))</span>

        <span class="c1"># Undo the half precision</span>
        <span class="k">if</span> <span class="n">half</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">half_precision</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">net_time</span><span class="p">,</span> <span class="n">gross_time</span></div>

<div class="viewcode-block" id="SgModel.compute_model_runtime"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.compute_model_runtime">[docs]</a>    <span class="k">def</span> <span class="nf">compute_model_runtime</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dims</span><span class="p">:</span> <span class="nb">tuple</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                              <span class="n">batch_sizes</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
                              <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the &quot;atomic&quot; inference time and throughput.</span>
<span class="sd">        Atomic refers to calculating the forward pass independently, discarding effects such as data augmentation,</span>
<span class="sd">        data upload to device, multi-gpu distribution etc.</span>
<span class="sd">        :param input_dims: tuple</span>
<span class="sd">            shape of a basic input to the network (without the first index) e.g. (3, 224, 224)</span>
<span class="sd">            if None uses an input from the test loader</span>
<span class="sd">        :param batch_sizes: int or list</span>
<span class="sd">            Batch sizes for latency calculation</span>
<span class="sd">        :param verbose: bool</span>
<span class="sd">            Prints results to screen</span>
<span class="sd">        :return: log: dict</span>
<span class="sd">            Latency and throughput for each tested batch size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">input_dims</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;Must get </span><span class="se">\&#39;</span><span class="s1">input_dims</span><span class="se">\&#39;</span><span class="s1"> or connect a dataset interface&#39;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span><span class="p">,</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">),</span> \
            <span class="s1">&#39;The model is on multiple GPUs, move it to a single GPU is order to compute runtime&#39;</span>

        <span class="c1"># TRANSFER THE MODEL TO EVALUATION MODE BUT REMEMBER THE MODE TO RETURN TO</span>
        <span class="n">was_in_training_mode</span> <span class="o">=</span> <span class="kc">True</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">training</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="c1"># INITIALIZE LOGS AND PRINTS</span>
        <span class="n">timer</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">Timer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">logs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">log_print</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">35</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span> \
                    <span class="sa">f</span><span class="s2">&quot;Batch   Time per Batch  Throughput</span><span class="se">\n</span><span class="s2">&quot;</span> \
                    <span class="sa">f</span><span class="s2">&quot;size         (ms)        (im/s)</span><span class="se">\n</span><span class="s2">&quot;</span> \
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">35</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

        <span class="c1"># GET THE INPUT SHAPE FROM THE DATA LOADER IF NOT PROVIDED EXPLICITLY</span>
        <span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims</span> <span class="ow">or</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># DEFINE NUMBER ACCORDING TO DEVICE</span>
        <span class="n">repetitions</span> <span class="o">=</span> <span class="mi">200</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">else</span> <span class="mi">20</span>

        <span class="c1"># CREATE A LIST OF BATCH SIZES</span>
        <span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">batch_sizes</span><span class="p">]</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)</span> <span class="o">==</span> <span class="nb">int</span> <span class="k">else</span> <span class="n">batch_sizes</span>

        <span class="k">for</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># CREATE A RANDOM TENSOR AS INPUT</span>
                <span class="n">dummy_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">*</span><span class="n">input_dims</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># WARM UP</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
                    <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">dummy_batch</span><span class="p">)</span>

                <span class="c1"># RUN &amp; TIME</span>
                <span class="n">accumulated_time</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">repetitions</span><span class="p">):</span>
                        <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
                        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">dummy_batch</span><span class="p">)</span>
                        <span class="n">accumulated_time</span> <span class="o">+=</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

                <span class="c1"># PERFORMANCE CALCULATION</span>
                <span class="n">time_per_batch</span> <span class="o">=</span> <span class="n">accumulated_time</span> <span class="o">/</span> <span class="n">repetitions</span>
                <span class="n">throughput</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">/</span> <span class="n">time_per_batch</span>

                <span class="n">logs</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;time_per_batch&#39;</span><span class="p">:</span> <span class="n">time_per_batch</span><span class="p">,</span> <span class="s1">&#39;throughput&#39;</span><span class="p">:</span> <span class="n">throughput</span><span class="p">}</span>
                <span class="n">log_print</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_size</span><span class="si">:</span><span class="s2">4.0f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">time_per_batch</span><span class="si">:</span><span class="s2">12.1f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">throughput</span><span class="si">:</span><span class="s2">12.0f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>

            <span class="k">except</span> <span class="ne">RuntimeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># ONLY FOR THE CASE OF CUDA OUT OF MEMORY WE CATCH THE EXCEPTION AND CONTINUE THE FUNCTION</span>
                <span class="k">if</span> <span class="s1">&#39;CUDA out of memory&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">):</span>
                    <span class="n">log_print</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">batch_size</span><span class="si">:</span><span class="s2">4d</span><span class="si">}</span><span class="se">\t</span><span class="si">{</span><span class="s1">&#39;CUDA out of memory&#39;</span><span class="si">:</span><span class="s2">13s</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span>

        <span class="c1"># PRINT RESULTS</span>
        <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">log_print</span><span class="p">)</span>

        <span class="c1"># RETURN THE MODEL TO THE PREVIOUS MODE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">was_in_training_mode</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">logs</span></div>

<div class="viewcode-block" id="SgModel.get_arch_params"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.get_arch_params">[docs]</a>    <span class="k">def</span> <span class="nf">get_arch_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span></div>

<div class="viewcode-block" id="SgModel.get_structure"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.get_structure">[docs]</a>    <span class="k">def</span> <span class="nf">get_structure</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">structure</span></div>

<div class="viewcode-block" id="SgModel.get_architecture"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.get_architecture">[docs]</a>    <span class="k">def</span> <span class="nf">get_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span></div>

<div class="viewcode-block" id="SgModel.set_experiment_name"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.set_experiment_name">[docs]</a>    <span class="k">def</span> <span class="nf">set_experiment_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span> <span class="o">=</span> <span class="n">experiment_name</span></div>

<div class="viewcode-block" id="SgModel.re_build_model"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.re_build_model">[docs]</a>    <span class="k">def</span> <span class="nf">re_build_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arch_params</span><span class="o">=</span><span class="p">{}):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        arch_params : dict</span>
<span class="sd">            Architecture H.P. e.g.: block, num_blocks, num_classes, etc.</span>
<span class="sd">        :return:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="s1">&#39;num_classes&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">arch_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_interface</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">,</span> <span class="s1">&#39;Number of classes not defined in arch params and dataset is not defined&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">arch_params</span><span class="p">[</span><span class="s1">&#39;num_classes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">HpmStruct</span><span class="p">(</span><span class="o">**</span><span class="n">arch_params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="n">num_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">instantiate_net</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">architecture</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint_params</span><span class="p">)</span>
        <span class="c1"># save the architecture for neural architecture search</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span> <span class="s1">&#39;structure&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">architecture</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">structure</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;Warning: distributed training is not supported in re_build_model()&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span>
                                         <span class="n">device_ids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="k">else</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">WrappedModel</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span></div>

<div class="viewcode-block" id="SgModel.update_architecture"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.update_architecture">[docs]</a>    <span class="k">def</span> <span class="nf">update_architecture</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">structure</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        architecture : str</span>
<span class="sd">            Defines the network&#39;s architecture according to the options in models/all_architectures</span>
<span class="sd">        load_checkpoint : bool</span>
<span class="sd">            Loads a checkpoint according to experiment_name</span>
<span class="sd">        arch_params : dict</span>
<span class="sd">            Architecture H.P. e.g.: block, num_blocks, num_classes, etc.</span>
<span class="sd">        :return:</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="s1">&#39;update_structure&#39;</span><span class="p">):</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">update_structure</span><span class="p">(</span><span class="n">structure</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;architecture is not valid for NAS&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="SgModel.get_module"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.get_module">[docs]</a>    <span class="k">def</span> <span class="nf">get_module</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span></div>

<div class="viewcode-block" id="SgModel.set_module"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.set_module">[docs]</a>    <span class="k">def</span> <span class="nf">set_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">module</span></div>

    <span class="k">def</span> <span class="nf">_initialize_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">requested_device</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">requested_multi_gpu</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">MultiGPUMode</span><span class="p">,</span> <span class="nb">str</span><span class="p">]):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        _initialize_device - Initializes the device for the model - Default is CUDA</span>
<span class="sd">            :param requested_device:        Device to initialize (&#39;cuda&#39; / &#39;cpu&#39;)</span>
<span class="sd">            :param requested_multi_gpu:     Get Multiple GPU</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">requested_multi_gpu</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">requested_multi_gpu</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="p">(</span><span class="n">requested_multi_gpu</span><span class="p">)</span>

        <span class="c1"># SELECT CUDA DEVICE</span>
        <span class="k">if</span> <span class="n">requested_device</span> <span class="o">==</span> <span class="s1">&#39;cuda&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>  <span class="c1"># TODO - we may want to set the device number as well i.e. &#39;cuda:1&#39;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;CUDA DEVICE NOT FOUND... EXITING&#39;</span><span class="p">)</span>

        <span class="c1"># SELECT CPU DEVICE</span>
        <span class="k">elif</span> <span class="n">requested_device</span> <span class="o">==</span> <span class="s1">&#39;cpu&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># SELECT CUDA DEVICE BY DEFAULT IF AVAILABLE</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>

        <span class="c1"># DEFUALT IS SET TO 1 - IT IS CHANGED IF MULTI-GPU IS USED</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># IN CASE OF MULTIPLE GPUS UPDATE THE LEARNING AND DATA PARAMETERS</span>
        <span class="c1"># FIXME - CREATE A DISCUSSION ON THESE PARAMETERS - WE MIGHT WANT TO CHANGE THE WAY WE USE THE LR AND</span>
        <span class="k">if</span> <span class="n">requested_multi_gpu</span> <span class="o">!=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">OFF</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;cuda&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
                <span class="c1"># COLLECT THE AVAILABLE GPU AND COUNT THE AVAILABLE GPUS AMOUNT</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">OFF</span>
                    <span class="k">if</span> <span class="n">requested_multi_gpu</span> <span class="o">!=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span>
                        <span class="c1"># if AUTO mode was set - do not log a warning</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">[WARNING] - Tried running on multiple GPU but only a single GPU is available</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">requested_multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">env_helpers</span><span class="o">.</span><span class="n">is_distributed</span><span class="p">():</span>
                            <span class="n">requested_multi_gpu</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">requested_multi_gpu</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DATA_PARALLEL</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">=</span> <span class="n">requested_multi_gpu</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_ddp</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># MULTIPLE GPUS CAN BE ACTIVE ONLY IF A GPU IS AVAILABLE</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">=</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">OFF</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">[WARNING] - Tried running on multiple GPU but none are available =&gt; running on CPU</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_ddp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes Distributed Data Parallel</span>

<span class="sd">        Usage:</span>

<span class="sd">            python -m torch.distributed.launch --nproc_per_node=n YOUR_TRAINING_SCRIPT.py</span>
<span class="sd">            where n is the number of GPUs required, e.g., n=8</span>

<span class="sd">            Important note: (1) in distributed training it is customary to specify learning rates and batch sizes per GPU.</span>
<span class="sd">            Whatever learning rate and schedule you specify will be applied to the each GPU individually.</span>
<span class="sd">            Since gradients are passed and summed (reduced) from all to all GPUs, the effective batch size is the</span>
<span class="sd">            batch you specify times the number of GPUs. In the literature there are several &quot;best practices&quot; to set</span>
<span class="sd">            learning rates and schedules for large batch sizes.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Distributed training starting...&quot;</span><span class="p">)</span>
        <span class="n">local_rank</span> <span class="o">=</span> <span class="n">environment_config</span><span class="o">.</span><span class="n">DDP_LOCAL_RANK</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;env://&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">local_rank</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">devnull</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span> <span class="o">=</span> <span class="n">f</span>  <span class="c1"># silent all printing for non master process</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">local_rank</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="s1">&#39;cuda:</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">local_rank</span>

        <span class="c1"># MAKE ALL HIGHER-RANK GPUS SILENT (DISTRIBUTED MODE)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ddp_silent_mode</span> <span class="o">=</span> <span class="n">local_rank</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training in distributed mode... with </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">())</span><span class="si">}</span><span class="s2"> GPUs&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_switch_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_device</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">new_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># FIXME - we need to resolve flake8&#39;s &#39;function is too complex&#39; for this function</span>
    <span class="k">def</span> <span class="nf">_load_checkpoint_to_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># noqa: C901 - too complex</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copies the source checkpoint to a local folder and loads the checkpoint&#39;s data to the model using the</span>
<span class="sd">         attributes:</span>

<span class="sd">         strict:           See StrictLoad class documentation for details.</span>
<span class="sd">         load_backbone:    loads the provided checkpoint to self.net.backbone instead of self.net</span>
<span class="sd">         source_ckpt_folder_name: The folder where the checkpoint is saved. By default uses the self.experiment_name</span>

<span class="sd">        NOTE: &#39;acc&#39;, &#39;epoch&#39;, &#39;optimizer_state_dict&#39; and the logs are NOT loaded if self.zeroize_prev_train_params</span>
<span class="sd">         is True</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_set_ckpt_loading_attributes</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">external_checkpoint_path</span><span class="p">:</span>
            <span class="c1"># GET LOCAL PATH TO THE CHECKPOINT FILE FIRST</span>
            <span class="n">ckpt_local_path</span> <span class="o">=</span> <span class="n">get_ckpt_local_path</span><span class="p">(</span><span class="n">source_ckpt_folder_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">source_ckpt_folder_name</span><span class="p">,</span>
                                                  <span class="n">experiment_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
                                                  <span class="n">ckpt_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ckpt_name</span><span class="p">,</span>
                                                  <span class="n">model_checkpoints_location</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_checkpoints_location</span><span class="p">,</span>
                                                  <span class="n">external_checkpoint_path</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">external_checkpoint_path</span><span class="p">,</span>
                                                  <span class="n">overwrite_local_checkpoint</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">overwrite_local_checkpoint</span><span class="p">,</span>
                                                  <span class="n">load_weights_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">load_weights_only</span><span class="p">)</span>

            <span class="c1"># LOAD CHECKPOINT TO MODEL</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">load_checkpoint_to_model</span><span class="p">(</span><span class="n">ckpt_local_path</span><span class="o">=</span><span class="n">ckpt_local_path</span><span class="p">,</span>
                                                       <span class="n">load_backbone</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">load_backbone</span><span class="p">,</span>
                                                       <span class="n">net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">,</span>
                                                       <span class="n">strict</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">strict_load</span><span class="o">.</span><span class="n">value</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">strict_load</span><span class="p">,</span> <span class="n">StrictLoad</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">strict_load</span><span class="p">,</span>
                                                       <span class="n">load_weights_only</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">load_weights_only</span><span class="p">,</span>
                                                       <span class="n">load_ema_as_net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">load_ema_as_net</span><span class="p">)</span>

            <span class="k">if</span> <span class="s1">&#39;ema_net&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;[WARNING] Main network has been loaded from checkpoint but EMA network exists as &quot;</span>
                               <span class="s2">&quot;well. It &quot;</span>
                               <span class="s2">&quot; will only be loaded during validation when training with ema=True. &quot;</span><span class="p">)</span>

        <span class="c1"># UPDATE TRAINING PARAMS IF THEY EXIST &amp; WE ARE NOT LOADING AN EXTERNAL MODEL&#39;s WEIGHTS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_metric</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="o">-</span><span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_epoch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">_prep_for_test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">post_prediction_callback</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">test_metrics_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">loss_logging_items_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_phase_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run commands that are common to all SgModels&quot;&quot;&quot;</span>
        <span class="c1"># SET THE MODEL IN evaluation STATE</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

        <span class="c1"># IF SPECIFIED IN THE FUNCTION CALL - OVERRIDE THE self ARGUMENTS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="o">=</span> <span class="n">test_loader</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">loss</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_prediction_callback</span> <span class="o">=</span> <span class="n">post_prediction_callback</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_prediction_callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">=</span> <span class="n">loss_logging_items_names</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="o">=</span> <span class="n">test_phase_callbacks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">test_metrics_list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">MetricCollection</span><span class="p">(</span><span class="n">test_metrics_list</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_metrics_update_callback</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TEST_BATCH_END</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span> <span class="o">=</span> <span class="n">CallbackHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span><span class="p">)</span>

        <span class="c1"># WHEN TESTING WITHOUT A LOSS FUNCTION- CREATE EPOCH HEADERS FOR PRINTS</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Metrics are required to perform test. Pass them through test_metrics_list arg when &quot;</span>
                             <span class="s2">&quot;calling test or through training_params when calling train(...)&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Test dataloader is required to perform test. Make sure to either pass it through &quot;</span>
                             <span class="s2">&quot;test_loader arg or calling connect_dataset_interface upon a DatasetInterface instance &quot;</span>
                             <span class="s2">&quot;with a non empty testset attribute.&quot;</span><span class="p">)</span>

        <span class="c1"># RESET METRIC RUNNERS</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_add_metrics_update_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">:</span> <span class="n">Phase</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds MetricsUpdateCallback to be fired at phase</span>

<span class="sd">        :param phase: Phase for the metrics callback to be fired at</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">MetricsUpdateCallback</span><span class="p">(</span><span class="n">phase</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_initialize_sg_logger_objects</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialize object that collect, write to disk, monitor and store remotely all training outputs&quot;&quot;&quot;</span>
        <span class="n">sg_logger</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">,</span> <span class="s1">&#39;sg_logger&#39;</span><span class="p">)</span>

        <span class="c1"># OVERRIDE SOME PARAMETERS TO MAKE SURE THEY MATCH THE TRAINING PARAMETERS</span>
        <span class="n">general_sg_logger_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;experiment_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">experiment_name</span><span class="p">,</span>
                                    <span class="s1">&#39;storage_location&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_checkpoints_location</span><span class="p">,</span>
                                    <span class="s1">&#39;resumed&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">,</span>
                                    <span class="s1">&#39;training_params&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">,</span>
                                    <span class="s1">&#39;checkpoints_dir_path&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">sg_logger</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;sg_logger must be defined in training params (see default_training_params)&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sg_logger</span><span class="p">,</span> <span class="n">AbstractSGLogger</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span> <span class="o">=</span> <span class="n">sg_logger</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sg_logger</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">sg_logger_params</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="p">,</span> <span class="s1">&#39;sg_logger_params&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">SG_LOGGERS</span><span class="p">[</span><span class="n">sg_logger</span><span class="p">],</span> <span class="n">BaseSGLogger</span><span class="p">):</span>
                <span class="n">sg_logger_params</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">sg_logger_params</span><span class="p">,</span> <span class="o">**</span><span class="n">general_sg_logger_params</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">sg_logger</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">SG_LOGGERS</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;sg_logger not defined in SG_LOGGERS&#39;</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span> <span class="o">=</span> <span class="n">SG_LOGGERS</span><span class="p">[</span><span class="n">sg_logger</span><span class="p">](</span><span class="o">**</span><span class="n">sg_logger_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;sg_logger can be either an sg_logger name (str) or a subcalss of AbstractSGLogger&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="p">,</span> <span class="n">BaseSGLogger</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">&quot;WARNING! Using a user-defined sg_logger: files will not be automatically written to disk!</span><span class="se">\n</span><span class="s2">&quot;</span>
                           <span class="s2">&quot;Please make sure the provided sg_logger writes to disk or compose your sg_logger to BaseSGLogger&quot;</span><span class="p">)</span>

        <span class="c1"># IN CASE SG_LOGGER UPDATED THE DIR PATH</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">checkpoints_dir_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">local_dir</span><span class="p">()</span>
        <span class="n">additional_log_items</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;initial_LR&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">initial_lr</span><span class="p">,</span>
                                <span class="s1">&#39;num_devices&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_devices</span><span class="p">,</span>
                                <span class="s1">&#39;multi_gpu&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span><span class="p">),</span>
                                <span class="s1">&#39;device_type&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">}</span>

        <span class="c1"># ADD INSTALLED PACKAGE LIST + THEIR VERSIONS</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">log_installed_packages</span><span class="p">:</span>
            <span class="n">pkg_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">pkg</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">pkg</span><span class="p">),</span> <span class="n">_get_installed_distributions</span><span class="p">()))</span>
            <span class="n">additional_log_items</span><span class="p">[</span><span class="s1">&#39;installed_packages&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pkg_list</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_config</span><span class="p">(</span><span class="s2">&quot;hyper_params&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;arch_params&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">arch_params</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span>
                                                   <span class="s2">&quot;training_hyperparams&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span>
                                                   <span class="s2">&quot;dataset_params&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_params</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">,</span>
                                                   <span class="s2">&quot;additional_log_items&quot;</span><span class="p">:</span> <span class="n">additional_log_items</span><span class="p">})</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_write_to_disk_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_metrics</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">validation_results</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">,</span> <span class="n">inf_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                                  <span class="n">context</span><span class="p">:</span> <span class="n">PhaseContext</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run the various logging operations, e.g.: log file, Tensorboard, save checkpoint etc.&quot;&quot;&quot;</span>
        <span class="c1"># STORE VALUES IN A TENSORBOARD FILE</span>
        <span class="n">train_results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">train_metrics</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">validation_results</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">inf_time</span><span class="p">]</span>
        <span class="n">all_titles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">results_titles</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;Inference Time&#39;</span><span class="p">]</span>

        <span class="n">result_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">all_titles</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">train_results</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_results</span><span class="p">))}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">tag_scalar_dict</span><span class="o">=</span><span class="n">result_dict</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

        <span class="c1"># SAVE THE CHECKPOINT</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">save_model</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">validation_results</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_write_lrs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))]</span>
        <span class="n">lr_titles</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LR/Param_group_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">))]</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="p">[</span><span class="s1">&#39;LR&#39;</span><span class="p">]</span>
        <span class="n">lr_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">lr_titles</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> <span class="n">lrs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lrs</span><span class="p">))}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="o">.</span><span class="n">add_scalars</span><span class="p">(</span><span class="n">tag_scalar_dict</span><span class="o">=</span><span class="n">lr_dict</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

<div class="viewcode-block" id="SgModel.test"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.test">[docs]</a>    <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>  <span class="c1"># noqa: C901</span>
             <span class="n">test_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">loss</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">_Loss</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
             <span class="n">silent_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
             <span class="n">test_metrics_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">loss_logging_items_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics_progress_verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">test_phase_callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
             <span class="n">use_ema_net</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the model on given dataloader and metrics.</span>

<span class="sd">        :param test_loader: dataloader to perform test on.</span>
<span class="sd">        :param test_metrics_list: (list(torchmetrics.Metric)) metrics list for evaluation.</span>
<span class="sd">        :param silent_mode: (bool) controls verbosity</span>
<span class="sd">        :param metrics_progress_verbose: (bool) controls the verbosity of metrics progress (default=False). Slows down the program.</span>
<span class="sd">        :param use_ema_net (bool) whether to perform test on self.ema_model.ema (when self.ema_model.ema exists,</span>
<span class="sd">            otherwise self.net will be tested) (default=True)</span>
<span class="sd">        :return: results tuple (tuple) containing the loss items and metric values.</span>

<span class="sd">        All of the above args will override SgModel&#39;s corresponding attribute when not equal to None. Then evaluation</span>
<span class="sd">         is ran on self.test_loader with self.test_metrics.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># IN CASE TRAINING WAS PERFROMED BEFORE TEST- MAKE SURE TO TEST THE EMA MODEL (UNLESS SPECIFIED OTHERWISE BY</span>
        <span class="c1"># use_ema_net)</span>

        <span class="k">if</span> <span class="n">use_ema_net</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">keep_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span><span class="o">.</span><span class="n">ema</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_prep_for_test</span><span class="p">(</span><span class="n">test_loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span>
                            <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
                            <span class="n">test_metrics_list</span><span class="o">=</span><span class="n">test_metrics_list</span><span class="p">,</span>
                            <span class="n">loss_logging_items_names</span><span class="o">=</span><span class="n">loss_logging_items_names</span><span class="p">,</span>
                            <span class="n">test_phase_callbacks</span><span class="o">=</span><span class="n">test_phase_callbacks</span><span class="p">,</span>
                            <span class="p">)</span>

        <span class="n">test_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_loader</span><span class="p">,</span>
                                     <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span><span class="p">,</span>
                                     <span class="n">evaluation_type</span><span class="o">=</span><span class="n">EvaluationType</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span>
                                     <span class="n">silent_mode</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">,</span>
                                     <span class="n">metrics_progress_verbose</span><span class="o">=</span><span class="n">metrics_progress_verbose</span><span class="p">)</span>

        <span class="c1"># SWITCH BACK BETWEEN NETS SO AN ADDITIONAL TRAINING CAN BE DONE AFTER TEST</span>
        <span class="k">if</span> <span class="n">use_ema_net</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">ema_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">keep_model</span>

        <span class="k">return</span> <span class="n">test_results</span></div>

    <span class="k">def</span> <span class="nf">_validate_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">silent_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Runs evaluation on self.valid_loader, with self.valid_metrics.</span>

<span class="sd">        :param epoch: (int) epoch idx</span>
<span class="sd">        :param silent_mode: (bool) controls verbosity</span>

<span class="sd">        :return: results tuple (tuple) containing the loss items and metric values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">data_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_loader</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">valid_metrics</span><span class="p">,</span>
                             <span class="n">evaluation_type</span><span class="o">=</span><span class="n">EvaluationType</span><span class="o">.</span><span class="n">VALIDATION</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">silent_mode</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">)</span>

<div class="viewcode-block" id="SgModel.evaluate"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.evaluate">[docs]</a>    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span> <span class="n">metrics</span><span class="p">:</span> <span class="n">MetricCollection</span><span class="p">,</span>
                 <span class="n">evaluation_type</span><span class="p">:</span> <span class="n">EvaluationType</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">silent_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">metrics_progress_verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the model on given dataloader and metrics.</span>

<span class="sd">        :param data_loader: dataloader to perform evaluataion on</span>
<span class="sd">        :param metrics: (MetricCollection) metrics for evaluation</span>
<span class="sd">        :param evaluation_type: (EvaluationType) controls which phase callbacks will be used (for example, on batch end,</span>
<span class="sd">            when evaluation_type=EvaluationType.VALIDATION the Phase.VALIDATION_BATCH_END callbacks will be triggered)</span>
<span class="sd">        :param epoch: (int) epoch idx</span>
<span class="sd">        :param silent_mode: (bool) controls verbosity</span>
<span class="sd">        :param metrics_progress_verbose: (bool) controls the verbosity of metrics progress (default=False).</span>
<span class="sd">            Slows down the program significantly.</span>

<span class="sd">        :return: results tuple (tuple) containing the loss items and metric values.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># THE DISABLE FLAG CONTROLS WHETHER THE PROGRESS BAR IS SILENT OR PRINTS THE LOGS</span>
        <span class="n">progress_bar_data_loader</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">data_loader</span><span class="p">,</span> <span class="n">bar_format</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{l_bar}{bar:10}{r_bar}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">dynamic_ncols</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">disable</span><span class="o">=</span><span class="n">silent_mode</span><span class="p">)</span>
        <span class="n">loss_avg_meter</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">AverageMeter</span><span class="p">()</span>
        <span class="n">logging_values</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss_tuple</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">lr_warmup_epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span><span class="o">.</span><span class="n">lr_warmup_epochs</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_params</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">PhaseContext</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                               <span class="n">metrics_compute_fn</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
                               <span class="n">loss_avg_meter</span><span class="o">=</span><span class="n">loss_avg_meter</span><span class="p">,</span>
                               <span class="n">criterion</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">,</span>
                               <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                               <span class="n">lr_warmup_epochs</span><span class="o">=</span><span class="n">lr_warmup_epochs</span><span class="p">,</span>
                               <span class="n">sg_logger</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sg_logger</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">silent_mode</span><span class="p">:</span>
            <span class="c1"># PRINT TITLES</span>
            <span class="n">pbar_start_msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Validation epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">evaluation_type</span> <span class="o">==</span> <span class="n">EvaluationType</span><span class="o">.</span><span class="n">VALIDATION</span> <span class="k">else</span> <span class="s2">&quot;Test&quot;</span>
            <span class="n">progress_bar_data_loader</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="n">pbar_start_msg</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="n">batch_items</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">progress_bar_data_loader</span><span class="p">):</span>
                <span class="n">batch_items</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">tensor_container_to_device</span><span class="p">(</span><span class="n">batch_items</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">additional_batch_items</span> <span class="o">=</span> <span class="n">sg_model_utils</span><span class="o">.</span><span class="n">unpack_batch_items</span><span class="p">(</span><span class="n">batch_items</span><span class="p">)</span>

                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># STORE THE loss_items ONLY, THE 1ST RETURNED VALUE IS THE loss FOR BACKPROP DURING TRAINING</span>
                    <span class="n">loss_tuple</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_losses</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">targets</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

                <span class="n">context</span><span class="o">.</span><span class="n">update_context</span><span class="p">(</span><span class="n">batch_idx</span><span class="o">=</span><span class="n">batch_idx</span><span class="p">,</span>
                                       <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                                       <span class="n">preds</span><span class="o">=</span><span class="n">output</span><span class="p">,</span>
                                       <span class="n">target</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span>
                                       <span class="n">loss_log_items</span><span class="o">=</span><span class="n">loss_tuple</span><span class="p">,</span>
                                       <span class="o">**</span><span class="n">additional_batch_items</span><span class="p">)</span>

                <span class="c1"># TRIGGER PHASE CALLBACKS CORRESPONDING TO THE EVALUATION TYPE</span>
                <span class="k">if</span> <span class="n">evaluation_type</span> <span class="o">==</span> <span class="n">EvaluationType</span><span class="o">.</span><span class="n">VALIDATION</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">VALIDATION_BATCH_END</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">phase_callback_handler</span><span class="p">(</span><span class="n">Phase</span><span class="o">.</span><span class="n">TEST_BATCH_END</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>

                <span class="c1"># COMPUTE METRICS IF PROGRESS VERBOSITY IS SET</span>
                <span class="k">if</span> <span class="n">metrics_progress_verbose</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">silent_mode</span><span class="p">:</span>
                    <span class="c1"># COMPUTE THE RUNNING USER METRICS AND LOSS RUNNING ITEMS. RESULT TUPLE IS THEIR CONCATENATION.</span>
                    <span class="n">logging_values</span> <span class="o">=</span> <span class="n">get_logging_values</span><span class="p">(</span><span class="n">loss_avg_meter</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">)</span>
                    <span class="n">pbar_message_dict</span> <span class="o">=</span> <span class="n">get_train_loop_description_dict</span><span class="p">(</span><span class="n">logging_values</span><span class="p">,</span>
                                                                        <span class="n">metrics</span><span class="p">,</span>
                                                                        <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">)</span>

                    <span class="n">progress_bar_data_loader</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="o">**</span><span class="n">pbar_message_dict</span><span class="p">)</span>

        <span class="c1"># NEED TO COMPUTE METRICS FOR THE FIRST TIME IF PROGRESS VERBOSITY IS NOT SET</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">metrics_progress_verbose</span><span class="p">:</span>
            <span class="c1"># COMPUTE THE RUNNING USER METRICS AND LOSS RUNNING ITEMS. RESULT TUPLE IS THEIR CONCATENATION.</span>
            <span class="n">logging_values</span> <span class="o">=</span> <span class="n">get_logging_values</span><span class="p">(</span><span class="n">loss_avg_meter</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">)</span>
            <span class="n">pbar_message_dict</span> <span class="o">=</span> <span class="n">get_train_loop_description_dict</span><span class="p">(</span><span class="n">logging_values</span><span class="p">,</span>
                                                                <span class="n">metrics</span><span class="p">,</span>
                                                                <span class="bp">self</span><span class="o">.</span><span class="n">loss_logging_items_names</span><span class="p">)</span>

            <span class="n">progress_bar_data_loader</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="o">**</span><span class="n">pbar_message_dict</span><span class="p">)</span>

        <span class="c1"># TODO: SUPPORT PRINTING AP PER CLASS- SINCE THE METRICS ARE NOT HARD CODED ANYMORE (as done in</span>
        <span class="c1">#  calc_batch_prediction_accuracy_per_class in metric_utils.py), THIS IS ONLY RELEVANT WHEN CHOOSING</span>
        <span class="c1">#  DETECTIONMETRICS, WHICH ALREADY RETURN THE METRICS VALUEST HEMSELVES AND NOT THE ITEMS REQUIRED FOR SUCH</span>
        <span class="c1">#  COMPUTATION. ALSO REMOVE THE BELOW LINES BY IMPLEMENTING CRITERION AS A TORCHMETRIC.</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">multi_gpu</span> <span class="o">==</span> <span class="n">MultiGPUMode</span><span class="o">.</span><span class="n">DISTRIBUTED_DATA_PARALLEL</span><span class="p">:</span>
            <span class="n">logging_values</span> <span class="o">=</span> <span class="n">reduce_results_tuple_for_ddp</span><span class="p">(</span><span class="n">logging_values</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logging_values</span></div>

<div class="viewcode-block" id="SgModel.instantiate_net"><a class="viewcode-back" href="../../../../super_gradients.training.sg_model.html#super_gradients.training.SgModel.instantiate_net">[docs]</a>    <span class="k">def</span> <span class="nf">instantiate_net</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">architecture</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">SgModule</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">arch_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
                        <span class="n">checkpoint_params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Instantiates nn.Module according to architecture and arch_params, and handles pretrained weights and the required</span>
<span class="sd">            module manipulation (i.e head replacement).</span>

<span class="sd">        :param architecture: String, torch.nn.Module or uninstantiated SgModule class describing the netowrks architecture.</span>
<span class="sd">        :param arch_params: Architecture&#39;s parameters passed to networks c&#39;tor.</span>
<span class="sd">        :param checkpoint_params: checkpoint loading related parameters dictionary with &#39;pretrained_weights&#39; key,</span>
<span class="sd">            s.t it&#39;s value is a string describing the dataset of the pretrained weights (for example &quot;imagenent&quot;).</span>

<span class="sd">        :return: instantiated netowrk i.e torch.nn.Module, architecture_class (will be none when architecture is not str)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">pretrained_weights</span> <span class="o">=</span> <span class="n">core_utils</span><span class="o">.</span><span class="n">get_param</span><span class="p">(</span><span class="n">checkpoint_params</span><span class="p">,</span> <span class="s1">&#39;pretrained_weights&#39;</span><span class="p">,</span> <span class="n">default_val</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">pretrained_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">num_classes_new_head</span> <span class="o">=</span> <span class="n">arch_params</span><span class="o">.</span><span class="n">num_classes</span>
            <span class="n">arch_params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">PRETRAINED_NUM_CLASSES</span><span class="p">[</span><span class="n">pretrained_weights</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">architecture</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">architecture_cls</span> <span class="o">=</span> <span class="n">ARCHITECTURES</span><span class="p">[</span><span class="n">architecture</span><span class="p">]</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">architecture_cls</span><span class="p">(</span><span class="n">arch_params</span><span class="o">=</span><span class="n">arch_params</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">architecture</span><span class="p">,</span> <span class="n">SgModule</span><span class="o">.</span><span class="vm">__class__</span><span class="p">):</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">architecture</span><span class="p">(</span><span class="n">arch_params</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">architecture</span>

        <span class="k">if</span> <span class="n">pretrained_weights</span><span class="p">:</span>
            <span class="n">load_pretrained_weights</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">architecture</span><span class="p">,</span> <span class="n">pretrained_weights</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num_classes_new_head</span> <span class="o">!=</span> <span class="n">arch_params</span><span class="o">.</span><span class="n">num_classes</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">replace_head</span><span class="p">(</span><span class="n">new_num_classes</span><span class="o">=</span><span class="n">num_classes_new_head</span><span class="p">)</span>
                <span class="n">arch_params</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes_new_head</span>

        <span class="k">return</span> <span class="n">net</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, SuperGradients team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>