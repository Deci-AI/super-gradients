<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>super_gradients.training.utils package &mdash; SuperGradients 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> SuperGradients
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Welcome To SuperGradients</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="welcome.html">Fill our 4-question quick survey! We will raffle free SuperGradients swag between those who will participate -&gt; Fill Survey</a></li>
<li class="toctree-l1"><a class="reference internal" href="welcome.html#supergradients">SuperGradients</a></li>
</ul>
<p class="caption"><span class="caption-text">Technical Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.common.html">Common package</a></li>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.html">Training package</a></li>
</ul>
<p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html">What is SuperGradients?</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#introducing-the-supergradients-library">Introducing the SuperGradients library</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#integrating-your-training-code-complete-walkthrough">Integrating Your Training Code - Complete Walkthrough</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#training-parameters">Training Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#logs-and-checkpoints">Logs and Checkpoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#dataset-parameters">Dataset Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#network-architectures">Network Architectures</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#pretrained-models">Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#how-to-reproduce-our-training-recipes">How To Reproduce Our Training Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#professional-tools-integration">Professional Tools Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="user_guide.html#supergradients-faq">SuperGradients FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperGradients</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>super_gradients.training.utils package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/super_gradients.training.utils.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="super-gradients-training-utils-package">
<h1>super_gradients.training.utils package<a class="headerlink" href="#super-gradients-training-utils-package" title="Permalink to this headline"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="super_gradients.training.utils.optimizers.html">super_gradients.training.utils.optimizers package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.utils.optimizers.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.utils.optimizers.html#module-super_gradients.training.utils.optimizers.rmsprop_tf">super_gradients.training.utils.optimizers.rmsprop_tf module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.utils.optimizers.html#module-super_gradients.training.utils.optimizers">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.utils.callbacks">
<span id="super-gradients-training-utils-callbacks-module"></span><h2>super_gradients.training.utils.callbacks module<a class="headerlink" href="#module-super_gradients.training.utils.callbacks" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">Phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#Phase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.PRE_TRAINING">
<span class="sig-name descname"><span class="pre">PRE_TRAINING</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'PRE_TRAINING'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.PRE_TRAINING" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TRAIN_BATCH_END">
<span class="sig-name descname"><span class="pre">TRAIN_BATCH_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TRAIN_BATCH_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TRAIN_BATCH_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TRAIN_BATCH_STEP">
<span class="sig-name descname"><span class="pre">TRAIN_BATCH_STEP</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TRAIN_BATCH_STEP'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TRAIN_BATCH_STEP" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TRAIN_EPOCH_START">
<span class="sig-name descname"><span class="pre">TRAIN_EPOCH_START</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TRAIN_EPOCH_START'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TRAIN_EPOCH_START" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TRAIN_EPOCH_END">
<span class="sig-name descname"><span class="pre">TRAIN_EPOCH_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TRAIN_EPOCH_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TRAIN_EPOCH_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.VALIDATION_BATCH_END">
<span class="sig-name descname"><span class="pre">VALIDATION_BATCH_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'VALIDATION_BATCH_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.VALIDATION_BATCH_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.VALIDATION_EPOCH_END">
<span class="sig-name descname"><span class="pre">VALIDATION_EPOCH_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'VALIDATION_EPOCH_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.VALIDATION_EPOCH_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.VALIDATION_END_BEST_EPOCH">
<span class="sig-name descname"><span class="pre">VALIDATION_END_BEST_EPOCH</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'VALIDATION_END_BEST_EPOCH'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.VALIDATION_END_BEST_EPOCH" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TEST_BATCH_END">
<span class="sig-name descname"><span class="pre">TEST_BATCH_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TEST_BATCH_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TEST_BATCH_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.TEST_END">
<span class="sig-name descname"><span class="pre">TEST_END</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'TEST_END'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.TEST_END" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.Phase.POST_TRAINING">
<span class="sig-name descname"><span class="pre">POST_TRAINING</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'POST_TRAINING'</span></em><a class="headerlink" href="#super_gradients.training.utils.callbacks.Phase.POST_TRAINING" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ContextSgMethods">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">ContextSgMethods</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">methods</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#ContextSgMethods"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.ContextSgMethods" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class for delegating SgModel’s methods, so that only the relevant ones are (“phase wise”) are accessible.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PhaseContext">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">PhaseContext</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_compute_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_avg_meter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_log_items</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_warmup_epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sg_logger</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ddp_silent_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">architecture</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_idx_in_results_tuple</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_to_watch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_methods</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PhaseContext"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PhaseContext" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Represents the input for phase callbacks, and is constantly updated after callback calls.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PhaseContext.update_context">
<span class="sig-name descname"><span class="pre">update_context</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PhaseContext.update_context"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PhaseContext.update_context" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PhaseCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">PhaseCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PhaseCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ModelConversionCheckCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">ModelConversionCheckCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_meta_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">deci_lab_client.models.model_metadata.ModelMetadata</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#ModelConversionCheckCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.ModelConversionCheckCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>Pre-training callback that verifies model conversion to onnx given specified conversion parameters.</p>
<p>The model is converted, then inference is applied with onnx runtime.</p>
<p>Use this callback wit hthe same args as DeciPlatformCallback to prevent conversion fails at the end of training.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ModelConversionCheckCallback.model_meta_data">
<span class="sig-name descname"><span class="pre">model_meta_data</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.ModelConversionCheckCallback.model_meta_data" title="Permalink to this definition"></a></dt>
<dd><p>(ModelMetadata) model’s meta-data object.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">The</span> <span class="pre">following</span> <span class="pre">parameters</span> <span class="pre">may</span> <span class="pre">be</span> <span class="pre">passed</span> <span class="pre">as</span> <span class="pre">kwargs</span> <span class="pre">in</span> <span class="pre">order</span> <span class="pre">to</span> <span class="pre">control</span> <span class="pre">the</span> <span class="pre">conversion</span> <span class="pre">to</span> <span class="pre">onnx</span></span></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">DeciLabUploadCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_meta_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimization_request_form</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">auth_token</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ckpt_best.pth'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#DeciLabUploadCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>Post-training callback for uploading and optimizing a model.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.email">
<span class="sig-name descname"><span class="pre">email</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.email" title="Permalink to this definition"></a></dt>
<dd><p>(str) username for Deci platform.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.model_meta_data">
<span class="sig-name descname"><span class="pre">model_meta_data</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.model_meta_data" title="Permalink to this definition"></a></dt>
<dd><p>(ModelMetadata) model’s meta-data object.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.optimization_request_form">
<span class="sig-name descname"><span class="pre">optimization_request_form</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.optimization_request_form" title="Permalink to this definition"></a></dt>
<dd><p>(dict) optimization request form object.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.password">
<span class="sig-name descname"><span class="pre">password</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.password" title="Permalink to this definition"></a></dt>
<dd><p>(str) default=None, should only be used for testing.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.ckpt_name">
<span class="sig-name descname"><span class="pre">ckpt_name</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.ckpt_name" title="Permalink to this definition"></a></dt>
<dd><p>(str) default=”ckpt_best” refers to the filename of the checkpoint, inside the checkpoint directory.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">The</span> <span class="pre">following</span> <span class="pre">parameters</span> <span class="pre">may</span> <span class="pre">be</span> <span class="pre">passed</span> <span class="pre">as</span> <span class="pre">kwargs</span> <span class="pre">in</span> <span class="pre">order</span> <span class="pre">to</span> <span class="pre">control</span> <span class="pre">the</span> <span class="pre">conversion</span> <span class="pre">to</span> <span class="pre">onnx</span></span></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.log_optimization_failed">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">log_optimization_failed</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#DeciLabUploadCallback.log_optimization_failed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.log_optimization_failed" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.upload_model">
<span class="sig-name descname"><span class="pre">upload_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#DeciLabUploadCallback.upload_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.upload_model" title="Permalink to this definition"></a></dt>
<dd><p>This function will upload the trained model to the Deci Lab</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> – The resulting model from the training process</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DeciLabUploadCallback.get_optimization_status">
<span class="sig-name descname"><span class="pre">get_optimization_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimized_model_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#DeciLabUploadCallback.get_optimization_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.DeciLabUploadCallback.get_optimization_status" title="Permalink to this definition"></a></dt>
<dd><p>This function will do fetch the optimized version of the trained model and check on its benchmark status.
The status will be checked against the server every 30 seconds and the process will timeout after 30 minutes
or log about the successful optimization - whichever happens first.
:param optimized_model_name: Optimized model name
:type optimized_model_name: str</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>whether or not the optimized model has been benchmarked</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRCallbackBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">LRCallbackBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">update_param_groups</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#LRCallbackBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>Base class for hard coded learning rate scheduling regimes, implemented as callbacks.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRCallbackBase.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseContext" title="super_gradients.training.utils.callbacks.PhaseContext"><span class="pre">super_gradients.training.utils.callbacks.PhaseContext</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#LRCallbackBase.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRCallbackBase.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRCallbackBase.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseContext" title="super_gradients.training.utils.callbacks.PhaseContext"><span class="pre">super_gradients.training.utils.callbacks.PhaseContext</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#LRCallbackBase.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRCallbackBase.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRCallbackBase.update_lr">
<span class="sig-name descname"><span class="pre">update_lr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#LRCallbackBase.update_lr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRCallbackBase.update_lr" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.WarmupLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">WarmupLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#WarmupLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.WarmupLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>LR scheduling callback for linear step warmup.
LR climbs from warmup_initial_lr with even steps to initial lr. When warmup_initial_lr is None- LR climb starts from</p>
<blockquote>
<div><p>initial_lr/(1+warmup_epochs).</p>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.WarmupLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#WarmupLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.WarmupLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.WarmupLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#WarmupLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.WarmupLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.StepLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">StepLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_updates</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_decay_factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">step_lr_update_freq</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#StepLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.StepLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>Hard coded step learning rate scheduling (i.e at specific milestones).</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.StepLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#StepLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.StepLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.StepLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#StepLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.StepLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ExponentialLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">ExponentialLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_decay_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#ExponentialLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.ExponentialLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>Exponential decay learning rate scheduling. Decays the learning rate by <cite>lr_decay_factor</cite> every epoch.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ExponentialLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#ExponentialLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.ExponentialLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.ExponentialLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#ExponentialLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.ExponentialLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PolyLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">PolyLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PolyLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PolyLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>Hard coded polynomial decay learning rate scheduling (i.e at specific milestones).</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PolyLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PolyLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PolyLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PolyLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PolyLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PolyLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.CosineLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">CosineLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cosine_final_lr_ratio</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#CosineLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.CosineLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>Hard coded step Cosine anealing learning rate scheduling.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.CosineLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#CosineLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.CosineLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.CosineLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#CosineLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.CosineLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.FunctionLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">FunctionLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr_schedule_function</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#FunctionLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.FunctionLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.LRCallbackBase" title="super_gradients.training.utils.callbacks.LRCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.LRCallbackBase</span></code></a></p>
<p>Hard coded rate scheduling for user defined lr scheduling function.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.FunctionLRCallback.is_lr_scheduling_enabled">
<span class="sig-name descname"><span class="pre">is_lr_scheduling_enabled</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#FunctionLRCallback.is_lr_scheduling_enabled"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.FunctionLRCallback.is_lr_scheduling_enabled" title="Permalink to this definition"></a></dt>
<dd><p>Predicate that controls whether to perform lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.
&#64;return: bool, whether to apply lr scheduling or not.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.FunctionLRCallback.perform_scheduling">
<span class="sig-name descname"><span class="pre">perform_scheduling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#FunctionLRCallback.perform_scheduling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.FunctionLRCallback.perform_scheduling" title="Permalink to this definition"></a></dt>
<dd><p>Performs lr scheduling based on values in context.</p>
<p>&#64;param context: PhaseContext: current phase’s context.</p>
</dd></dl>

</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.IllegalLRSchedulerMetric">
<em class="property"><span class="pre">exception</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">IllegalLRSchedulerMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#IllegalLRSchedulerMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.IllegalLRSchedulerMetric" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Exception raised illegal combination of training parameters.</p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">message</span> <span class="pre">--</span> <span class="pre">explanation</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">error</span></span></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRSchedulerCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">LRSchedulerCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#LRSchedulerCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRSchedulerCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>Learning rate scheduler callback.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRSchedulerCallback.scheduler">
<span class="sig-name descname"><span class="pre">scheduler</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRSchedulerCallback.scheduler" title="Permalink to this definition"></a></dt>
<dd><p>torch.optim._LRScheduler, the learning rate scheduler to be called step() with.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.LRSchedulerCallback.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.LRSchedulerCallback.metric_name" title="Permalink to this definition"></a></dt>
<dd><p>str, (default=None) the metric name for ReduceLROnPlateau learning rate scheduler.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">When</span> <span class="pre">passing</span> <span class="pre">__call__</span> <span class="pre">a</span> <span class="pre">metrics_dict,</span> <span class="pre">with</span> <span class="pre">a</span> <span class="pre">key=self.metric_name,</span> <span class="pre">the</span> <span class="pre">value</span> <span class="pre">of</span> <span class="pre">that</span> <span class="pre">metric</span> <span class="pre">will</span> <span class="pre">monitored</span></span></dt>
<dd><p>for ReduceLROnPlateau (i.e step(metrics_dict[self.metric_name]).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.MetricsUpdateCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">MetricsUpdateCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#MetricsUpdateCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.MetricsUpdateCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.KDModelMetricsUpdateCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">KDModelMetricsUpdateCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#KDModelMetricsUpdateCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.KDModelMetricsUpdateCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.MetricsUpdateCallback" title="super_gradients.training.utils.callbacks.MetricsUpdateCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.MetricsUpdateCallback</span></code></a></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.PhaseContextTestCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">PhaseContextTestCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#PhaseContextTestCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.PhaseContextTestCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>A callback that saves the phase context the for testing.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DetectionVisualizationCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">DetectionVisualizationCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">post_prediction_callback</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback" title="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback"><span class="pre">super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_img_idx_in_batch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#DetectionVisualizationCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.DetectionVisualizationCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>A callback that adds a visualization of a batch of detection predictions to context.sg_logger
.. attribute:: freq</p>
<blockquote>
<div><p>frequency (in epochs) to perform this callback.</p>
</div></blockquote>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DetectionVisualizationCallback.batch_idx">
<span class="sig-name descname"><span class="pre">batch_idx</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DetectionVisualizationCallback.batch_idx" title="Permalink to this definition"></a></dt>
<dd><p>batch index to perform visualization for.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DetectionVisualizationCallback.classes">
<span class="sig-name descname"><span class="pre">classes</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DetectionVisualizationCallback.classes" title="Permalink to this definition"></a></dt>
<dd><p>class list of the dataset.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.DetectionVisualizationCallback.last_img_idx_in_batch">
<span class="sig-name descname"><span class="pre">last_img_idx_in_batch</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.DetectionVisualizationCallback.last_img_idx_in_batch" title="Permalink to this definition"></a></dt>
<dd><p>Last image index to add to log. (default=-1, will take entire batch).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">BinarySegmentationVisualizationCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">freq</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_img_idx_in_batch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">-</span> <span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#BinarySegmentationVisualizationCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>A callback that adds a visualization of a batch of segmentation predictions to context.sg_logger
.. attribute:: freq</p>
<blockquote>
<div><p>frequency (in epochs) to perform this callback.</p>
</div></blockquote>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback.batch_idx">
<span class="sig-name descname"><span class="pre">batch_idx</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback.batch_idx" title="Permalink to this definition"></a></dt>
<dd><p>batch index to perform visualization for.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback.last_img_idx_in_batch">
<span class="sig-name descname"><span class="pre">last_img_idx_in_batch</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.BinarySegmentationVisualizationCallback.last_img_idx_in_batch" title="Permalink to this definition"></a></dt>
<dd><p>Last image index to add to log. (default=-1, will take entire batch).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">TrainingStageSwitchCallbackBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">next_stage_start_epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#TrainingStageSwitchCallbackBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>TrainingStageSwitchCallback</p>
<p>A phase callback that is called at a specific epoch (epoch start) to support multi-stage training.
It does so by manipulating the objects inside the context.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase.next_stage_start_epoch">
<span class="sig-name descname"><span class="pre">next_stage_start_epoch</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase.next_stage_start_epoch" title="Permalink to this definition"></a></dt>
<dd><p>int, the epoch idx to apply the stage change.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase.apply_stage_change">
<span class="sig-name descname"><span class="pre">apply_stage_change</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseContext" title="super_gradients.training.utils.callbacks.PhaseContext"><span class="pre">super_gradients.training.utils.callbacks.PhaseContext</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#TrainingStageSwitchCallbackBase.apply_stage_change"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase.apply_stage_change" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>This method is called when the callback is fired on the next_stage_start_epoch,</dt><dd><p>and holds the stage change logic that should be applied to the context’s objects.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>context</strong> – PhaseContext, context of current phase</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.YoloXTrainingStageSwitchCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">YoloXTrainingStageSwitchCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">next_stage_start_epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">285</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#YoloXTrainingStageSwitchCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.YoloXTrainingStageSwitchCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase" title="super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.TrainingStageSwitchCallbackBase</span></code></a></p>
<p>Training stage switch for YoloX training.
Disables mosaic, and manipulates YoloX loss to use L1.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.YoloXTrainingStageSwitchCallback.apply_stage_change">
<span class="sig-name descname"><span class="pre">apply_stage_change</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseContext" title="super_gradients.training.utils.callbacks.PhaseContext"><span class="pre">super_gradients.training.utils.callbacks.PhaseContext</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#YoloXTrainingStageSwitchCallback.apply_stage_change"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.YoloXTrainingStageSwitchCallback.apply_stage_change" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>This method is called when the callback is fired on the next_stage_start_epoch,</dt><dd><p>and holds the stage change logic that should be applied to the context’s objects.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>context</strong> – PhaseContext, context of current phase</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.CallbackHandler">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">CallbackHandler</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callbacks</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#CallbackHandler"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.CallbackHandler" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Runs all callbacks who’s phase attribute equals to the given phase.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.CallbackHandler.callbacks">
<span class="sig-name descname"><span class="pre">callbacks</span></span><a class="headerlink" href="#super_gradients.training.utils.callbacks.CallbackHandler.callbacks" title="Permalink to this definition"></a></dt>
<dd><p>List[PhaseCallback]. Callbacks to be run.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.callbacks.TestLRCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.callbacks.</span></span><span class="sig-name descname"><span class="pre">TestLRCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr_placeholder</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/callbacks.html#TestLRCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.callbacks.TestLRCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<dl class="simple">
<dt>Phase callback that collects the learning rates in lr_placeholder at the end of each epoch (used for testing). In</dt><dd><p>the case of multiple parameter groups (i.e multiple learning rates) the learning rate is collected from the first
one. The phase is VALIDATION_EPOCH_END to ensure all lr updates have been performed before calling this callback.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.checkpoint_utils">
<span id="super-gradients-training-utils-checkpoint-utils-module"></span><h2>super_gradients.training.utils.checkpoint_utils module<a class="headerlink" href="#module-super_gradients.training.utils.checkpoint_utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.get_ckpt_local_path">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">get_ckpt_local_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source_ckpt_folder_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">experiment_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ckpt_name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_checkpoints_location</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">external_checkpoint_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_local_checkpoint</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_weights_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#get_ckpt_local_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.get_ckpt_local_path" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Gets the local path to the checkpoint file, which will be:</dt><dd><ul class="simple">
<li><p>By default: YOUR_REPO_ROOT/super_gradients/checkpoints/experiment_name.</p></li>
<li><dl class="simple">
<dt>if the checkpoint file is remotely located:</dt><dd><p>when overwrite_local_checkpoint=True then it will be saved in a temporary path which will be returned,
otherwise it will be downloaded to YOUR_REPO_ROOT/super_gradients/checkpoints/experiment_name and overwrite
YOUR_REPO_ROOT/super_gradients/checkpoints/experiment_name/ckpt_name if such file exists.</p>
</dd>
</dl>
</li>
<li><p>external_checkpoint_path when external_checkpoint_path != None</p></li>
</ul>
</dd>
</dl>
<p>&#64;param source_ckpt_folder_name: The folder where the checkpoint is saved. When set to None- uses the experiment_name.
&#64;param experiment_name: experiment name attr in sg_model
&#64;param ckpt_name: checkpoint filename
&#64;param model_checkpoints_location: S3, local ot URL
&#64;param external_checkpoint_path: full path to checkpoint file (that might be located outside of super_gradients/checkpoints directory)
&#64;param overwrite_local_checkpoint: whether to overwrite the checkpoint file with the same name when downloading from S3.
&#64;param load_weights_only: whether to load the network’s state dict only.
&#64;return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.adaptive_load_state_dict">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">adaptive_load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#adaptive_load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.adaptive_load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>Adaptively loads state_dict to net, by adapting the state_dict to net’s layer names first.</p>
<p>&#64;param net: (nn.Module) to load state_dict to
&#64;param state_dict: (dict) Chekpoint state_dict
&#64;param strict: (str) key matching strictness
&#64;return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.read_ckpt_state_dict">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">read_ckpt_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#read_ckpt_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.read_ckpt_state_dict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.adapt_state_dict_to_fit_model_layer_names">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">adapt_state_dict_to_fit_model_layer_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">callable</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#adapt_state_dict_to_fit_model_layer_names"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.adapt_state_dict_to_fit_model_layer_names" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method tries to correct the keys in the model_state_dict to fit
the ckpt in order to properly load the weights into the model. If unsuccessful - returns None</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param model_state_dict</dt>
<dd class="field-odd"><p>the model state_dict</p>
</dd>
<dt class="field-even">param source_ckpt</dt>
<dd class="field-even"><p>checkpoint dict</p>
</dd>
</dl>
<p>:param exclude                  optional list for excluded layers
:param solver:                  callable with signature (ckpt_key, ckpt_val, model_key, model_val)</p>
<blockquote>
<div><p>that returns a desired weight for ckpt_val.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>renamed checkpoint dict (if possible)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.raise_informative_runtime_error">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">raise_informative_runtime_error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exception_msg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#raise_informative_runtime_error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.raise_informative_runtime_error" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method calls “adapt_state_dict_to_fit_model_layer_names”
and enhances the exception_msg if loading the checkpoint_dict via the conversion method is possible</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.load_checkpoint_to_model">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">load_checkpoint_to_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_local_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_backbone</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_weights_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_ema_as_net</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#load_checkpoint_to_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.load_checkpoint_to_model" title="Permalink to this definition"></a></dt>
<dd><p>Loads the state dict in ckpt_local_path to net and returns the checkpoint’s state dict.</p>
<p>&#64;param load_ema_as_net: Will load the EMA inside the checkpoint file to the network when set
&#64;param ckpt_local_path: local path to the checkpoint file
&#64;param load_backbone: whether to load the checkpoint as a backbone
&#64;param net: network to load the checkpoint to
&#64;param strict:
&#64;param load_weights_only:
&#64;return:</p>
</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.MissingPretrainedWeightsException">
<em class="property"><span class="pre">exception</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">MissingPretrainedWeightsException</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">desc</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#MissingPretrainedWeightsException"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.MissingPretrainedWeightsException" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Exception raised by unsupported pretrianed model.</p>
<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">message</span> <span class="pre">--</span> <span class="pre">explanation</span> <span class="pre">of</span> <span class="pre">the</span> <span class="pre">error</span></span></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.checkpoint_utils.load_pretrained_weights">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.checkpoint_utils.</span></span><span class="sig-name descname"><span class="pre">load_pretrained_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">architecture</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pretrained_weights</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#load_pretrained_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.checkpoint_utils.load_pretrained_weights" title="Permalink to this definition"></a></dt>
<dd><p>Loads pretrained weights from the MODEL_URLS dictionary to model
&#64;param architecture: name of the model’s architecture
&#64;param model: model to load pretrinaed weights for
&#64;param pretrained_weights: name for the pretrianed weights (i.e imagenet)
&#64;return: None</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.detection_utils">
<span id="super-gradients-training-utils-detection-utils-module"></span><h2>super_gradients.training.utils.detection_utils module<a class="headerlink" href="#module-super_gradients.training.utils.detection_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">DetectionTargetsFormat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionTargetsFormat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Enum class for the different detection output formats</p>
<p>When NORMALIZED is not specified- the type refers to unnormalized image coordinates (of the bboxes).</p>
<p>For example:
LABEL_NORMALIZED_XYXY means [class_idx,x1,y1,x2,y2]</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_XYXY">
<span class="sig-name descname"><span class="pre">LABEL_XYXY</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'LABEL_XYXY'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_XYXY" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.XYXY_LABEL">
<span class="sig-name descname"><span class="pre">XYXY_LABEL</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'XYXY_LABEL'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.XYXY_LABEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_NORMALIZED_XYXY">
<span class="sig-name descname"><span class="pre">LABEL_NORMALIZED_XYXY</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'LABEL_NORMALIZED_XYXY'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_NORMALIZED_XYXY" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.NORMALIZED_XYXY_LABEL">
<span class="sig-name descname"><span class="pre">NORMALIZED_XYXY_LABEL</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'NORMALIZED_XYXY_LABEL'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.NORMALIZED_XYXY_LABEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_CXCYWH">
<span class="sig-name descname"><span class="pre">LABEL_CXCYWH</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'LABEL_CXCYWH'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_CXCYWH" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.CXCYWH_LABEL">
<span class="sig-name descname"><span class="pre">CXCYWH_LABEL</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'CXCYWH_LABEL'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.CXCYWH_LABEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_NORMALIZED_CXCYWH">
<span class="sig-name descname"><span class="pre">LABEL_NORMALIZED_CXCYWH</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'LABEL_NORMALIZED_CXCYWH'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.LABEL_NORMALIZED_CXCYWH" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionTargetsFormat.NORMALIZED_CXCYWH_LABEL">
<span class="sig-name descname"><span class="pre">NORMALIZED_CXCYWH_LABEL</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'NORMALIZED_CXCYWH_LABEL'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat.NORMALIZED_CXCYWH_LABEL" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.get_cls_posx_in_target">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">get_cls_posx_in_target</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_format</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.detection_utils.DetectionTargetsFormat" title="super_gradients.training.utils.detection_utils.DetectionTargetsFormat"><span class="pre">super_gradients.training.utils.detection_utils.DetectionTargetsFormat</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#get_cls_posx_in_target"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.get_cls_posx_in_target" title="Permalink to this definition"></a></dt>
<dd><p>Get the label of a given target
:param target_format:   Representation of the target (ex: LABEL_XYXY)
:return:                Position of the class id in a bbox</p>
<blockquote>
<div><p>ex: 0 if bbox of format label_xyxy | -1 if bbox of format xyxy_label</p>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.convert_xywh_bbox_to_xyxy">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">convert_xywh_bbox_to_xyxy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_bbox</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#convert_xywh_bbox_to_xyxy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.convert_xywh_bbox_to_xyxy" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Converts bounding box format from [x, y, w, h] to [x1, y1, x2, y2]</dt><dd><dl class="field-list simple">
<dt class="field-odd">param input_bbox</dt>
<dd class="field-odd"><p>input bbox either 2-dimensional (for all boxes of a single image) or 3-dimensional (for
boxes of a batch of images)</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>Converted bbox in same dimensions as the original</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.calculate_bbox_iou_matrix">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">calculate_bbox_iou_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x1y1x2y2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">GIoU</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">DIoU</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">CIoU</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-09</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#calculate_bbox_iou_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.calculate_bbox_iou_matrix" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>calculate iou matrix containing the iou of every couple iuo(i,j) where i is in box1 and j is in box2</dt><dd><dl class="field-list simple">
<dt class="field-odd">param box1</dt>
<dd class="field-odd"><p>a 2D tensor of boxes (shape N x 4)</p>
</dd>
<dt class="field-even">param box2</dt>
<dd class="field-even"><p>a 2D tensor of boxes (shape M x 4)</p>
</dd>
<dt class="field-odd">param x1y1x2y2</dt>
<dd class="field-odd"><p>boxes format is x1y1x2y2 (True) or xywh where xy is the center (False)</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>a 2D iou matrix (shape NxM)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.calc_bbox_iou_matrix">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">calc_bbox_iou_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#calc_bbox_iou_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.calc_bbox_iou_matrix" title="Permalink to this definition"></a></dt>
<dd><p>calculate iou for every pair of boxes in the boxes vector
:param pred: a 3-dimensional tensor containing all boxes for a batch of images [N, num_boxes, 4], where</p>
<blockquote>
<div><p>each box format is [x1,y1,x2,y2]</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a 3-dimensional matrix where M_i_j_k is the iou of box j and box k of the i’th image in the batch</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.change_bbox_bounds_for_image_size">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">change_bbox_bounds_for_image_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">boxes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#change_bbox_bounds_for_image_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.change_bbox_bounds_for_image_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">DetectionPostPredictionCallback</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionPostPredictionCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback.forward">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionPostPredictionCallback.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the output of your model</p></li>
<li><p><strong>device</strong> – the device to move all output tensors into</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list with length batch_size, each item in the list is a detections
with shape: nx6 (x1, y1, x2, y2, confidence, class) where x and y are in range [0,1]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.IouThreshold">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">IouThreshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#IouThreshold"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.IouThreshold" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.IouThreshold.MAP_05">
<span class="sig-name descname"><span class="pre">MAP_05</span></span><em class="property"> <span class="pre">=</span> <span class="pre">(0.5,</span> <span class="pre">0.5)</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.IouThreshold.MAP_05" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.IouThreshold.MAP_05_TO_095">
<span class="sig-name descname"><span class="pre">MAP_05_TO_095</span></span><em class="property"> <span class="pre">=</span> <span class="pre">(0.5,</span> <span class="pre">0.95)</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.IouThreshold.MAP_05_TO_095" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.IouThreshold.is_range">
<span class="sig-name descname"><span class="pre">is_range</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#IouThreshold.is_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.IouThreshold.is_range" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.IouThreshold.to_tensor">
<span class="sig-name descname"><span class="pre">to_tensor</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#IouThreshold.to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.IouThreshold.to_tensor" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.box_iou">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">box_iou</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#box_iou"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.box_iou" title="Permalink to this definition"></a></dt>
<dd><p>Return intersection-over-union (Jaccard index) of boxes.
Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
:param box1:
:type box1: Tensor[N, 4]
:param box2:
:type box2: Tensor[M, 4]</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>the NxM matrix containing the pairwise</dt><dd><p>IoU values for every element in boxes1 and boxes2</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>iou (Tensor[N, M])</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.non_max_suppression">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">non_max_suppression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_thres</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.6</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multi_label_per_box</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_confidence</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#non_max_suppression"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.non_max_suppression" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Performs Non-Maximum Suppression (NMS) on inference results</dt><dd><dl class="field-list simple">
<dt class="field-odd">param prediction</dt>
<dd class="field-odd"><p>raw model prediction</p>
</dd>
<dt class="field-even">param conf_thres</dt>
<dd class="field-even"><p>below the confidence threshold - prediction are discarded</p>
</dd>
<dt class="field-odd">param iou_thres</dt>
<dd class="field-odd"><p>IoU threshold for the nms algorithm</p>
</dd>
<dt class="field-even">param multi_label_per_box</dt>
<dd class="field-even"><p>whether to use re-use each box with all possible labels
(instead of the maximum confidence all confidences above threshold
will be sent to NMS); by default is set to True</p>
</dd>
<dt class="field-odd">param with_confidence</dt>
<dd class="field-odd"><p>whether to multiply objectness score with class score.
usually valid for Yolo models only.</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>(x1, y1, x2, y2, object_conf, class_conf, class)</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>nx6 (x1, y1, x2, y2, conf, cls)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>detections with shape</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.matrix_non_max_suppression">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">matrix_non_max_suppression</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf_thres</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'gaussian'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">3.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_num_of_detections</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">500</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#matrix_non_max_suppression"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.matrix_non_max_suppression" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Performs Matrix Non-Maximum Suppression (NMS) on inference results</dt><dd><p><a class="reference external" href="https://arxiv.org/pdf/1912.04488.pdf">https://arxiv.org/pdf/1912.04488.pdf</a>
:param pred: raw model prediction (in test mode) - a Tensor of shape [batch, num_predictions, 85]
where each item format is (x, y, w, h, object_conf, class_conf, … 80 classes score …)
:param conf_thres: below the confidence threshold - prediction are discarded
:param kernel: type of kernel to use [‘gaussian’, ‘linear’]
:param sigma: sigma for the gussian kernel
:param max_num_of_detections: maximum number of boxes to output
:return:  list of (x1, y1, x2, y2, object_conf, class_conf, class)</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(x1, y1, x2, y2, conf, cls)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>detections list with shape</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.NMS_Type">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">NMS_Type</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#NMS_Type"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.NMS_Type" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>Type of non max suppression algorithm that can be used for post processing detection</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.NMS_Type.ITERATIVE">
<span class="sig-name descname"><span class="pre">ITERATIVE</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'iterative'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.NMS_Type.ITERATIVE" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.NMS_Type.MATRIX">
<span class="sig-name descname"><span class="pre">MATRIX</span></span><em class="property"> <span class="pre">=</span> <span class="pre">'matrix'</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.NMS_Type.MATRIX" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.undo_image_preprocessing">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">undo_image_preprocessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">im_tensor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">numpy.ndarray</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#undo_image_preprocessing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.undo_image_preprocessing" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im_tensor</strong> – images in a batch after preprocessing for inference, RGB, (B, C, H, W)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>images in a batch in cv2 format, BGR, (B, H, W, C)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionVisualization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">DetectionVisualization</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionVisualization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionVisualization" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionVisualization.visualize_batch">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">visualize_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">image_tensor:</span> <span class="pre">torch.Tensor,</span> <span class="pre">pred_boxes:</span> <span class="pre">List[torch.Tensor],</span> <span class="pre">target_boxes:</span> <span class="pre">torch.Tensor,</span> <span class="pre">batch_name:</span> <span class="pre">Union[int,</span> <span class="pre">str],</span> <span class="pre">class_names:</span> <span class="pre">List[str],</span> <span class="pre">checkpoint_dir:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">undo_preprocessing_func:</span> <span class="pre">Callable[[torch.Tensor],</span> <span class="pre">numpy.ndarray]</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">undo_image_preprocessing&gt;,</span> <span class="pre">box_thickness:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">2,</span> <span class="pre">image_scale:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0,</span> <span class="pre">gt_alpha:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.4</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionVisualization.visualize_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionVisualization.visualize_batch" title="Permalink to this definition"></a></dt>
<dd><p>A helper function to visualize detections predicted by a network:
saves images into a given path with a name that is {batch_name}_{imade_idx_in_the_batch}.jpg, one batch per call.
Colors are generated on the fly: uniformly sampled from color wheel to support all given classes.</p>
<dl class="simple">
<dt>Adjustable:</dt><dd><ul class="simple">
<li><p>Ground truth box transparency;</p></li>
<li><p>Box width;</p></li>
<li><p>Image size (larger or smaller than what’s provided)</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image_tensor</strong> – rgb images, (B, H, W, 3)</p></li>
<li><p><strong>pred_boxes</strong> – boxes after NMS for each image in a batch, each (Num_boxes, 6),
values on dim 1 are: x1, y1, x2, y2, confidence, class</p></li>
<li><p><strong>target_boxes</strong> – (Num_targets, 6), values on dim 1 are: image id in a batch, class, x y w h
(coordinates scaled to [0, 1])</p></li>
<li><p><strong>batch_name</strong> – id of the current batch to use for image naming</p></li>
<li><p><strong>class_names</strong> – names of all classes, each on its own index</p></li>
<li><p><strong>checkpoint_dir</strong> – a path where images with boxes will be saved. if None, the result images will
be returns as a list of numpy image arrays</p></li>
<li><p><strong>undo_preprocessing_func</strong> – a function to convert preprocessed images tensor into a batch of cv2-like images</p></li>
<li><p><strong>box_thickness</strong> – box line thickness in px</p></li>
<li><p><strong>image_scale</strong> – scale of an image w.r.t. given image size,
e.g. incoming images are (320x320), use scale = 2. to preview in (640x640)</p></li>
<li><p><strong>gt_alpha</strong> – a value in [0., 1.] transparency on ground truth boxes,
0 for invisible, 1 for fully opaque</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">Anchors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">anchors_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#Anchors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A wrapper function to hold the anchors used by detection models such as Yolo</p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.stride">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">stride</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.nn.parameter.Parameter</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.anchors">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">anchors</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.nn.parameter.Parameter</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.anchors" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.anchor_grid">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">anchor_grid</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.nn.parameter.Parameter</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.anchor_grid" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.detection_layers_num">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">detection_layers_num</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.detection_layers_num" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.num_anchors">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_anchors</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.num_anchors" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.Anchors.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.detection_utils.Anchors.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.xyxy2cxcywh">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">xyxy2cxcywh</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bboxes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#xyxy2cxcywh"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.xyxy2cxcywh" title="Permalink to this definition"></a></dt>
<dd><p>Transforms bboxes from xyxy format to centerized xy wh format
:param bboxes: array, shaped (nboxes, 4)
:return: modified bboxes</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.cxcywh2xyxy">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">cxcywh2xyxy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bboxes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#cxcywh2xyxy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.cxcywh2xyxy" title="Permalink to this definition"></a></dt>
<dd><p>Transforms bboxes from centerized xy wh format to xyxy format
:param bboxes: array, shaped (nboxes, 4)
:return: modified bboxes</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.get_mosaic_coordinate">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">get_mosaic_coordinate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mosaic_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_h</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_w</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#get_mosaic_coordinate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.get_mosaic_coordinate" title="Permalink to this definition"></a></dt>
<dd><p>Returns the mosaic coordinates of final mosaic image according to mosaic image index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mosaic_index</strong> – (int) mosaic image index</p></li>
<li><p><strong>xc</strong> – (int) center x coordinate of the entire mosaic grid.</p></li>
<li><p><strong>yc</strong> – (int) center y coordinate of the entire mosaic grid.</p></li>
<li><p><strong>w</strong> – (int) width of bbox</p></li>
<li><p><strong>h</strong> – (int) height of bbox</p></li>
<li><p><strong>input_h</strong> – (int) image input height (should be 1/2 of the final mosaic output image height).</p></li>
<li><p><strong>input_w</strong> – (int) image input width (should be 1/2 of the final mosaic output image width).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(x1, y1, x2, y2), (x1s, y1s, x2s, y2s) where (x1, y1, x2, y2) are the coordinates in the final mosaic
output image, and (x1s, y1s, x2s, y2s) are the coordinates in the placed image.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.adjust_box_anns">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">adjust_box_anns</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">bbox</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padw</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">w_max</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">h_max</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#adjust_box_anns"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.adjust_box_anns" title="Permalink to this definition"></a></dt>
<dd><p>Adjusts the bbox annotations of rescaled, padded image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>bbox</strong> – (np.array) bbox to modify.</p></li>
<li><p><strong>scale_ratio</strong> – (float) scale ratio between rescale output image and original one.</p></li>
<li><p><strong>padw</strong> – (int) width padding size.</p></li>
<li><p><strong>padh</strong> – (int) height padding size.</p></li>
<li><p><strong>w_max</strong> – (int) width border.</p></li>
<li><p><strong>h_max</strong> – (int) height border</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>modified bbox (np.array)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.DetectionCollateFN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">DetectionCollateFN</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#DetectionCollateFN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.DetectionCollateFN" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Collate function for Yolox training</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.CrowdDetectionCollateFN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">CrowdDetectionCollateFN</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#CrowdDetectionCollateFN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.CrowdDetectionCollateFN" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.detection_utils.DetectionCollateFN" title="super_gradients.training.utils.detection_utils.DetectionCollateFN"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.detection_utils.DetectionCollateFN</span></code></a></p>
<p>Collate function for Yolox training with additional_batch_items that includes crowd targets</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.compute_box_area">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">compute_box_area</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#compute_box_area"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.compute_box_area" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Compute the area of one or many boxes.</dt><dd><dl class="field-list simple">
<dt class="field-odd">param box</dt>
<dd class="field-odd"><p>One or many boxes, shape = (4, ?), each box in format (x1, y1, x2, y2)</p>
</dd>
</dl>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Area of every box, shape = (1, ?)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.crowd_ioa">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">crowd_ioa</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">det_box</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crowd_box</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#crowd_ioa"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.crowd_ioa" title="Permalink to this definition"></a></dt>
<dd><p>Return intersection-over-detection_area of boxes, used for crowd ground truths.
Both sets of boxes are expected to be in (x1, y1, x2, y2) format.
:param det_box:
:type det_box: Tensor[N, 4]
:param crowd_box:
:type crowd_box: Tensor[M, 4]</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p><dl class="simple">
<dt>the NxM matrix containing the pairwise</dt><dd><p>IoA values for every element in det_box and crowd_box</p>
</dd>
</dl>
</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>crowd_ioa (Tensor[N, M])</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.compute_detection_matching">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">compute_detection_matching</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">output</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_thresholds</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">denormalize_targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crowd_targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_on_cpu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#compute_detection_matching"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.compute_detection_matching" title="Permalink to this definition"></a></dt>
<dd><p>Match predictions (NMS output) and the targets (ground truth) with respect to IoU and confidence score.
:param output:          list (of length batch_size) of Tensors of shape (num_predictions, 6)</p>
<blockquote>
<div><p>format:     (x1, y1, x2, y2, confidence, class_label) where x1,y1,x2,y2 are according to image size</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>targets</strong> – targets for all images of shape (total_num_targets, 6)
format:     (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
<li><p><strong>height</strong> – dimensions of the image</p></li>
<li><p><strong>width</strong> – dimensions of the image</p></li>
<li><p><strong>iou_thresholds</strong> – Threshold to compute the mAP</p></li>
<li><p><strong>device</strong> – Device</p></li>
<li><p><strong>crowd_targets</strong> – crowd targets for all images of shape (total_num_crowd_targets, 6)
format:     (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
<li><p><strong>top_k</strong> – Number of predictions to keep per class, ordered by confidence score</p></li>
<li><p><strong>denormalize_targets</strong> – If True, denormalize the targets and crowd_targets</p></li>
<li><p><strong>return_on_cpu</strong> – If True, the output will be returned on “CPU”, otherwise it will be returned on “device”</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><p>list of the following tensors, for every image:
:preds_matched:     Tensor of shape (num_img_predictions, n_iou_thresholds)</p>
<blockquote>
<div><p>True when prediction (i) is matched with a target with respect to the (j)th IoU threshold</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">preds_to_ignore</dt>
<dd class="field-odd"><p>Tensor of shape (num_img_predictions, n_iou_thresholds)
True when prediction (i) is matched with a crowd target with respect to the (j)th IoU threshold</p>
</dd>
<dt class="field-even">preds_scores</dt>
<dd class="field-even"><p>Tensor of shape (num_img_predictions), confidence score for every prediction</p>
</dd>
<dt class="field-odd">preds_cls</dt>
<dd class="field-odd"><p>Tensor of shape (num_img_predictions), predicted class for every prediction</p>
</dd>
<dt class="field-even">targets_cls</dt>
<dd class="field-even"><p>Tensor of shape (num_img_targets), ground truth class for every target</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.compute_img_detection_matching">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">compute_img_detection_matching</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crowd_targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">height</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_thresholds</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">denormalize_targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_on_cpu</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#compute_img_detection_matching"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.compute_img_detection_matching" title="Permalink to this definition"></a></dt>
<dd><p>Match predictions (NMS output) and the targets (ground truth) with respect to IoU and confidence score
for a given image.
:param preds:           Tensor of shape (num_img_predictions, 6)</p>
<blockquote>
<div><p>format:     (x1, y1, x2, y2, confidence, class_label) where x1,y1,x2,y2 are according to image size</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>targets</strong> – targets for this image of shape (num_img_targets, 6)
format:     (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
<li><p><strong>height</strong> – dimensions of the image</p></li>
<li><p><strong>width</strong> – dimensions of the image</p></li>
<li><p><strong>iou_thresholds</strong> – Threshold to compute the mAP</p></li>
<li><p><strong>device</strong> – </p></li>
<li><p><strong>crowd_targets</strong> – crowd targets for all images of shape (total_num_crowd_targets, 6)
format:     (index, x, y, w, h, label) where x,y,w,h are in range [0,1]</p></li>
<li><p><strong>top_k</strong> – Number of predictions to keep per class, ordered by confidence score</p></li>
<li><p><strong>device</strong> – Device</p></li>
<li><p><strong>denormalize_targets</strong> – If True, denormalize the targets and crowd_targets</p></li>
<li><p><strong>return_on_cpu</strong> – If True, the output will be returned on “CPU”, otherwise it will be returned on “device”</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="field-list simple">
<dt class="field-odd">preds_matched</dt>
<dd class="field-odd"><p>Tensor of shape (num_img_predictions, n_iou_thresholds)
True when prediction (i) is matched with a target with respect to the (j)th IoU threshold</p>
</dd>
<dt class="field-even">preds_to_ignore</dt>
<dd class="field-even"><p>Tensor of shape (num_img_predictions, n_iou_thresholds)
True when prediction (i) is matched with a crowd target with respect to the (j)th IoU threshold</p>
</dd>
<dt class="field-odd">preds_scores</dt>
<dd class="field-odd"><p>Tensor of shape (num_img_predictions), confidence score for every prediction</p>
</dd>
<dt class="field-even">preds_cls</dt>
<dd class="field-even"><p>Tensor of shape (num_img_predictions), predicted class for every prediction</p>
</dd>
<dt class="field-odd">targets_cls</dt>
<dd class="field-odd"><p>Tensor of shape (num_img_targets), ground truth class for every target</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.get_top_k_idx_per_cls">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">get_top_k_idx_per_cls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds_scores</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_cls</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">top_k</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#get_top_k_idx_per_cls"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.get_top_k_idx_per_cls" title="Permalink to this definition"></a></dt>
<dd><p>Get the indexes of all the top k predictions for every class</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preds_scores</strong> – The confidence scores, vector of shape (n_pred)</p></li>
<li><p><strong>preds_cls</strong> – The predicted class, vector of shape (n_pred)</p></li>
<li><p><strong>top_k</strong> – Number of predictions to keep per class, ordered by confidence score</p></li>
</ul>
</dd>
<dt class="field-even">Return top_k_idx</dt>
<dd class="field-even"><p>Indexes of the top k predictions. length &lt;= (k * n_unique_class)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.compute_detection_metrics">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">compute_detection_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds_matched</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_to_ignore</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_scores</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_cls</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">targets_cls</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thresholds</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_threshold</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#compute_detection_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.compute_detection_metrics" title="Permalink to this definition"></a></dt>
<dd><p>Compute the list of precision, recall, MaP and f1 for every recall IoU threshold and for every class.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>preds_matched</strong> – Tensor of shape (num_predictions, n_iou_thresholds)
True when prediction (i) is matched with a target with respect to the (j)th IoU threshold</p>
</dd>
</dl>
<dl class="simple">
<dt>:param preds_to_ignore     Tensor of shape (num_predictions, n_iou_thresholds)</dt><dd><p>True when prediction (i) is matched with a crowd target with respect to the (j)th IoU threshold</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>preds_scores</strong> – Tensor of shape (num_predictions), confidence score for every prediction</p></li>
<li><p><strong>preds_cls</strong> – Tensor of shape (num_predictions), predicted class for every prediction</p></li>
<li><p><strong>targets_cls</strong> – Tensor of shape (num_targets), ground truth class for every target box to be detected</p></li>
<li><p><strong>recall_thresholds</strong> – Recall thresholds used to compute MaP.</p></li>
<li><p><strong>score_threshold</strong> – Minimum confidence score to consider a prediction for the computation of
precision, recall and f1 (not MaP)</p></li>
<li><p><strong>device</strong> – Device</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><dl class="field-list simple">
<dt class="field-odd">ap, precision, recall, f1</dt>
<dd class="field-odd"><p>Tensors of shape (n_class, nb_iou_thrs)</p>
</dd>
<dt class="field-even">unique_classes</dt>
<dd class="field-even"><p>Vector with all unique target classes</p>
</dd>
</dl>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.detection_utils.compute_detection_metrics_per_cls">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.detection_utils.</span></span><span class="sig-name descname"><span class="pre">compute_detection_metrics_per_cls</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">preds_matched</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_to_ignore</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds_scores</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_targets</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recall_thresholds</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_threshold</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/detection_utils.html#compute_detection_metrics_per_cls"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.detection_utils.compute_detection_metrics_per_cls" title="Permalink to this definition"></a></dt>
<dd><p>Compute the list of precision, recall and MaP of a given class for every recall IoU threshold.</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param preds_matched</dt>
<dd class="field-odd"><p>Tensor of shape (num_predictions, n_iou_thresholds)
True when prediction (i) is matched with a target
with respect to the(j)th IoU threshold</p>
</dd>
</dl>
<dl class="simple">
<dt>:param preds_to_ignore     Tensor of shape (num_predictions, n_iou_thresholds)</dt><dd><p>True when prediction (i) is matched with a crowd target
with respect to the (j)th IoU threshold</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">param preds_scores</dt>
<dd class="field-odd"><p>Tensor of shape (num_predictions), confidence score for every prediction</p>
</dd>
<dt class="field-even">param n_targets</dt>
<dd class="field-even"><p>Number of target boxes of this class</p>
</dd>
<dt class="field-odd">param recall_thresholds</dt>
<dd class="field-odd"><p>Tensor of shape (max_n_rec_thresh) list of recall thresholds used to compute MaP</p>
</dd>
<dt class="field-even">param score_threshold</dt>
<dd class="field-even"><p>Minimum confidence score to consider a prediction for the computation of
precision and recall (not MaP)</p>
</dd>
<dt class="field-odd">param device</dt>
<dd class="field-odd"><p>Device</p>
</dd>
<dt class="field-even">return ap, precision, recall</dt>
<dd class="field-even"><p>Tensors of shape (nb_iou_thrs)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.distributed_training_utils">
<span id="super-gradients-training-utils-distributed-training-utils-module"></span><h2>super_gradients.training.utils.distributed_training_utils module<a class="headerlink" href="#module-super_gradients.training.utils.distributed_training_utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.distributed_all_reduce_tensor_average">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">distributed_all_reduce_tensor_average</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#distributed_all_reduce_tensor_average"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.distributed_all_reduce_tensor_average" title="Permalink to this definition"></a></dt>
<dd><p>This method performs a reduce operation on multiple nodes running distributed training
It first sums all of the results and then divides the summation
:param tensor:  The tensor to perform the reduce operation for
:param n:  Number of nodes
:return:   Averaged tensor from all of the nodes</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.reduce_results_tuple_for_ddp">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">reduce_results_tuple_for_ddp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">validation_results_tuple</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#reduce_results_tuple_for_ddp"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.reduce_results_tuple_for_ddp" title="Permalink to this definition"></a></dt>
<dd><p>Gather all validation tuples from the various devices and average them</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.MultiGPUModeAutocastWrapper">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">MultiGPUModeAutocastWrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#MultiGPUModeAutocastWrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.MultiGPUModeAutocastWrapper" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.scaled_all_reduce">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">scaled_all_reduce</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gpus</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#scaled_all_reduce"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.scaled_all_reduce" title="Permalink to this definition"></a></dt>
<dd><p>Performs the scaled all_reduce operation on the provided tensors.
The input tensors are modified in-place.
Currently supports only the sum
reduction operator.
The reduced values are scaled by the inverse size of the
process group (equivalent to num_gpus).</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.compute_precise_bn_stats">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">compute_precise_bn_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.utils.data.dataloader.DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">precise_bn_batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_gpus</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#compute_precise_bn_stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.compute_precise_bn_stats" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – The model being trained (ie: SgModel.net)</p></li>
<li><p><strong>loader</strong> – Training dataloader (ie: SgModel.train_loader)</p></li>
<li><p><strong>precise_bn_batch_size</strong> – The effective batch size we want to calculate the batchnorm on. For example, if we are training a model
on 8 gpus, with a batch of 128 on each gpu, a good rule of thumb would be to give it 8192
(ie: effective_batch_size * num_gpus = batch_per_gpu * num_gpus * num_gpus).
If precise_bn_batch_size is not provided in the training_params, the latter heuristic
will be taken.</p></li>
</ul>
</dd>
</dl>
<p>param num_gpus:                 The number of gpus we are training on</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.get_local_rank">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">get_local_rank</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#get_local_rank"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.get_local_rank" title="Permalink to this definition"></a></dt>
<dd><p>Returns the local rank if running in DDP, and 0 otherwise
:return: local rank</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.get_world_size">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">get_world_size</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#get_world_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.get_world_size" title="Permalink to this definition"></a></dt>
<dd><p>Returns the world size if running in DDP, and 1 otherwise
:return: world size</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.distributed_training_utils.wait_for_the_master">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.distributed_training_utils.</span></span><span class="sig-name descname"><span class="pre">wait_for_the_master</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">local_rank</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/distributed_training_utils.html#wait_for_the_master"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.distributed_training_utils.wait_for_the_master" title="Permalink to this definition"></a></dt>
<dd><p>Make all processes waiting for the master to do some task.</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.early_stopping">
<span id="super-gradients-training-utils-early-stopping-module"></span><h2>super_gradients.training.utils.early_stopping module<a class="headerlink" href="#module-super_gradients.training.utils.early_stopping" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.early_stopping.EarlyStop">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.early_stopping.</span></span><span class="sig-name descname"><span class="pre">EarlyStop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.callbacks.Phase" title="super_gradients.training.utils.callbacks.Phase"><span class="pre">super_gradients.training.utils.callbacks.Phase</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">monitor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'min'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_delta</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_finite</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/early_stopping.html#EarlyStop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.early_stopping.EarlyStop" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.callbacks.PhaseCallback" title="super_gradients.training.utils.callbacks.PhaseCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.callbacks.PhaseCallback</span></code></a></p>
<p>Callback to monitor a metric and stop training when it stops improving.
Inspired by pytorch_lightning.callbacks.early_stopping and tf.keras.callbacks.EarlyStopping</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.early_stopping.EarlyStop.mode_dict">
<span class="sig-name descname"><span class="pre">mode_dict</span></span><em class="property"> <span class="pre">=</span> <span class="pre">{'max':</span> <span class="pre">&lt;built-in</span> <span class="pre">method</span> <span class="pre">gt</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;,</span> <span class="pre">'min':</span> <span class="pre">&lt;built-in</span> <span class="pre">method</span> <span class="pre">lt</span> <span class="pre">of</span> <span class="pre">type</span> <span class="pre">object&gt;}</span></em><a class="headerlink" href="#super_gradients.training.utils.early_stopping.EarlyStop.mode_dict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.early_stopping.EarlyStop.supported_phases">
<span class="sig-name descname"><span class="pre">supported_phases</span></span><em class="property"> <span class="pre">=</span> <span class="pre">(&lt;Phase.VALIDATION_EPOCH_END:</span> <span class="pre">'VALIDATION_EPOCH_END'&gt;,</span> <span class="pre">&lt;Phase.TRAIN_EPOCH_END:</span> <span class="pre">'TRAIN_EPOCH_END'&gt;)</span></em><a class="headerlink" href="#super_gradients.training.utils.early_stopping.EarlyStop.supported_phases" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="super_gradients.training.utils.early_stopping.MissingMonitorKeyException">
<em class="property"><span class="pre">exception</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.early_stopping.</span></span><span class="sig-name descname"><span class="pre">MissingMonitorKeyException</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/early_stopping.html#MissingMonitorKeyException"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.early_stopping.MissingMonitorKeyException" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>Exception raised for missing monitor key in metrics_dict.</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.ema">
<span id="super-gradients-training-utils-ema-module"></span><h2>super_gradients.training.utils.ema module<a class="headerlink" href="#module-super_gradients.training.utils.ema" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.ema.copy_attr">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.ema.</span></span><span class="sig-name descname"><span class="pre">copy_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">()</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ema.html#copy_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ema.copy_attr" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.ema.ModelEMA">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.ema.</span></span><span class="sig-name descname"><span class="pre">ModelEMA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.9999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_activation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ema.html#ModelEMA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ema.ModelEMA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Model Exponential Moving Average from <a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a>
Keep a moving average of everything in the model state_dict (parameters and buffers).
This is intended to allow functionality like
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage">https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage</a>
A smoothed version of the weights is necessary for some training schemes to perform well.
This class is sensitive where it is initialized in the sequence of model init,
GPU assignment and distributed training wrappers.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.ema.ModelEMA.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_percent</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ema.html#ModelEMA.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ema.ModelEMA.update" title="Permalink to this definition"></a></dt>
<dd><p>Update the state of the EMA model.
:param model: current training model
:param training_percent: the percentage of the training process [0,1]. i.e 0.4 means 40% of the training have passed</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.ema.ModelEMA.update_attr">
<span class="sig-name descname"><span class="pre">update_attr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ema.html#ModelEMA.update_attr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ema.ModelEMA.update_attr" title="Permalink to this definition"></a></dt>
<dd><p>This function updates model attributes (not weight and biases) from original model to the ema model.
attributes of the original model, such as anchors and grids (of detection models), may be crucial to the
model operation and need to be updated.
If include_attributes and exclude_attributes lists were not defined, all non-private (not starting with ‘_’)
attributes will be updated (and only them).
:param model: the source model</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.ema.KDModelEMA">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.ema.</span></span><span class="sig-name descname"><span class="pre">KDModelEMA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kd_model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">super_gradients.training.models.kd_modules.kd_module.KDModule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.9999</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_activation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ema.html#KDModelEMA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ema.KDModelEMA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.ema.ModelEMA" title="super_gradients.training.utils.ema.ModelEMA"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.ema.ModelEMA</span></code></a></p>
<p>Model Exponential Moving Average from <a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a>
Keep a moving average of everything in the model state_dict (parameters and buffers).
This is intended to allow functionality like
<a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage">https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage</a>
A smoothed version of the weights is necessary for some training schemes to perform well.
This class is sensitive where it is initialized in the sequence of model init,
GPU assignment and distributed training wrappers.</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.export_utils">
<span id="super-gradients-training-utils-export-utils-module"></span><h2>super_gradients.training.utils.export_utils module<a class="headerlink" href="#module-super_gradients.training.utils.export_utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.export_utils.fuse_conv_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.export_utils.</span></span><span class="sig-name descname"><span class="pre">fuse_conv_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_bn_with_identity</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/export_utils.html#fuse_conv_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.export_utils.fuse_conv_bn" title="Permalink to this definition"></a></dt>
<dd><p>Fuses consecutive nn.Conv2d and nn.BatchNorm2d layers recursively inplace in all of the model
:param replace_bn_with_identity: if set to true, bn will be replaced with identity. otherwise, bn will be removed
:param model: the target model
:return: the number of fuses executed</p>
</dd></dl>

</section>
<section id="super-gradients-training-utils-get-model-stats-module">
<h2>super_gradients.training.utils.get_model_stats module<a class="headerlink" href="#super-gradients-training-utils-get-model-stats-module" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.utils.module_utils">
<span id="super-gradients-training-utils-module-utils-module"></span><h2>super_gradients.training.utils.module_utils module<a class="headerlink" href="#module-super_gradients.training.utils.module_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.MultiOutputModule">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.module_utils.</span></span><span class="sig-name descname"><span class="pre">MultiOutputModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_paths</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#MultiOutputModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.MultiOutputModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>This module wraps around a container nn.Module (such as Module, Sequential and ModuleList) and allows to extract
multiple output from its inner modules on each forward call() (as a list of output tensors)
note: the default output of the wrapped module will not be added to the output list by default. To get
the default output in the outputs list, explicitly include its path in the &#64;output_paths parameter</p>
<p>i.e.
for module:</p>
<blockquote>
<div><dl>
<dt>Sequential(</dt><dd><dl class="simple">
<dt>(0): Sequential(</dt><dd><p>(0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
(1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): ReLU6(inplace=True)</p>
</dd>
</dl>
<p>)                                         ===================================&gt;&gt;
(1): InvertedResidual(</p>
<blockquote>
<div><dl class="simple">
<dt>(conv): Sequential(</dt><dd><p>(0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
(1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(2): ReLU6(inplace=True)              ===================================&gt;&gt;
(3): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
(4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
<p>)</p>
</dd>
</dl>
<p>)</p>
</div></blockquote>
<dl class="simple">
<dt>and paths:</dt><dd><p>[0, [1, ‘conv’, 2]]</p>
</dd>
</dl>
<p>the output are marked with arrows</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.MultiOutputModule.save_output_hook">
<span class="sig-name descname"><span class="pre">save_output_hook</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#MultiOutputModule.save_output_hook"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.MultiOutputModule.save_output_hook" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.MultiOutputModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#MultiOutputModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.MultiOutputModule.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.MultiOutputModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.module_utils.MultiOutputModule.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.replace_activations">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.module_utils.</span></span><span class="sig-name descname"><span class="pre">replace_activations</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_activation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activations_to_replace</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">type</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#replace_activations"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.replace_activations" title="Permalink to this definition"></a></dt>
<dd><p>Recursively go through module and replaces each activation in activations_to_replace with a copy of new_activation
:param module:                  a module that will be changed inplace
:param new_activation:          a sample of a new activation (will be copied)
:param activations_to_replace:  types of activations to replace, each must be a subclass of nn.Module</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.fuse_repvgg_blocks_residual_branches">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.module_utils.</span></span><span class="sig-name descname"><span class="pre">fuse_repvgg_blocks_residual_branches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#fuse_repvgg_blocks_residual_branches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.fuse_repvgg_blocks_residual_branches" title="Permalink to this definition"></a></dt>
<dd><p>Call fuse_block_residual_branches for all repvgg blocks in the model
:param model: torch.nn.Module with repvgg blocks. Doesn’t have to be entirely consists of repvgg.
:type model: torch.nn.Module</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.ConvBNReLU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.module_utils.</span></span><span class="sig-name descname"><span class="pre">ConvBNReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'zeros'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_normalization</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eps</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">momentum</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">affine</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">track_running_stats</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_activation</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#ConvBNReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.ConvBNReLU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="simple">
<dt>Class for Convolution2d-Batchnorm2d-Relu layer. Default behaviour is Conv-BN-Relu. To exclude Batchnorm module use</dt><dd><p><cite>use_normalization=False</cite>, to exclude Relu activation use <cite>use_activation=False</cite>.</p>
</dd>
</dl>
<p>For convolution arguments documentation see <cite>nn.Conv2d</cite>.
For batchnorm arguments documentation see <cite>nn.BatchNorm2d</cite>.
For relu arguments documentation see <cite>nn.Relu</cite>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.ConvBNReLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#ConvBNReLU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.ConvBNReLU.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.ConvBNReLU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.module_utils.ConvBNReLU.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.NormalizationAdapter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.module_utils.</span></span><span class="sig-name descname"><span class="pre">NormalizationAdapter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_original</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_original</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_required</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std_required</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#NormalizationAdapter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.NormalizationAdapter" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Denormalizes input by mean_original, std_original, then normalizes by mean_required, std_required.</p>
<p>Used in KD training where teacher expects data normalized by mean_required, std_required.</p>
<dl class="simple">
<dt>mean_original, std_original, mean_required, std_required are all list-like objects of length that’s equal to the</dt><dd><p>number of input channels.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.NormalizationAdapter.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/module_utils.html#NormalizationAdapter.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.module_utils.NormalizationAdapter.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.module_utils.NormalizationAdapter.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.module_utils.NormalizationAdapter.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.utils.optimizer_utils">
<span id="super-gradients-training-utils-optimizer-utils-module"></span><h2>super_gradients.training.utils.optimizer_utils module<a class="headerlink" href="#module-super_gradients.training.utils.optimizer_utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.optimizer_utils.separate_zero_wd_params_groups_for_optimizer">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.optimizer_utils.</span></span><span class="sig-name descname"><span class="pre">separate_zero_wd_params_groups_for_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_named_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/optimizer_utils.html#separate_zero_wd_params_groups_for_optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.optimizer_utils.separate_zero_wd_params_groups_for_optimizer" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>separate param groups for batchnorm and biases and others with weight decay. return list of param groups in format</dt><dd><p>required by torch Optimizer classes.</p>
</dd>
<dt>bias + BN with weight decay=0 and the rest with the given weight decay</dt><dd><dl class="field-list simple">
<dt class="field-odd">param module</dt>
<dd class="field-odd"><p>train net module.</p>
</dd>
<dt class="field-even">param net_named_params</dt>
<dd class="field-even"><p>list of params groups, output of SgModule.initialize_param_groups</p>
</dd>
<dt class="field-odd">param weight_decay</dt>
<dd class="field-odd"><p>value to set for the non BN and bias parameters</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.optimizer_utils.build_optimizer">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.optimizer_utils.</span></span><span class="sig-name descname"><span class="pre">build_optimizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/optimizer_utils.html#build_optimizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.optimizer_utils.build_optimizer" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Wrapper function for initializing the optimizer</dt><dd><dl class="field-list simple">
<dt class="field-odd">param net</dt>
<dd class="field-odd"><p>the nn_module to build the optimizer for</p>
</dd>
<dt class="field-even">param lr</dt>
<dd class="field-even"><p>initial learning rate</p>
</dd>
<dt class="field-odd">param training_params</dt>
<dd class="field-odd"><p>training_parameters</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.regularization_utils">
<span id="super-gradients-training-utils-regularization-utils-module"></span><h2>super_gradients.training.utils.regularization_utils module<a class="headerlink" href="#module-super_gradients.training.utils.regularization_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.regularization_utils.DropPath">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.regularization_utils.</span></span><span class="sig-name descname"><span class="pre">DropPath</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">drop_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/regularization_utils.html#DropPath"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.regularization_utils.DropPath" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).</p>
<p>Code taken from TIMM (<a class="reference external" href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models</a>)
Apache License 2.0</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.regularization_utils.DropPath.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/regularization_utils.html#DropPath.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.regularization_utils.DropPath.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.regularization_utils.DropPath.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.regularization_utils.DropPath.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.utils.segmentation_utils">
<span id="super-gradients-training-utils-segmentation-utils-module"></span><h2>super_gradients.training.utils.segmentation_utils module<a class="headerlink" href="#module-super_gradients.training.utils.segmentation_utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.coco_sub_classes_inclusion_tuples_list">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">coco_sub_classes_inclusion_tuples_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#coco_sub_classes_inclusion_tuples_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.coco_sub_classes_inclusion_tuples_list" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.to_one_hot">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">to_one_hot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#to_one_hot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.to_one_hot" title="Permalink to this definition"></a></dt>
<dd><p>Target label to one_hot tensor. labels and ignore_index must be consecutive numbers.
:param target: Class labels long tensor, with shape [N, H, W]
:param num_classes: num of classes in datasets excluding ignore label, this is the output channels of the one hot</p>
<blockquote>
<div><p>result.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>one hot tensor with shape [N, num_classes, H, W]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.reverse_imagenet_preprocessing">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">reverse_imagenet_preprocessing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">im_tensor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">numpy.ndarray</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#reverse_imagenet_preprocessing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.reverse_imagenet_preprocessing" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>im_tensor</strong> – images in a batch after preprocessing for inference, RGB, (B, C, H, W)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>images in a batch in cv2 format, BGR, (B, H, W, C)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.BinarySegmentationVisualization">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">BinarySegmentationVisualization</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#BinarySegmentationVisualization"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.BinarySegmentationVisualization" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.BinarySegmentationVisualization.visualize_batch">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">visualize_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">image_tensor:</span> <span class="pre">torch.Tensor,</span> <span class="pre">pred_mask:</span> <span class="pre">torch.Tensor,</span> <span class="pre">target_mask:</span> <span class="pre">torch.Tensor,</span> <span class="pre">batch_name:</span> <span class="pre">Union[int,</span> <span class="pre">str],</span> <span class="pre">checkpoint_dir:</span> <span class="pre">Optional[str]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">undo_preprocessing_func:</span> <span class="pre">Callable[[torch.Tensor],</span> <span class="pre">numpy.ndarray]</span> <span class="pre">=</span> <span class="pre">&lt;function</span> <span class="pre">reverse_imagenet_preprocessing&gt;,</span> <span class="pre">image_scale:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#BinarySegmentationVisualization.visualize_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.BinarySegmentationVisualization.visualize_batch" title="Permalink to this definition"></a></dt>
<dd><p>A helper function to visualize detections predicted by a network:
saves images into a given path with a name that is {batch_name}_{imade_idx_in_the_batch}.jpg, one batch per call.
Colors are generated on the fly: uniformly sampled from color wheel to support all given classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image_tensor</strong> – rgb images, (B, H, W, 3)</p></li>
<li><p><strong>pred_boxes</strong> – boxes after NMS for each image in a batch, each (Num_boxes, 6),
values on dim 1 are: x1, y1, x2, y2, confidence, class</p></li>
<li><p><strong>target_boxes</strong> – (Num_targets, 6), values on dim 1 are: image id in a batch, class, x y w h
(coordinates scaled to [0, 1])</p></li>
<li><p><strong>batch_name</strong> – id of the current batch to use for image naming</p></li>
<li><p><strong>checkpoint_dir</strong> – a path where images with boxes will be saved. if None, the result images will
be returns as a list of numpy image arrays</p></li>
<li><p><strong>undo_preprocessing_func</strong> – a function to convert preprocessed images tensor into a batch of cv2-like images</p></li>
<li><p><strong>image_scale</strong> – scale factor for output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.visualize_batches">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">visualize_batches</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">visualization_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_batches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">undo_preprocessing_func</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#visualize_batches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.visualize_batches" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.one_hot_to_binary_edge">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">one_hot_to_binary_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#one_hot_to_binary_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.one_hot_to_binary_edge" title="Permalink to this definition"></a></dt>
<dd><p>Utils function to create edge feature maps.
:param x: input tensor, must be one_hot tensor with shape [B, C, H, W]
:param kernel_size: kernel size of dilation erosion convolutions. The result edge widths depends on this argument as</p>
<blockquote>
<div><p>follows: <cite>edge_width = kernel - 1</cite></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>flatten_channels</strong> – Whether to apply logical_or across channels dimension, if at least one pixel class is
considered as edge pixel flatten value is 1. If set as <cite>False</cite> the output tensor shape is [B, C, H, W], else
[B, 1, H, W]. Default is <cite>True</cite>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>one_hot edge torch.Tensor.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.segmentation_utils.target_to_binary_edge">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.segmentation_utils.</span></span><span class="sig-name descname"><span class="pre">target_to_binary_edge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flatten_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="reference internal" href="_modules/super_gradients/training/utils/segmentation_utils.html#target_to_binary_edge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.segmentation_utils.target_to_binary_edge" title="Permalink to this definition"></a></dt>
<dd><p>Utils function to create edge feature maps from target.
:param target: Class labels long tensor, with shape [N, H, W]
:param num_classes: num of classes in datasets excluding ignore label, this is the output channels of the one hot</p>
<blockquote>
<div><p>result.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – kernel size of dilation erosion convolutions. The result edge widths depends on this argument as
follows: <cite>edge_width = kernel - 1</cite></p></li>
<li><p><strong>flatten_channels</strong> – Whether to apply logical or across channels dimension, if at least one pixel class is
considered as edge pixel flatten value is 1. If set as <cite>False</cite> the output tensor shape is [B, C, H, W], else
[B, 1, H, W]. Default is <cite>True</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>one_hot edge torch.Tensor.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.sg_model_utils">
<span id="super-gradients-training-utils-sg-model-utils-module"></span><h2>super_gradients.training.utils.sg_model_utils module<a class="headerlink" href="#module-super_gradients.training.utils.sg_model_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">MonitoredValue</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">greater_is_better</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">previous</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">change_from_previous</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">change_from_best</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#MonitoredValue"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Store a value and some indicators relative to its past iterations.</p>
<p>The value can be a metric/loss, and the iteration can be epochs/batch.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.greater_is_better">
<span class="sig-name descname"><span class="pre">greater_is_better</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.greater_is_better" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.current">
<span class="sig-name descname"><span class="pre">current</span></span><em class="property"><span class="pre">:</span> <span class="pre">float</span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.current" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.previous">
<span class="sig-name descname"><span class="pre">previous</span></span><em class="property"><span class="pre">:</span> <span class="pre">float</span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.previous" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.best">
<span class="sig-name descname"><span class="pre">best</span></span><em class="property"><span class="pre">:</span> <span class="pre">float</span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.best" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.change_from_previous">
<span class="sig-name descname"><span class="pre">change_from_previous</span></span><em class="property"><span class="pre">:</span> <span class="pre">float</span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.change_from_previous" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.change_from_best">
<span class="sig-name descname"><span class="pre">change_from_best</span></span><em class="property"><span class="pre">:</span> <span class="pre">float</span></em><em class="property"> <span class="pre">=</span> <span class="pre">None</span></em><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.change_from_best" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.is_better_than_previous">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">is_better_than_previous</span></span><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.is_better_than_previous" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.MonitoredValue.is_best_value">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">is_best_value</span></span><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue.is_best_value" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.update_monitored_value">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">update_monitored_value</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">previous_monitored_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#update_monitored_value"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.update_monitored_value" title="Permalink to this definition"></a></dt>
<dd><p>Update the given ValueToMonitor object (could be a loss or a metric) with the new value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>previous_monitored_value</strong> – The stats about the value that is monitored throughout epochs.</p></li>
<li><p><strong>new_value</strong> – The value of the current epoch that will be used to update previous_monitored_value</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.update_monitored_values_dict">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">update_monitored_values_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">monitored_values_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">new_values_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#update_monitored_values_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.update_monitored_values_dict" title="Permalink to this definition"></a></dt>
<dd><p>Update the given ValueToMonitor object (could be a loss or a metric) with the new value</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>monitored_values_dict</strong> – Dict mapping value names to their stats throughout epochs.</p></li>
<li><p><strong>new_values_dict</strong> – Dict mapping value names to their new (i.e. current epoch) value.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Updated monitored_values_dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.display_epoch_summary">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">display_epoch_summary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_digits</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_monitored_values</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_monitored_values</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#super_gradients.training.utils.sg_model_utils.MonitoredValue" title="super_gradients.training.utils.sg_model_utils.MonitoredValue"><span class="pre">super_gradients.training.utils.sg_model_utils.MonitoredValue</span></a><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#display_epoch_summary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.display_epoch_summary" title="Permalink to this definition"></a></dt>
<dd><p>Display a summary of loss/metric of interest, for a given epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epoch</strong> – the number of epoch.</p></li>
<li><p><strong>n_digits</strong> – number of digits to display on screen for float values</p></li>
<li><p><strong>train_monitored_values</strong> – mapping of loss/metric with their stats that will be displayed</p></li>
<li><p><strong>valid_monitored_values</strong> – mapping of loss/metric with their stats that will be displayed</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.try_port">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">try_port</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">port</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#try_port"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.try_port" title="Permalink to this definition"></a></dt>
<dd><p>try_port - Helper method for tensorboard port binding
:param port:
:return:</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.launch_tensorboard_process">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">launch_tensorboard_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoints_dir_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sleep_postpone</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">port</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">multiprocessing.context.Process</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#launch_tensorboard_process"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.launch_tensorboard_process" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>launch_tensorboard_process - Default behavior is to scan all free ports from 6006-6016 and try using them</dt><dd><blockquote>
<div><p>unless port is defined by the user</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">param checkpoints_dir_path</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">param sleep_postpone</dt>
<dd class="field-even"><p></p></dd>
<dt class="field-odd">param port</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>tuple of tb process, port</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.init_summary_writer">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">init_summary_writer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tb_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_loaded</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">user_prompt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#init_summary_writer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.init_summary_writer" title="Permalink to this definition"></a></dt>
<dd><p>Remove previous tensorboard files from directory and launch a tensor board process</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.add_log_to_file">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">add_log_to_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filename</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_titles_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_values_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#add_log_to_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.add_log_to_file" title="Permalink to this definition"></a></dt>
<dd><p>Add a message to the log file</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.write_training_results">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">write_training_results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">writer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_titles_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">results_values_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#write_training_results"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.write_training_results" title="Permalink to this definition"></a></dt>
<dd><p>Stores the training and validation loss and accuracy for current epoch in a tensorboard file</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.write_hpms">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">write_hpms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">writer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hpmstructs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">special_conf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#write_hpms"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.write_hpms" title="Permalink to this definition"></a></dt>
<dd><p>Stores the training and dataset hyper params in the tensorboard file</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.unpack_batch_items">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">unpack_batch_items</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_items</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#unpack_batch_items"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.unpack_batch_items" title="Permalink to this definition"></a></dt>
<dd><p>Adds support for unpacking batch items in train/validation loop.</p>
<dl>
<dt>&#64;param batch_items: (Union[tuple, torch.Tensor]) returned by the data loader, which is expected to be in one of</dt><dd><dl class="simple">
<dt>the following formats:</dt><dd><ol class="arabic simple">
<li><p>torch.Tensor or tuple, s.t inputs = batch_items[0], targets = batch_items[1] and len(batch_items) = 2</p></li>
<li><p>tuple: (inputs, targets, additional_batch_items)</p></li>
</ol>
</dd>
</dl>
<p>where inputs are fed to the network, targets are their corresponding labels and additional_batch_items is a
dictionary (format {additional_batch_item_i_name: additional_batch_item_i …}) which can be accessed through
the phase context under the attribute additional_batch_item_i_name, using a phase callback.</p>
</dd>
</dl>
<p>&#64;return: inputs, target, additional_batch_items</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.sg_model_utils.log_uncaught_exceptions">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.sg_model_utils.</span></span><span class="sig-name descname"><span class="pre">log_uncaught_exceptions</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">logger</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/sg_model_utils.html#log_uncaught_exceptions"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.sg_model_utils.log_uncaught_exceptions" title="Permalink to this definition"></a></dt>
<dd><p>Makes logger log uncaught exceptions
&#64;param logger: logging.Logger</p>
<p>&#64;return: None</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.ssd_utils">
<span id="super-gradients-training-utils-ssd-utils-module"></span><h2>super_gradients.training.utils.ssd_utils module<a class="headerlink" href="#module-super_gradients.training.utils.ssd_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.DefaultBoxes">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.ssd_utils.</span></span><span class="sig-name descname"><span class="pre">DefaultBoxes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fig_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feat_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scales</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aspect_ratios</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_xy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_wh</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ssd_utils.html#DefaultBoxes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.DefaultBoxes" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Default Boxes, (aka: anchor boxes or priors boxes) used by SSD model</p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.DefaultBoxes.scale_xy">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">scale_xy</span></span><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.DefaultBoxes.scale_xy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.DefaultBoxes.scale_wh">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">scale_wh</span></span><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.DefaultBoxes.scale_wh" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.SSDPostPredictCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.ssd_utils.</span></span><span class="sig-name descname"><span class="pre">SSDPostPredictCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">conf:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.001</span></em>, <em class="sig-param"><span class="pre">iou:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.6</span></em>, <em class="sig-param"><span class="pre">classes:</span> <span class="pre">Optional[list]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">max_predictions:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">300</span></em>, <em class="sig-param"><span class="pre">nms_type:</span> <span class="pre">super_gradients.training.utils.detection_utils.NMS_Type</span> <span class="pre">=</span> <span class="pre">&lt;NMS_Type.ITERATIVE:</span> <span class="pre">'iterative'&gt;</span></em>, <em class="sig-param"><span class="pre">multi_label_per_box=True</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ssd_utils.html#SSDPostPredictCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.SSDPostPredictCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback" title="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback</span></code></a></p>
<p>post prediction callback module to convert and filter predictions coming from the SSD net to a format
used by all other detection models</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.SSDPostPredictCallback.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">predictions</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/ssd_utils.html#SSDPostPredictCallback.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.SSDPostPredictCallback.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the output of your model</p></li>
<li><p><strong>device</strong> – the device to move all output tensors into</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list with length batch_size, each item in the list is a detections
with shape: nx6 (x1, y1, x2, y2, confidence, class) where x and y are in range [0,1]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.ssd_utils.SSDPostPredictCallback.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.ssd_utils.SSDPostPredictCallback.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.utils.utils">
<span id="super-gradients-training-utils-utils-module"></span><h2>super_gradients.training.utils.utils module<a class="headerlink" href="#module-super_gradients.training.utils.utils" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.convert_to_tensor">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">convert_to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#convert_to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.convert_to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts numpy arrays and lists to Torch tensors before calculation losses
:param array: torch.tensor / Numpy array / List</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.HpmStruct">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">HpmStruct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.HpmStruct" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.HpmStruct.set_schema">
<span class="sig-name descname"><span class="pre">set_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.set_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.HpmStruct.set_schema" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.HpmStruct.override">
<span class="sig-name descname"><span class="pre">override</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.HpmStruct.override" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.HpmStruct.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.to_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.HpmStruct.to_dict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.HpmStruct.validate">
<span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.validate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.HpmStruct.validate" title="Permalink to this definition"></a></dt>
<dd><p>Validate the current dict values according to the provided schema
:raises</p>
<blockquote>
<div><p><cite>AttributeError</cite> if schema was not set
<cite>jsonschema.exceptions.ValidationError</cite> if the instance is invalid
<cite>jsonschema.exceptions.SchemaError</cite> if the schema itselfis invalid</p>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.WrappedModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">WrappedModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.WrappedModel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.WrappedModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.WrappedModel.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.WrappedModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.utils.WrappedModel.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.Timer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">Timer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.Timer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to measure time handling both GPU &amp; CPU processes
Returns time in milliseconds</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.Timer.start">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.start"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.Timer.start" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.Timer.stop">
<span class="sig-name descname"><span class="pre">stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.stop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.Timer.stop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.AverageMeter">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">AverageMeter</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#AverageMeter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.AverageMeter" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to calculate the average of a metric, for each batch
during training/testing</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.AverageMeter.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#AverageMeter.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.AverageMeter.update" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.AverageMeter.average">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">average</span></span><a class="headerlink" href="#super_gradients.training.utils.utils.AverageMeter.average" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.tensor_container_to_device">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">tensor_container_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#tensor_container_to_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.tensor_container_to_device" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>recursively send compounded objects to device (sending all tensors to device and maintaining structure)</dt><dd><p>:param obj           the object to send to device (list / tuple / tensor / dict)
:param device:       device to send the tensors to
:param non_blocking: used for DistributedDataParallel
:returns        an object with the same structure (tensors, lists, tuples) with the device pointers (like</p>
<blockquote>
<div><p>the return value of Tensor.to(device)</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.get_param">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.get_param" title="Permalink to this definition"></a></dt>
<dd><p>Retrieves a param from a parameter object/dict. If the parameter does not exist, will return default_val.
In case the default_val is of type dictionary, and a value is found in the params - the function
will return the default value dictionary with internal values overridden by the found value</p>
<p>i.e.
default_opt_params = {‘lr’:0.1, ‘momentum’:0.99, ‘alpha’:0.001}
training_params = {‘optimizer_params’: {‘lr’:0.0001}, ‘batch’: 32 …. }
get_param(training_params, name=’optimizer_params’, default_val=default_opt_params)
will return {‘lr’:0.0001, ‘momentum’:0.99, ‘alpha’:0.001}</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – an object (typically HpmStruct) or a dict holding the params</p></li>
<li><p><strong>name</strong> – name of the searched parameter</p></li>
<li><p><strong>default_val</strong> – assumed to be the same type as the value searched in the params</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the found value, or default if not found</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.static_vars">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">static_vars</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#static_vars"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.static_vars" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.print_once">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">print_once</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">s</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#print_once"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.print_once" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.move_state_dict_to_device">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">move_state_dict_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_sd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#move_state_dict_to_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.move_state_dict_to_device" title="Permalink to this definition"></a></dt>
<dd><p>Moving model state dict tensors to target device (cuda or cpu)
:param model_sd: model state dict
:param device: either cuda or cpu</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.random_seed">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_ddp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#random_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Sets random seed of numpy, torch and random.</p>
<p>When using ddp a seed will be set for each process according to its local rank derived from the device number.
:param is_ddp: bool, will set different random seed for each process when using ddp.
:param device: ‘cuda’,’cpu’, ‘cuda:&lt;device_number&gt;’
:param seed: int, random seed to be set</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.load_func">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">load_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dotpath</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#load_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.load_func" title="Permalink to this definition"></a></dt>
<dd><p>load function in module.  function is right-most segment.</p>
<p>Used for passing functions (without calling them) in yaml files.</p>
<p>&#64;param dotpath: path to module.
&#64;return: a python function</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.get_filename_suffix_by_framework">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">get_filename_suffix_by_framework</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">framework</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_filename_suffix_by_framework"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.get_filename_suffix_by_framework" title="Permalink to this definition"></a></dt>
<dd><p>Return the file extension of framework.</p>
<p>&#64;param framework: (str)
&#64;return: (str) the suffix for the specific framework</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.check_models_have_same_weights">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">check_models_have_same_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_1</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_2</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#check_models_have_same_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.check_models_have_same_weights" title="Permalink to this definition"></a></dt>
<dd><p>Checks whether two networks have the same weights</p>
<p>&#64;param model_1: Net to be checked
&#64;param model_2: Net to be checked
&#64;return: True iff the two networks have the same weights</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.recursive_override">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">recursive_override</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">extension</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#recursive_override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.recursive_override" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.download_and_unzip_from_url">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">download_and_unzip_from_url</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">url</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">unzip</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delete</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#download_and_unzip_from_url"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.download_and_unzip_from_url" title="Permalink to this definition"></a></dt>
<dd><p>Downloads a zip file from url to dir, and unzips it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>url</strong> – Url to download the file from.</p></li>
<li><p><strong>dir</strong> – Destination directory.</p></li>
<li><p><strong>unzip</strong> – Whether to unzip the downloaded file.</p></li>
<li><p><strong>delete</strong> – Whether to delete the zip file.</p></li>
</ul>
</dd>
</dl>
<p>used to downlaod VOC.</p>
<p>Source:
<a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml">https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml</a></p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.download_and_untar_from_url">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">download_and_untar_from_url</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">urls</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dir</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">pathlib.Path</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'.'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#download_and_untar_from_url"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.download_and_untar_from_url" title="Permalink to this definition"></a></dt>
<dd><p>Download a file from url and untar.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>urls</strong> – Url to download the file from.</p></li>
<li><p><strong>dir</strong> – Destination directory.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.make_divisible">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">make_divisible</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divisor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ceil</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#make_divisible"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.make_divisible" title="Permalink to this definition"></a></dt>
<dd><p>Returns x evenly divisible by divisor.
If ceil=True it will return the closest larger number to the original x, and ceil=False the closest smaller number.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.check_img_size_divisibility">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">check_img_size_divisibility</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">,</span> </span><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#check_img_size_divisibility"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.check_img_size_divisibility" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>img_size</strong> – Int, the size of the image (H or W).</p></li>
<li><p><strong>stride</strong> – Int, the number to check if img_size is divisible by.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(True, None) if img_size is divisble by stride, (False, Suggestions) if it’s not.
Note: Suggestions are the two closest numbers to img_size that <em>are</em> divisible by stride.
For example if img_size=321, stride=32, it will return (False,(352, 320)).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.get_orientation_key">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">get_orientation_key</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_orientation_key"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.get_orientation_key" title="Permalink to this definition"></a></dt>
<dd><p>Get the orientation key according to PIL, which is useful to get the image size for instance
:return: Orientation key according to PIL</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.exif_size">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">exif_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">image:</span> <span class="pre">&lt;module</span> <span class="pre">'PIL.Image'</span> <span class="pre">from</span> <span class="pre">'/Users/shaniperl/opt/anaconda3/lib/python3.9/site-packages/PIL/Image.py'&gt;</span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#exif_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.exif_size" title="Permalink to this definition"></a></dt>
<dd><p>Get the size of image.
:param image:   The image to get size from
:return:        (width, height)</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.utils.get_image_size_from_path">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.utils.</span></span><span class="sig-name descname"><span class="pre">get_image_size_from_path</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_path</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_image_size_from_path"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.utils.get_image_size_from_path" title="Permalink to this definition"></a></dt>
<dd><p>Get the image size of an image at a specific path</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.utils.weight_averaging_utils">
<span id="super-gradients-training-utils-weight-averaging-utils-module"></span><h2>super_gradients.training.utils.weight_averaging_utils module<a class="headerlink" href="#module-super_gradients.training.utils.weight_averaging_utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.weight_averaging_utils.</span></span><span class="sig-name descname"><span class="pre">ModelWeightAveraging</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ckpt_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">greater_is_better</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_ckpt_folder_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_to_watch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'acc'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_idx</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">load_checkpoint</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_models_to_average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_checkpoints_location</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'local'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/weight_averaging_utils.html#ModelWeightAveraging"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Utils class for managing the averaging of the best several snapshots into a single model.
A snapshot dictionary file and the average model will be saved / updated at every epoch and evaluated only when
training is completed. The snapshot file will only be deleted upon completing the training.
The snapshot dict will be managed on cpu.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.update_snapshots_dict">
<span class="sig-name descname"><span class="pre">update_snapshots_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_results_tuple</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/weight_averaging_utils.html#ModelWeightAveraging.update_snapshots_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.update_snapshots_dict" title="Permalink to this definition"></a></dt>
<dd><p>Update the snapshot dict and returns the updated average model for saving
:param model: the latest model
:param validation_results_tuple: performance of the latest model</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.get_average_model">
<span class="sig-name descname"><span class="pre">get_average_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_results_tuple</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/weight_averaging_utils.html#ModelWeightAveraging.get_average_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.get_average_model" title="Permalink to this definition"></a></dt>
<dd><p>Returns the averaged model
:param model: will be used to determine arch
:param validation_results_tuple: if provided, will update the average model before returning
:param target_device: if provided, return sd on target device</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.cleanup">
<span class="sig-name descname"><span class="pre">cleanup</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/weight_averaging_utils.html#ModelWeightAveraging.cleanup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.weight_averaging_utils.ModelWeightAveraging.cleanup" title="Permalink to this definition"></a></dt>
<dd><p>Delete snapshot file when reaching the last epoch</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.utils">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-super_gradients.training.utils" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">Timer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to measure time handling both GPU &amp; CPU processes
Returns time in milliseconds</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer.start">
<span class="sig-name descname"><span class="pre">start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.start"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer.start" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.Timer.stop">
<span class="sig-name descname"><span class="pre">stop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#Timer.stop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.Timer.stop" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">HpmStruct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.set_schema">
<span class="sig-name descname"><span class="pre">set_schema</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">schema</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.set_schema"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.set_schema" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.override">
<span class="sig-name descname"><span class="pre">override</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">entries</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.override"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.override" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.to_dict">
<span class="sig-name descname"><span class="pre">to_dict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.to_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.to_dict" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.HpmStruct.validate">
<span class="sig-name descname"><span class="pre">validate</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#HpmStruct.validate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.HpmStruct.validate" title="Permalink to this definition"></a></dt>
<dd><p>Validate the current dict values according to the provided schema
:raises</p>
<blockquote>
<div><p><cite>AttributeError</cite> if schema was not set
<cite>jsonschema.exceptions.ValidationError</cite> if the instance is invalid
<cite>jsonschema.exceptions.SchemaError</cite> if the schema itselfis invalid</p>
</div></blockquote>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">WrappedModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.WrappedModel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#WrappedModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.WrappedModel.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.utils.WrappedModel.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.utils.WrappedModel.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.convert_to_tensor">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">convert_to_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">array</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#convert_to_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.convert_to_tensor" title="Permalink to this definition"></a></dt>
<dd><p>Converts numpy arrays and lists to Torch tensors before calculation losses
:param array: torch.tensor / Numpy array / List</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.get_param">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">get_param</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">default_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#get_param"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.get_param" title="Permalink to this definition"></a></dt>
<dd><p>Retrieves a param from a parameter object/dict. If the parameter does not exist, will return default_val.
In case the default_val is of type dictionary, and a value is found in the params - the function
will return the default value dictionary with internal values overridden by the found value</p>
<p>i.e.
default_opt_params = {‘lr’:0.1, ‘momentum’:0.99, ‘alpha’:0.001}
training_params = {‘optimizer_params’: {‘lr’:0.0001}, ‘batch’: 32 …. }
get_param(training_params, name=’optimizer_params’, default_val=default_opt_params)
will return {‘lr’:0.0001, ‘momentum’:0.99, ‘alpha’:0.001}</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>params</strong> – an object (typically HpmStruct) or a dict holding the params</p></li>
<li><p><strong>name</strong> – name of the searched parameter</p></li>
<li><p><strong>default_val</strong> – assumed to be the same type as the value searched in the params</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the found value, or default if not found</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.tensor_container_to_device">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">tensor_container_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">,</span> </span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">non_blocking</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#tensor_container_to_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.tensor_container_to_device" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>recursively send compounded objects to device (sending all tensors to device and maintaining structure)</dt><dd><p>:param obj           the object to send to device (list / tuple / tensor / dict)
:param device:       device to send the tensors to
:param non_blocking: used for DistributedDataParallel
:returns        an object with the same structure (tensors, lists, tuples) with the device pointers (like</p>
<blockquote>
<div><p>the return value of Tensor.to(device)</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.adapt_state_dict_to_fit_model_layer_names">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">adapt_state_dict_to_fit_model_layer_names</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_state_dict</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">source_ckpt</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exclude</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">callable</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#adapt_state_dict_to_fit_model_layer_names"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.adapt_state_dict_to_fit_model_layer_names" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method tries to correct the keys in the model_state_dict to fit
the ckpt in order to properly load the weights into the model. If unsuccessful - returns None</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">param model_state_dict</dt>
<dd class="field-odd"><p>the model state_dict</p>
</dd>
<dt class="field-even">param source_ckpt</dt>
<dd class="field-even"><p>checkpoint dict</p>
</dd>
</dl>
<p>:param exclude                  optional list for excluded layers
:param solver:                  callable with signature (ckpt_key, ckpt_val, model_key, model_val)</p>
<blockquote>
<div><p>that returns a desired weight for ckpt_val.</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>renamed checkpoint dict (if possible)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.raise_informative_runtime_error">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">raise_informative_runtime_error</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exception_msg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/checkpoint_utils.html#raise_informative_runtime_error"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.raise_informative_runtime_error" title="Permalink to this definition"></a></dt>
<dd><p>Given a model state dict and source checkpoints, the method calls “adapt_state_dict_to_fit_model_layer_names”
and enhances the exception_msg if loading the checkpoint_dict via the conversion method is possible</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.utils.random_seed">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.utils.</span></span><span class="sig-name descname"><span class="pre">random_seed</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">is_ddp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/utils/utils.html#random_seed"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.utils.random_seed" title="Permalink to this definition"></a></dt>
<dd><p>Sets random seed of numpy, torch and random.</p>
<p>When using ddp a seed will be set for each process according to its local rank derived from the device number.
:param is_ddp: bool, will set different random seed for each process when using ddp.
:param device: ‘cuda’,’cpu’, ‘cuda:&lt;device_number&gt;’
:param seed: int, random seed to be set</p>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, SuperGradients team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>