<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>super_gradients.training.models package &mdash; SuperGradients 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="super_gradients.training.sg_model package" href="super_gradients.training.sg_model.html" />
    <link rel="prev" title="super_gradients.training.metrics package" href="super_gradients.training.metrics.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> SuperGradients
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#installation">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="super_gradients.training.html">super_gradients.training package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="super_gradients.training.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.datasets.html">super_gradients.training.datasets package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.exceptions.html">super_gradients.training.exceptions package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.legacy.html">super_gradients.training.legacy package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.losses.html">super_gradients.training.losses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.metrics.html">super_gradients.training.metrics package</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">super_gradients.training.models package</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.all_architectures">super_gradients.training.models.all_architectures module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.csp_darknet53">super_gradients.training.models.csp_darknet53 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.darknet53">super_gradients.training.models.darknet53 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.ddrnet">super_gradients.training.models.ddrnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.densenet">super_gradients.training.models.densenet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.dpn">super_gradients.training.models.dpn module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.efficientnet">super_gradients.training.models.efficientnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.googlenet">super_gradients.training.models.googlenet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.laddernet">super_gradients.training.models.laddernet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.lenet">super_gradients.training.models.lenet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.mobilenet">super_gradients.training.models.mobilenet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.mobilenetv2">super_gradients.training.models.mobilenetv2 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.mobilenetv3">super_gradients.training.models.mobilenetv3 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.pnasnet">super_gradients.training.models.pnasnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.preact_resnet">super_gradients.training.models.preact_resnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.regnet">super_gradients.training.models.regnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.repvgg">super_gradients.training.models.repvgg module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.resnet">super_gradients.training.models.resnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.resnext">super_gradients.training.models.resnext module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.senet">super_gradients.training.models.senet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.sg_module">super_gradients.training.models.sg_module module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.shelfnet">super_gradients.training.models.shelfnet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.shufflenet">super_gradients.training.models.shufflenet module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.shufflenetv2">super_gradients.training.models.shufflenetv2 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.ssd">super_gradients.training.models.ssd module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.vgg">super_gradients.training.models.vgg module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.yolov3">super_gradients.training.models.yolov3 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models.yolov5">super_gradients.training.models.yolov5 module</a></li>
<li class="toctree-l4"><a class="reference internal" href="#module-super_gradients.training.models">Module contents</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.sg_model.html">super_gradients.training.sg_model package</a></li>
<li class="toctree-l3"><a class="reference internal" href="super_gradients.training.utils.html">super_gradients.training.utils package</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training.params">super_gradients.training.params module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training.pretrained_models">super_gradients.training.pretrained_models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="super_gradients.training.html#module-super_gradients.training">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">SuperGradients</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="super_gradients.training.html">super_gradients.training package</a> &raquo;</li>
      <li>super_gradients.training.models package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/super_gradients.training.models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="super-gradients-training-models-package">
<h1>super_gradients.training.models package<a class="headerlink" href="#super-gradients-training-models-package" title="Permalink to this headline"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.models.all_architectures">
<span id="super-gradients-training-models-all-architectures-module"></span><h2>super_gradients.training.models.all_architectures module<a class="headerlink" href="#module-super_gradients.training.models.all_architectures" title="Permalink to this headline"></a></h2>
</section>
<section id="module-super_gradients.training.models.csp_darknet53">
<span id="super-gradients-training-models-csp-darknet53-module"></span><h2>super_gradients.training.models.csp_darknet53 module<a class="headerlink" href="#module-super_gradients.training.models.csp_darknet53" title="Permalink to this headline"></a></h2>
<p>CSP Darknet</p>
<p>credits: <a class="reference external" href="https://github.com/ultralytics">https://github.com/ultralytics</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Bottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">Bottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_channels</span></em>, <em class="sig-param"><span class="pre">output_channels</span></em>, <em class="sig-param"><span class="pre">shortcut=True</span></em>, <em class="sig-param"><span class="pre">groups=1</span></em>, <em class="sig-param"><span class="pre">width_mult_factor:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></em>, <em class="sig-param"><span class="pre">activation_func_type:</span> <span class="pre">type</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'torch.nn.modules.activation.Hardswish'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Bottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Bottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Bottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Bottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Bottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Bottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Bottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.BottleneckCSP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">BottleneckCSP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_blocks_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shortcut</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expansion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth_mult_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#BottleneckCSP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.BottleneckCSP" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.BottleneckCSP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#BottleneckCSP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.BottleneckCSP.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.BottleneckCSP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.BottleneckCSP.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.C3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">C3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_channels</span></em>, <em class="sig-param"><span class="pre">output_channels</span></em>, <em class="sig-param"><span class="pre">bottleneck_blocks_num=1</span></em>, <em class="sig-param"><span class="pre">shortcut=True</span></em>, <em class="sig-param"><span class="pre">groups=1</span></em>, <em class="sig-param"><span class="pre">expansion=0.5</span></em>, <em class="sig-param"><span class="pre">width_mult_factor:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></em>, <em class="sig-param"><span class="pre">depth_mult_factor:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></em>, <em class="sig-param"><span class="pre">activation_func_type:</span> <span class="pre">type</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'torch.nn.modules.activation.SiLU'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#C3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.C3" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.C3.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#C3.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.C3.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.C3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.C3.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.CSPDarknet53">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">CSPDarknet53</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#CSPDarknet53"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.CSPDarknet53" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.CSPDarknet53.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#CSPDarknet53.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.CSPDarknet53.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.CSPDarknet53.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.CSPDarknet53.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Conv">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">Conv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_channels</span></em>, <em class="sig-param"><span class="pre">output_channels</span></em>, <em class="sig-param"><span class="pre">kernel=1</span></em>, <em class="sig-param"><span class="pre">stride=1</span></em>, <em class="sig-param"><span class="pre">padding=None</span></em>, <em class="sig-param"><span class="pre">groups=1</span></em>, <em class="sig-param"><span class="pre">activation_func_type:</span> <span class="pre">type</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'torch.nn.modules.activation.Hardswish'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Conv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Conv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Conv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Conv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Conv.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Conv.fuseforward">
<span class="sig-name descname"><span class="pre">fuseforward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Conv.fuseforward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Conv.fuseforward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Conv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Conv.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Focus">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">Focus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Focus"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Focus" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Focus.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#Focus.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Focus.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.Focus.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.Focus.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.NumClassesMissingException">
<em class="property"><span class="pre">exception</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">NumClassesMissingException</span></span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#NumClassesMissingException"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.NumClassesMissingException" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPP">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">SPP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">k</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(5,</span> <span class="pre">9,</span> <span class="pre">13)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#SPP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPP" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#SPP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPP.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPP.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPP.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPPF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">SPPF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_channels</span></em>, <em class="sig-param"><span class="pre">output_channels</span></em>, <em class="sig-param"><span class="pre">k:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">5</span></em>, <em class="sig-param"><span class="pre">width_mult_factor:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">1.0</span></em>, <em class="sig-param"><span class="pre">activation_func_type:</span> <span class="pre">type</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'torch.nn.modules.activation.SiLU'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#SPPF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPPF" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPPF.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#SPPF.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPPF.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.SPPF.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.SPPF.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.ViewModule">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">ViewModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#ViewModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.ViewModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Returns a reshaped version of the input, to be used in None-Backbone Mode</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.ViewModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#ViewModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.ViewModule.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.ViewModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.ViewModule.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.autopad">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">autopad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#autopad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.autopad" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.csp_darknet53.width_multiplier">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.csp_darknet53.</span></span><span class="sig-name descname"><span class="pre">width_multiplier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/csp_darknet53.html#width_multiplier"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.csp_darknet53.width_multiplier" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.darknet53">
<span id="super-gradients-training-models-darknet53-module"></span><h2>super_gradients.training.models.darknet53 module<a class="headerlink" href="#module-super_gradients.training.models.darknet53" title="Permalink to this headline"></a></h2>
<p>Darknet</p>
<p>credits: <a class="reference external" href="https://github.com/ultralytics">https://github.com/ultralytics</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.DarkResidualBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.darknet53.</span></span><span class="sig-name descname"><span class="pre">DarkResidualBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shortcut</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#DarkResidualBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.DarkResidualBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>DarkResidualBlock - The Darknet Residual Block</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.DarkResidualBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#DarkResidualBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.DarkResidualBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.DarkResidualBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.darknet53.DarkResidualBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.darknet53.</span></span><span class="sig-name descname"><span class="pre">Darknet53</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#Darknet53"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.darknet53.Darknet53Base" title="super_gradients.training.models.darknet53.Darknet53Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.darknet53.Darknet53Base</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#Darknet53.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>forward - Forward pass on the modules list</dt><dd><dl class="field-list simple">
<dt class="field-odd">param x</dt>
<dd class="field-odd"><p>The input data</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>forward pass for backbone pass or classification pass</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53.get_modules_list">
<span class="sig-name descname"><span class="pre">get_modules_list</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#Darknet53.get_modules_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53.get_modules_list" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53Base">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.darknet53.</span></span><span class="sig-name descname"><span class="pre">Darknet53Base</span></span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#Darknet53Base"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53Base" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53Base.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#Darknet53Base.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53Base.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.Darknet53Base.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.darknet53.Darknet53Base.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.ViewModule">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.darknet53.</span></span><span class="sig-name descname"><span class="pre">ViewModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1024</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#ViewModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.ViewModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Returns a reshaped version of the input, to be used in None-Backbone Mode</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.ViewModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#ViewModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.ViewModule.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.ViewModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.darknet53.ViewModule.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.darknet53.create_conv_module">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.darknet53.</span></span><span class="sig-name descname"><span class="pre">create_conv_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/darknet53.html#create_conv_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.darknet53.create_conv_module" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.ddrnet">
<span id="super-gradients-training-models-ddrnet-module"></span><h2>super_gradients.training.models.ddrnet module<a class="headerlink" href="#module-super_gradients.training.models.ddrnet" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.AnyBackBoneDDRNet23">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">AnyBackBoneDDRNet23</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#AnyBackBoneDDRNet23"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.AnyBackBoneDDRNet23" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRNetCustom" title="super_gradients.training.models.ddrnet.DDRNetCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRNetCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.AnyBackBoneDDRNet23.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.AnyBackBoneDDRNet23.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.BasicDDRBackBone">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">BasicDDRBackBone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#BasicDDRBackBone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.BasicDDRBackBone" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase" title="super_gradients.training.models.ddrnet.DDRBackBoneBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRBackBoneBase</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.BasicDDRBackBone.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.BasicDDRBackBone.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.ConvBN">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">ConvBN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">add_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#ConvBN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.ConvBN" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPM">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DAPPM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">branch_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_sizes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inter_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'bilinear'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DAPPM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPM" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPM.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DAPPM.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPM.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPM.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPM.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPMBranch">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DAPPMBranch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">branch_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inter_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'bilinear'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DAPPMBranch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPMBranch" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPMBranch.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DAPPMBranch.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPMBranch.forward" title="Permalink to this definition"></a></dt>
<dd><p>All branches of the DAPPM but the first one receive the output of the previous branch as a second input
:param x: in branch 0 - the original input of the DAPPM. in other branches - a list containing the original
input and the output of the previous branch.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DAPPMBranch.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DAPPMBranch.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRBackBoneBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DDRBackBoneBase</span></span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRBackBoneBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A base class defining functions that must be supported by DDRBackBones</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRBackBoneBase.get_backbone_output_number_of_channels">
<span class="sig-name descname"><span class="pre">get_backbone_output_number_of_channels</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRBackBoneBase.get_backbone_output_number_of_channels"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase.get_backbone_output_number_of_channels" title="Permalink to this definition"></a></dt>
<dd><p>Return a dictionary of the shapes of each output of the backbone to determine the in_channels of the
skip and compress layers</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRBackBoneBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRBackBoneBase.validate_backbone_attributes">
<span class="sig-name descname"><span class="pre">validate_backbone_attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRBackBoneBase.validate_backbone_attributes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase.validate_backbone_attributes" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DDRNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">backbone:</span> <span class="pre">type,</span> <span class="pre">additional_layers:</span> <span class="pre">list,</span> <span class="pre">upscale_module:</span> <span class="pre">torch.nn.modules.module.Module,</span> <span class="pre">num_classes:</span> <span class="pre">int,</span> <span class="pre">highres_planes:</span> <span class="pre">int,</span> <span class="pre">spp_width:</span> <span class="pre">int,</span> <span class="pre">head_width:</span> <span class="pre">int,</span> <span class="pre">aux_head:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">ssp_inter_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'bilinear',</span> <span class="pre">segmentation_inter_mode:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'bilinear',</span> <span class="pre">skip_block:</span> <span class="pre">Optional[type]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">layer5_block:</span> <span class="pre">type</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.models.resnet.Bottleneck'&gt;,</span> <span class="pre">layer5_bottleneck_expansion:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">2,</span> <span class="pre">classification_mode=False,</span> <span class="pre">spp_kernel_sizes:</span> <span class="pre">list</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">5,</span> <span class="pre">9,</span> <span class="pre">17,</span> <span class="pre">0],</span> <span class="pre">spp_strides:</span> <span class="pre">list</span> <span class="pre">=</span> <span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">4,</span> <span class="pre">8,</span> <span class="pre">0]</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet23">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DDRNet23</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRNet23"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet23" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRNetCustom" title="super_gradients.training.models.ddrnet.DDRNetCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRNetCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet23.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet23.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet23Slim">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DDRNet23Slim</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRNet23Slim"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet23Slim" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRNetCustom" title="super_gradients.training.models.ddrnet.DDRNetCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRNetCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNet23Slim.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNet23Slim.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNetCustom">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">DDRNetCustom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#DDRNetCustom"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNetCustom" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRNet" title="super_gradients.training.models.ddrnet.DDRNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.DDRNetCustom.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.DDRNetCustom.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.RegnetDDRBackBone">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">RegnetDDRBackBone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">regnet_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#RegnetDDRBackBone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.RegnetDDRBackBone" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ddrnet.DDRBackBoneBase" title="super_gradients.training.models.ddrnet.DDRBackBoneBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ddrnet.DDRBackBoneBase</span></code></a></p>
<p>Translation of Regnet to fit DDR model</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.RegnetDDRBackBone.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.RegnetDDRBackBone.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.SegmentHead">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">SegmentHead</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inter_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inter_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'bilinear'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#SegmentHead"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.SegmentHead" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.SegmentHead.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#SegmentHead.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.SegmentHead.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.SegmentHead.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.SegmentHead.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.UpscaleOnline">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ddrnet.</span></span><span class="sig-name descname"><span class="pre">UpscaleOnline</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'bilinear'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#UpscaleOnline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.UpscaleOnline" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>In some cases the required scale/size for the scaling is known only when the input is received.
This class support such cases. only the interpolation mode is set in advance.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.UpscaleOnline.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_height</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_width</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ddrnet.html#UpscaleOnline.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ddrnet.UpscaleOnline.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ddrnet.UpscaleOnline.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ddrnet.UpscaleOnline.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.densenet">
<span id="super-gradients-training-models-densenet-module"></span><h2>super_gradients.training.models.densenet module<a class="headerlink" href="#module-super_gradients.training.models.densenet" title="Permalink to this headline"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.CustomizedDensnet">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">CustomizedDensnet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#CustomizedDensnet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.CustomizedDensnet" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.DenseNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">DenseNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">growth_rate</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">structure</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_init_features</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bn_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_rate</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#DenseNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.DenseNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.DenseNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#DenseNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.DenseNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.DenseNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.densenet.DenseNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.densenet121">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">densenet121</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#densenet121"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.densenet121" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.densenet161">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">densenet161</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#densenet161"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.densenet161" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.densenet169">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">densenet169</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#densenet169"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.densenet169" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.densenet.densenet201">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.densenet.</span></span><span class="sig-name descname"><span class="pre">densenet201</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/densenet.html#densenet201"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.densenet.densenet201" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.dpn">
<span id="super-gradients-training-models-dpn-module"></span><h2>super_gradients.training.models.dpn module<a class="headerlink" href="#module-super_gradients.training.models.dpn" title="Permalink to this headline"></a></h2>
<p>Dual Path Networks in PyTorch.</p>
<p>Credits: <a class="reference external" href="https://github.com/kuangliu/pytorch-cifar/blob/master/models/dpn.py">https://github.com/kuangliu/pytorch-cifar/blob/master/models/dpn.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.Bottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.dpn.</span></span><span class="sig-name descname"><span class="pre">Bottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">last_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dense_depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#Bottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.Bottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.Bottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#Bottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.Bottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.Bottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.dpn.Bottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.DPN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.dpn.</span></span><span class="sig-name descname"><span class="pre">DPN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#DPN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.DPN" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.DPN.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#DPN.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.DPN.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.DPN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.dpn.DPN.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.DPN26">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.dpn.</span></span><span class="sig-name descname"><span class="pre">DPN26</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#DPN26"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.DPN26" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.DPN92">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.dpn.</span></span><span class="sig-name descname"><span class="pre">DPN92</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#DPN92"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.DPN92" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.dpn.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.dpn.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/dpn.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.dpn.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.efficientnet">
<span id="super-gradients-training-models-efficientnet-module"></span><h2>super_gradients.training.models.efficientnet module<a class="headerlink" href="#module-super_gradients.training.models.efficientnet" title="Permalink to this headline"></a></h2>
<p>EfficientNet model class, based on
“EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks” &lt;<a class="reference external" href="https://arxiv.org/abs/1905.11946">https://arxiv.org/abs/1905.11946</a>&gt;`
Code source: <a class="reference external" href="https://github.com/lukemelas/EfficientNet-PyTorch">https://github.com/lukemelas/EfficientNet-PyTorch</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">BlockArgs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_repeat</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_filters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_filters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">id_skip</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.expand_ratio">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">expand_ratio</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.expand_ratio" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.id_skip">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">id_skip</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.id_skip" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.input_filters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">input_filters</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.input_filters" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.kernel_size">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">kernel_size</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.kernel_size" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.num_repeat">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">num_repeat</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.num_repeat" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.output_filters">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">output_filters</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.output_filters" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.se_ratio">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">se_ratio</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.se_ratio" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockArgs.stride">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">stride</span></span><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockArgs.stride" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockDecoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">BlockDecoder</span></span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#BlockDecoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockDecoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Block Decoder for readability, straight from the official TensorFlow repository.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockDecoder.decode">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">decode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">string_list</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#BlockDecoder.decode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockDecoder.decode" title="Permalink to this definition"></a></dt>
<dd><p>Decode a list of string notations to specify blocks inside the network.
Args:</p>
<blockquote>
<div><p>string_list (list[str]): A list of strings, each string is a notation of block.</p>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>blocks_args: A list of BlockArgs namedtuples of block args.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.BlockDecoder.encode">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">blocks_args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#BlockDecoder.encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.BlockDecoder.encode" title="Permalink to this definition"></a></dt>
<dd><p>Encode a list of BlockArgs to a list of strings.
Args:</p>
<blockquote>
<div><p>blocks_args (list[namedtuples]): A list of BlockArgs namedtuples of block args.</p>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>block_strings: A list of strings, each string is a notation of block.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">Conv2dDynamicSamePadding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Conv2dDynamicSamePadding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code></p>
<p>2D Convolutions like TensorFlow, for a dynamic image size.
The padding is operated in forward function by calculating dynamically.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.bias">
<span class="sig-name descname"><span class="pre">bias</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.bias" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Conv2dDynamicSamePadding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.output_padding">
<span class="sig-name descname"><span class="pre">output_padding</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.output_padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><em class="property"><span class="pre">:</span> <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.padding_mode">
<span class="sig-name descname"><span class="pre">padding_mode</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.padding_mode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.transposed">
<span class="sig-name descname"><span class="pre">transposed</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.transposed" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Tensor</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dDynamicSamePadding.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">Conv2dStaticSamePadding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Conv2dStaticSamePadding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.conv.Conv2d</span></code></p>
<p>2D Convolutions like TensorFlow’s ‘SAME’ mode, with the given input image size.
The padding mudule is calculated in construction function, then used in forward.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.bias">
<span class="sig-name descname"><span class="pre">bias</span></span><em class="property"><span class="pre">:</span> <span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.bias" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.dilation">
<span class="sig-name descname"><span class="pre">dilation</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.dilation" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Conv2dStaticSamePadding.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.groups">
<span class="sig-name descname"><span class="pre">groups</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.groups" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.kernel_size">
<span class="sig-name descname"><span class="pre">kernel_size</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.kernel_size" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.out_channels">
<span class="sig-name descname"><span class="pre">out_channels</span></span><em class="property"><span class="pre">:</span> <span class="pre">int</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.out_channels" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.output_padding">
<span class="sig-name descname"><span class="pre">output_padding</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.output_padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.padding">
<span class="sig-name descname"><span class="pre">padding</span></span><em class="property"><span class="pre">:</span> <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.padding" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.padding_mode">
<span class="sig-name descname"><span class="pre">padding_mode</span></span><em class="property"><span class="pre">:</span> <span class="pre">str</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.padding_mode" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.stride">
<span class="sig-name descname"><span class="pre">stride</span></span><em class="property"><span class="pre">:</span> <span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.stride" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.transposed">
<span class="sig-name descname"><span class="pre">transposed</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.transposed" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.weight">
<span class="sig-name descname"><span class="pre">weight</span></span><em class="property"><span class="pre">:</span> <span class="pre">torch.Tensor</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Conv2dStaticSamePadding.weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.CustomizedEfficientnet">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">CustomizedEfficientnet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#CustomizedEfficientnet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.CustomizedEfficientnet" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.EfficientNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">EfficientNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">blocks_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#EfficientNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.EfficientNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<p>EfficientNet model.
Args:</p>
<blockquote>
<div><p>blocks_args (list[namedtuple]): A list of BlockArgs to construct blocks.
arch_params (HpmStruct): A set of global params shared between blocks.</p>
</div></blockquote>
<dl class="simple">
<dt>References:</dt><dd><p>[1] <a class="reference external" href="https://arxiv.org/abs/1905.11946">https://arxiv.org/abs/1905.11946</a> (EfficientNet)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.EfficientNet.extract_features">
<span class="sig-name descname"><span class="pre">extract_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#EfficientNet.extract_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.EfficientNet.extract_features" title="Permalink to this definition"></a></dt>
<dd><p>Use convolution layer to extract feature.
Args:</p>
<blockquote>
<div><p>inputs (tensor): Input tensor.</p>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>Output of the final convolution.
layer in the efficientnet model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.EfficientNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#EfficientNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.EfficientNet.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>EfficientNet’s forward function.</dt><dd><p>Calls extract_features to extract features, applies final linear layer, and returns logits.</p>
</dd>
<dt>Args:</dt><dd><p>inputs (tensor): Input tensor.</p>
</dd>
<dt>Returns:</dt><dd><p>Output of this model after processing.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.EfficientNet.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#EfficientNet.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.EfficientNet.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>load_state_dict - Overloads the base method and calls it to load a modified dict for usage as a backbone
:param state_dict:  The state_dict to load
:param strict:      strict loading (see super() docs)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.EfficientNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.EfficientNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Identity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">Identity</span></span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Identity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Identity" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Identity mapping.
Send input to output directly.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Identity.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#Identity.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.Identity.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.Identity.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.Identity.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.MBConvBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">MBConvBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block_args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_norm_momentum</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_norm_epsilon</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#MBConvBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.MBConvBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Mobile Inverted Residual Bottleneck Block.
Args:</p>
<blockquote>
<div><p>block_args (namedtuple): BlockArgs.
arch_params (HpmStruct): HpmStruct.
image_size (tuple or list): [image_height, image_width].</p>
</div></blockquote>
<dl class="simple">
<dt>References:</dt><dd><p>[1] <a class="reference external" href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a> (MobileNet v1)
[2] <a class="reference external" href="https://arxiv.org/abs/1801.04381">https://arxiv.org/abs/1801.04381</a> (MobileNet v2)
[3] <a class="reference external" href="https://arxiv.org/abs/1905.02244">https://arxiv.org/abs/1905.02244</a> (MobileNet v3)</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.MBConvBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_connect_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#MBConvBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.MBConvBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>MBConvBlock’s forward function.
Args:</p>
<blockquote>
<div><p>inputs (tensor): Input tensor.
drop_connect_rate (bool): Drop connect rate (float, between 0 and 1).</p>
</div></blockquote>
<dl class="simple">
<dt>Returns:</dt><dd><p>Output of this block after processing.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.MBConvBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.efficientnet.MBConvBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b0">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b0"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b0" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b1">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b3">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b3" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b4">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b4</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b4"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b4" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b5">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b5" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b6">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b6</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b6"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b6" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b7">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b7</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b7"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b7" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.b8">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">b8</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#b8"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.b8" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.build_efficientnet">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">build_efficientnet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">res</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#build_efficientnet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.build_efficientnet" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>width</strong> – </p></li>
<li><p><strong>depth</strong> – </p></li>
<li><p><strong>res</strong> – </p></li>
<li><p><strong>dropout</strong> – </p></li>
<li><p><strong>arch_params</strong> – </p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.calculate_output_image_size">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">calculate_output_image_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_image_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#calculate_output_image_size"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.calculate_output_image_size" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculates the output image size when using Conv2dSamePadding with a stride.</dt><dd><p>Necessary for static padding. Thanks to mannatsingh for pointing this out.</p>
</dd>
<dt>Args:</dt><dd><p>input_image_size (int, tuple or list): Size of input image.
stride (int, tuple or list): Conv2d operation’s stride.</p>
</dd>
<dt>Returns:</dt><dd><p>output_image_size: A list [H,W].</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.drop_connect">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">drop_connect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#drop_connect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.drop_connect" title="Permalink to this definition"></a></dt>
<dd><p>Drop connect.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>inputs (tensor: BCWH): Input of this structure.
p (float: 0.0~1.0): Probability of drop connection.
training (bool): The running mode.</p>
</dd>
<dt>Returns:</dt><dd><p>output: Output after drop connection.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.get_same_padding_conv2d">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">get_same_padding_conv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#get_same_padding_conv2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.get_same_padding_conv2d" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Chooses static padding if you have specified an image size, and dynamic padding otherwise.</dt><dd><p>Static padding is necessary for ONNX exporting of models.</p>
</dd>
<dt>Args:</dt><dd><p>image_size (int or tuple): Size of the image.</p>
</dd>
<dt>Returns:</dt><dd><p>Conv2dDynamicSamePadding or Conv2dStaticSamePadding.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.l2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">l2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#l2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.l2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.round_filters">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">round_filters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_coefficient</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth_divisor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_depth</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#round_filters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.round_filters" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate and round number of filters based on width multiplier.</dt><dd><p>Use width_coefficient, depth_divisor and min_depth.</p>
</dd>
<dt>Args:</dt><dd><p>filters (int): Filters number to be calculated.
Params from arch_params:
width_coefficient (int): model’s width coefficient. Used as the multiplier.
depth_divisor (int): model’s depth divisor. Used as the divisor.
and min_depth (int): model’s minimal depth, if given.</p>
</dd>
<dt>Returns:</dt><dd><p>new_filters: New filters number after calculating.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.efficientnet.round_repeats">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.efficientnet.</span></span><span class="sig-name descname"><span class="pre">round_repeats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">repeats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth_coefficient</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/efficientnet.html#round_repeats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.efficientnet.round_repeats" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Calculate module’s repeat number of a block based on depth multiplier.</dt><dd><p>Use depth_coefficient.</p>
</dd>
<dt>Args:</dt><dd><p>repeats (int): num_repeat to be calculated.
depth_coefficient (int): the depth coefficient of the model. this func uses it as the multiplier.</p>
</dd>
<dt>Returns:</dt><dd><p>new repeat: New repeat number after calculating.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.googlenet">
<span id="super-gradients-training-models-googlenet-module"></span><h2>super_gradients.training.models.googlenet module<a class="headerlink" href="#module-super_gradients.training.models.googlenet" title="Permalink to this headline"></a></h2>
<p>Googlenet code based on <a class="reference external" href="https://pytorch.org/vision/stable/_modules/torchvision/models/googlenet.html">https://pytorch.org/vision/stable/_modules/torchvision/models/googlenet.html</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.BasicConv2d">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">BasicConv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#BasicConv2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.BasicConv2d" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.BasicConv2d.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#BasicConv2d.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.BasicConv2d.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.BasicConv2d.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.googlenet.BasicConv2d.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">GoogLeNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_logits</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#GoogLeNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#GoogLeNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNet.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#GoogLeNet.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNet.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>load_state_dict - Overloads the base method and calls it to load a modified dict for usage as a backbone
:param state_dict:  The state_dict to load
:param strict:      strict loading (see super() docs)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNetOutputs">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">GoogLeNetOutputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">log_</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_logits2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux_logits1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNetOutputs" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p>
<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNetOutputs.aux_logits1">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">aux_logits1</span></span><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNetOutputs.aux_logits1" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNetOutputs.aux_logits2">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">aux_logits2</span></span><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNetOutputs.aux_logits2" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.GoogLeNetOutputs.log_">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">log_</span></span><a class="headerlink" href="#super_gradients.training.models.googlenet.GoogLeNetOutputs.log_" title="Permalink to this definition"></a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.Inception">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">Inception</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ch1x1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ch3x3red</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ch3x3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ch5x5red</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ch5x5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pool_proj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#Inception"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.Inception" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.Inception.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#Inception.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.Inception.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.Inception.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.googlenet.Inception.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.InceptionAux">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">InceptionAux</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conv_block</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#InceptionAux"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.InceptionAux" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.InceptionAux.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#InceptionAux.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.InceptionAux.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.InceptionAux.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.googlenet.InceptionAux.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.googlenet.googlenet_v1">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.googlenet.</span></span><span class="sig-name descname"><span class="pre">googlenet_v1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/googlenet.html#googlenet_v1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.googlenet.googlenet_v1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.laddernet">
<span id="super-gradients-training-models-laddernet-module"></span><h2>super_gradients.training.models.laddernet module<a class="headerlink" href="#module-super_gradients.training.models.laddernet" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BaseNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">BaseNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nclass</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">aux</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilated</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">576</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">crop_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">608</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.485,</span> <span class="pre">0.456,</span> <span class="pre">0.406]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">std</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.229,</span> <span class="pre">0.224,</span> <span class="pre">0.225]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'~/.encoding/models'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#BaseNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.BaseNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BaseNet.base_forward">
<span class="sig-name descname"><span class="pre">base_forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#BaseNet.base_forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.BaseNet.base_forward" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BaseNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.BaseNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BasicBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">BasicBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplanes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#BasicBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.BasicBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BasicBlock.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">1</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.BasicBlock.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BasicBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#BasicBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.BasicBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.BasicBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.BasicBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Bottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">Bottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplanes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Bottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Bottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Bottleneck.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">4</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.Bottleneck.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Bottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Bottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Bottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Bottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.Bottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Decoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">Decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">kernel=3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.laddernet.BasicBlock'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Decoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Decoder" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Decoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Decoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Decoder.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Decoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.Decoder.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.FCNHead">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">FCNHead</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_layer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#FCNHead"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.FCNHead" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.FCNHead.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#FCNHead.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.FCNHead.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.FCNHead.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.FCNHead.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Final_LadderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">Final_LadderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">kernel=3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.laddernet.BasicBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">inplanes=3</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Final_LadderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Final_LadderBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Final_LadderBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Final_LadderBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Final_LadderBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Final_LadderBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.Final_LadderBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Initial_LadderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">Initial_LadderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">kernel=3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.laddernet.BasicBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">inplanes=3</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Initial_LadderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Initial_LadderBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Initial_LadderBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#Initial_LadderBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.Initial_LadderBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.Initial_LadderBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.Initial_LadderBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">kernel=3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.laddernet.BasicBlock'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderBottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplanes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">previous_dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderBottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>ResNet Bottleneck</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBottleneck.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">4</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBottleneck.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderBottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderBottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderBottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderHead">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderHead</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_inchannels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_outchannels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nclass</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">up_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderHead"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderHead" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderHead.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderHead.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderHead.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderHead.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderHead.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">nclass</span></em>, <em class="sig-param"><span class="pre">backbone</span></em>, <em class="sig-param"><span class="pre">aux=True</span></em>, <em class="sig-param"><span class="pre">se_loss=True</span></em>, <em class="sig-param"><span class="pre">lateral=False</span></em>, <em class="sig-param"><span class="pre">arch_params=None</span></em>, <em class="sig-param"><span class="pre">norm_layer=&lt;class</span> <span class="pre">'torch.nn.modules.batchnorm.BatchNorm2d'&gt;</span></em>, <em class="sig-param"><span class="pre">dilated=False</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.BaseNet" title="super_gradients.training.models.laddernet.BaseNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.BaseNet</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet101">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNet101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNet101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet101" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderNet" title="super_gradients.training.models.laddernet.LadderNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet101.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet101.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet50">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNet50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNet50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet50" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderNet" title="super_gradients.training.models.laddernet.LadderNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet50.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet50.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet503433">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNet503433</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNet503433"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet503433" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderNet" title="super_gradients.training.models.laddernet.LadderNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNet503433.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNet503433.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone101">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNetBackBone101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNetBackBone101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone101" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderResNet" title="super_gradients.training.models.laddernet.LadderResNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderResNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone101.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone101.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone50">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNetBackBone50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNetBackBone50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone50" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderResNet" title="super_gradients.training.models.laddernet.LadderResNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderResNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone50.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone50.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone503433">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderNetBackBone503433</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderNetBackBone503433"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone503433" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.laddernet.LadderResNet" title="super_gradients.training.models.laddernet.LadderResNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.laddernet.LadderResNet</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderNetBackBone503433.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderNetBackBone503433.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderResNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">LadderResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">block</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">num_classes=1000</span></em>, <em class="sig-param"><span class="pre">dilated=False</span></em>, <em class="sig-param"><span class="pre">norm_layer=&lt;class</span> <span class="pre">'torch.nn.modules.batchnorm.BatchNorm2d'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderResNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderResNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Dilated Pre-trained ResNet Model, which preduces the stride of 8 featuremaps at conv5.</p>
<dl class="simple">
<dt>block<span class="classifier">Block</span></dt><dd><p>Class for the residual block. Options are BasicBlockV1, BottleneckV1.</p>
</dd>
<dt>layers<span class="classifier">list of int</span></dt><dd><p>Numbers of layers in each block</p>
</dd>
<dt>classes<span class="classifier">int, default 1000</span></dt><dd><p>Number of classification classes.</p>
</dd>
<dt>dilated<span class="classifier">bool, default False</span></dt><dd><p>Applying dilation strategy to pretrained ResNet yielding a stride-8 model,
typically used in Semantic Segmentation.</p>
</dd>
<dt>norm_layer<span class="classifier">object</span></dt><dd><p>Normalization layer used in backbone network (default: <code class="xref py py-class docutils literal notranslate"><span class="pre">mxnet.gluon.nn.BatchNorm</span></code>;
for Synchronized Cross-GPU BachNormalization).</p>
</dd>
</dl>
<p>Reference:</p>
<blockquote>
<div><ul class="simple">
<li><p>He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.</p></li>
<li><p>Yu, Fisher, and Vladlen Koltun. “Multi-scale context aggregation by dilated convolutions.”</p></li>
</ul>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderResNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#LadderResNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderResNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.LadderResNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.laddernet.LadderResNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.laddernet.conv3x3">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.laddernet.</span></span><span class="sig-name descname"><span class="pre">conv3x3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/laddernet.html#conv3x3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.laddernet.conv3x3" title="Permalink to this definition"></a></dt>
<dd><p>3x3 convolution with padding</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.lenet">
<span id="super-gradients-training-models-lenet-module"></span><h2>super_gradients.training.models.lenet module<a class="headerlink" href="#module-super_gradients.training.models.lenet" title="Permalink to this headline"></a></h2>
<p>LeNet in PyTorch.</p>
<p><a class="reference external" href="https://yann.lecun.com/exdb/lenet/">https://yann.lecun.com/exdb/lenet/</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.lenet.LeNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.lenet.</span></span><span class="sig-name descname"><span class="pre">LeNet</span></span><a class="reference internal" href="_modules/super_gradients/training/models/lenet.html#LeNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.lenet.LeNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.lenet.LeNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/lenet.html#LeNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.lenet.LeNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.lenet.LeNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.lenet.LeNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.mobilenet">
<span id="super-gradients-training-models-mobilenet-module"></span><h2>super_gradients.training.models.mobilenet module<a class="headerlink" href="#module-super_gradients.training.models.mobilenet" title="Permalink to this headline"></a></h2>
<p>MobileNet in PyTorch.</p>
<p>See the paper “MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications”
for more details.</p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.Block">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenet.</span></span><span class="sig-name descname"><span class="pre">Block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenet.html#Block"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenet.Block" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Depthwise conv + Pointwise conv</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.Block.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenet.html#Block.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenet.Block.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.Block.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenet.Block.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.MobileNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenet.</span></span><span class="sig-name descname"><span class="pre">MobileNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">up_to_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenet.html#MobileNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenet.MobileNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.MobileNet.cfg">
<span class="sig-name descname"><span class="pre">cfg</span></span><em class="property"> <span class="pre">=</span> <span class="pre">[64,</span> <span class="pre">128,</span> <span class="pre">(128,</span> <span class="pre">2),</span> <span class="pre">256,</span> <span class="pre">(256,</span> <span class="pre">2),</span> <span class="pre">512,</span> <span class="pre">512,</span> <span class="pre">512,</span> <span class="pre">512,</span> <span class="pre">512,</span> <span class="pre">(512,</span> <span class="pre">2),</span> <span class="pre">1024,</span> <span class="pre">(1024,</span> <span class="pre">2)]</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenet.MobileNet.cfg" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.MobileNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenet.html#MobileNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenet.MobileNet.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>up_to_layer</strong> – forward through the net layers up to a specific layer. if None, run all layers</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenet.MobileNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenet.MobileNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.mobilenetv2">
<span id="super-gradients-training-models-mobilenetv2-module"></span><h2>super_gradients.training.models.mobilenetv2 module<a class="headerlink" href="#module-super_gradients.training.models.mobilenetv2" title="Permalink to this headline"></a></h2>
<p>This is a PyTorch implementation of MobileNetV2 architecture as described in the paper:
Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation.
<a class="reference external" href="https://arxiv.org/pdf/1801.04381">https://arxiv.org/pdf/1801.04381</a></p>
<p>Code taken from <a class="reference external" href="https://github.com/tonylins/pytorch-mobilenet-v2">https://github.com/tonylins/pytorch-mobilenet-v2</a>
License: Apache Version 2.0, January 2004 <a class="reference external" href="http://www.apache.org/licenses/">http://www.apache.org/licenses/</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.InvertedResidual">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">InvertedResidual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expand_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grouped_conv_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#InvertedResidual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.InvertedResidual" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.InvertedResidual.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#InvertedResidual.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.InvertedResidual.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.InvertedResidual.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.InvertedResidual.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.MobileNetV2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">MobileNetV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">structure</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grouped_conv_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#MobileNetV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.MobileNetV2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.MobileNetV2.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#MobileNetV2.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.MobileNetV2.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.MobileNetV2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.MobileNetV2.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.conv_1x1_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">conv_1x1_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#conv_1x1_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.conv_1x1_bn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.conv_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">conv_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#conv_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.conv_bn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.custom_mobile_net_v2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">custom_mobile_net_v2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#custom_mobile_net_v2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.custom_mobile_net_v2" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arch_params</strong> – <p>HpmStruct
must contain:</p>
<blockquote>
<div><p>’num_classes’: int
‘width_mult’: float
‘structure’ : list. specify the mobilenetv2 architecture</p>
</div></blockquote>
</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MobileNetV2: nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.make_divisible">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">make_divisible</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">divisible_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#make_divisible"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.make_divisible" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.mobile_net_v2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">mobile_net_v2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#mobile_net_v2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.mobile_net_v2" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>arch_params</strong> – HpmStruct
must contain: ‘num_classes’: int</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>MobileNetV2: nn.Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv2.mobile_net_v2_135">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv2.</span></span><span class="sig-name descname"><span class="pre">mobile_net_v2_135</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv2.html#mobile_net_v2_135"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv2.mobile_net_v2_135" title="Permalink to this definition"></a></dt>
<dd><p>This Model achieves 75.73% on Imagenet - similar to Resnet50
:param arch_params: HpmStruct</p>
<blockquote>
<div><p>must contain: ‘num_classes’: int</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>MobileNetV2: nn.Module</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.mobilenetv3">
<span id="super-gradients-training-models-mobilenetv3-module"></span><h2>super_gradients.training.models.mobilenetv3 module<a class="headerlink" href="#module-super_gradients.training.models.mobilenetv3" title="Permalink to this headline"></a></h2>
<p>Creates a MobileNetV3 Model as defined in:
Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, Hartwig Adam. (2019).
Searching for MobileNetV3
arXiv preprint arXiv:1905.02244.</p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.InvertedResidual">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">InvertedResidual</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_se</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_hs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#InvertedResidual"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.InvertedResidual" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.InvertedResidual.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#InvertedResidual.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.InvertedResidual.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.InvertedResidual.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.InvertedResidual.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.MobileNetV3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">MobileNetV3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfgs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#MobileNetV3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.MobileNetV3" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.MobileNetV3.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#MobileNetV3.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.MobileNetV3.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.MobileNetV3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.MobileNetV3.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.SELayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">SELayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#SELayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.SELayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.SELayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#SELayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.SELayer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.SELayer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.SELayer.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.conv_1x1_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">conv_1x1_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#conv_1x1_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.conv_1x1_bn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.conv_3x3_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">conv_3x3_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oup</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#conv_3x3_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.conv_3x3_bn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_sigmoid">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">h_sigmoid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#h_sigmoid"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_sigmoid" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_sigmoid.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#h_sigmoid.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_sigmoid.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_sigmoid.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_sigmoid.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_swish">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">h_swish</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplace</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#h_swish"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_swish" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_swish.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#h_swish.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_swish.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.h_swish.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.h_swish.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.mobilenetv3_custom">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">mobilenetv3_custom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#mobilenetv3_custom"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.mobilenetv3_custom" title="Permalink to this definition"></a></dt>
<dd><p>Constructs a MobileNetV3-Customized model</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.mobilenetv3_large">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">mobilenetv3_large</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#mobilenetv3_large"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.mobilenetv3_large" title="Permalink to this definition"></a></dt>
<dd><p>Constructs a MobileNetV3-Large model</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.mobilenetv3.mobilenetv3_small">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.mobilenetv3.</span></span><span class="sig-name descname"><span class="pre">mobilenetv3_small</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/mobilenetv3.html#mobilenetv3_small"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.mobilenetv3.mobilenetv3_small" title="Permalink to this definition"></a></dt>
<dd><p>Constructs a MobileNetV3-Small model</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.pnasnet">
<span id="super-gradients-training-models-pnasnet-module"></span><h2>super_gradients.training.models.pnasnet module<a class="headerlink" href="#module-super_gradients.training.models.pnasnet" title="Permalink to this headline"></a></h2>
<p>PNASNet in PyTorch.</p>
<p>Paper: Progressive Neural Architecture Search</p>
<p><a class="reference external" href="https://github.com/kuangliu/pytorch-cifar/blob/master/models/pnasnet.py">https://github.com/kuangliu/pytorch-cifar/blob/master/models/pnasnet.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellA">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">CellA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#CellA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellA" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellA.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#CellA.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellA.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellA.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellA.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellB">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">CellB</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#CellB"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellB" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellB.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#CellB.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellB.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.CellB.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.pnasnet.CellB.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.PNASNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">PNASNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cell_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_cells</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_planes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#PNASNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.PNASNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.PNASNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#PNASNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.PNASNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.PNASNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.pnasnet.PNASNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.PNASNetA">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">PNASNetA</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#PNASNetA"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.PNASNetA" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.PNASNetB">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">PNASNetB</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#PNASNetB"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.PNASNetB" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.SepConv">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">SepConv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#SepConv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.SepConv" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Separable Convolution.</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.SepConv.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#SepConv.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.SepConv.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.SepConv.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.pnasnet.SepConv.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.pnasnet.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.pnasnet.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/pnasnet.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.pnasnet.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.preact_resnet">
<span id="super-gradients-training-models-preact-resnet-module"></span><h2>super_gradients.training.models.preact_resnet module<a class="headerlink" href="#module-super_gradients.training.models.preact_resnet" title="Permalink to this headline"></a></h2>
<p>Pre-activation ResNet in PyTorch.</p>
<p>Reference:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<blockquote>
<div><p>Identity Mappings in Deep Residual Networks. arXiv:1603.05027</p>
</div></blockquote>
<p>Based on <a class="reference external" href="https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py">https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Pre-activation version of the BasicBlock.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBlock.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">1</span></em><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBlock.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActBottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActBottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Pre-activation version of the original Bottleneck module.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBottleneck.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">4</span></em><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBottleneck.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActBottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActBottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActBottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet101">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet101</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet101" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet152">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet152</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet152"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet152" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet18">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet18</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet18"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet18" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet34">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet34</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet34"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet34" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.PreActResNet50">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">PreActResNet50</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#PreActResNet50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.PreActResNet50" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.preact_resnet.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.preact_resnet.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/preact_resnet.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.preact_resnet.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.regnet">
<span id="super-gradients-training-models-regnet-module"></span><h2>super_gradients.training.models.regnet module<a class="headerlink" href="#module-super_gradients.training.models.regnet" title="Permalink to this headline"></a></h2>
<p>Regnet - from paper: Designing Network Design Spaces - <a class="reference external" href="https://arxiv.org/pdf/2003.13678.pdf">https://arxiv.org/pdf/2003.13678.pdf</a>
Implementation of paradigm described in paper published by Facebook AI Research (FAIR)
&#64;author: Signatrix GmbH
Code taken from: <a class="reference external" href="https://github.com/signatrix/regnet">https://github.com/signatrix/regnet</a> - MIT Licence</p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.AnyNetX">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">AnyNetX</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ls_num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_block_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_group_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">droppath_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#AnyNetX"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.AnyNetX" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.AnyNetX.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#AnyNetX.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.AnyNetX.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.AnyNetX.initialize_weight">
<span class="sig-name descname"><span class="pre">initialize_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#AnyNetX.initialize_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.AnyNetX.initialize_weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.AnyNetX.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.AnyNetX.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.CustomRegNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">CustomRegNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#CustomRegNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.CustomRegNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetX" title="super_gradients.training.models.regnet.RegNetX"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetX</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.CustomRegNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.CustomRegNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Head">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">Head</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout_prob</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Head"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Head" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Head.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Head.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Head.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Head.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.Head.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.NASRegNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">NASRegNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#NASRegNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.NASRegNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetX" title="super_gradients.training.models.regnet.RegNetX"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetX</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.NASRegNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.NASRegNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetX">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetX</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slope</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantized_param</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network_depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetX"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetX" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.AnyNetX" title="super_gradients.training.models.regnet.AnyNetX"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.AnyNetX</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetX.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetX.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetY</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">initial_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slope</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantized_param</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">network_depth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetY"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetX" title="super_gradients.training.models.regnet.RegNetX"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetX</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY200">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetY200</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetY200"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY200" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetY" title="super_gradients.training.models.regnet.RegNetY"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetY</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY200.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY200.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY400">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetY400</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetY400"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY400" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetY" title="super_gradients.training.models.regnet.RegNetY"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetY</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY400.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY400.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY600">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetY600</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetY600"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY600" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetY" title="super_gradients.training.models.regnet.RegNetY"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetY</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY600.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY600.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY800">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">RegNetY800</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#RegNetY800"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY800" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.regnet.RegNetY" title="super_gradients.training.models.regnet.RegNetY"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.regnet.RegNetY</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.RegNetY800.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.RegNetY800.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stage">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">Stage</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">droppath_prob</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Stage"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Stage" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stage.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Stage.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Stage.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stage.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.Stage.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stem">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">Stem</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Stem"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Stem" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stem.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#Stem.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.Stem.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.Stem.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.Stem.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.XBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">XBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">group_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">se_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">droppath_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#XBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.XBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.XBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#XBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.XBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.XBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.regnet.XBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.regnet.verify_correctness_of_parameters">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.regnet.</span></span><span class="sig-name descname"><span class="pre">verify_correctness_of_parameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ls_num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_block_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_bottleneck_ratio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ls_group_width</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/regnet.html#verify_correctness_of_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.regnet.verify_correctness_of_parameters" title="Permalink to this definition"></a></dt>
<dd><p>VERIFY THAT THE GIVEN PARAMETERS FIT THE SEARCH SPACE DEFINED IN THE REGNET PAPER</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.repvgg">
<span id="super-gradients-training-models-repvgg-module"></span><h2>super_gradients.training.models.repvgg module<a class="headerlink" href="#module-super_gradients.training.models.repvgg" title="Permalink to this headline"></a></h2>
<p>Repvgg Pytorch Implementation. This model trains a vgg with residual blocks
but during inference (in deployment mode) will convert the model to vgg model.
Pretrained models: <a class="reference external" href="https://drive.google.com/drive/folders/1Avome4KvNp0Lqh2QwhXO6L5URQjzCjUq">https://drive.google.com/drive/folders/1Avome4KvNp0Lqh2QwhXO6L5URQjzCjUq</a>
Refrerences:</p>
<blockquote>
<div><p>[1] <a class="reference external" href="https://github.com/DingXiaoH/RepVGG">https://github.com/DingXiaoH/RepVGG</a>
[2] <a class="reference external" href="https://arxiv.org/pdf/2101.03697.pdf">https://arxiv.org/pdf/2101.03697.pdf</a></p>
</div></blockquote>
<p>Based on <a class="reference external" href="https://github.com/DingXiaoH/RepVGG">https://github.com/DingXiaoH/RepVGG</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGG">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVGG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">struct</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_multiplier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">build_residual_branches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_se</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGG" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGG.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGG.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGG.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGG.prep_model_for_conversion">
<span class="sig-name descname"><span class="pre">prep_model_for_conversion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGG.prep_model_for_conversion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGG.prep_model_for_conversion" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the model to be converted to ONNX or other frameworks.
Typically, this function will freeze the size of layers which is otherwise flexible, replace some modules
with convertible substitutes and remove all auxiliary or training related parts.
:param input_size: [H,W]</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGG.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGG.train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGG.train" title="Permalink to this definition"></a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>mode (bool): whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation</dt><dd><p>mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Module: self</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGG.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGG.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGGBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVGGBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">build_residual_branches</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_se</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGGBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGGBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Repvgg block consists of three branches
3x3: a branch of a 3x3 convolution + batchnorm + relu
1x1: a branch of a 1x1 convolution + batchnorm + relu
no_conv_branch: a branch with only batchnorm which will only be used if input channel == output channel
(usually in all but the first block of each stage)</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGGBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGGBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGGBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGGBlock.fuse_block_residual_branches">
<span class="sig-name descname"><span class="pre">fuse_block_residual_branches</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVGGBlock.fuse_block_residual_branches"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGGBlock.fuse_block_residual_branches" title="Permalink to this definition"></a></dt>
<dd><p>converts a repvgg block from training model (with branches) to deployment mode (vgg like model)
:return:
:rtype:</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVGGBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVGGBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA0">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggA0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggA0"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA0" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA0.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA0.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA1">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggA1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggA1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA1" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA1.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA1.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggA2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggA2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggA2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggA2.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB0">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggB0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggB0"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB0" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB0.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB0.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB1">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggB1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggB1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB1" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB1.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB1.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggB2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggB2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB2.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggB3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggB3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB3" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggB3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggB3.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggCustom">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggCustom</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggCustom"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggCustom" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVGG" title="super_gradients.training.models.repvgg.RepVGG"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVGG</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggCustom.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggCustom.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggD2SE">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">RepVggD2SE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#RepVggD2SE"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggD2SE" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.repvgg.RepVggCustom" title="super_gradients.training.models.repvgg.RepVggCustom"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.repvgg.RepVggCustom</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.RepVggD2SE.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.RepVggD2SE.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.SEBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">SEBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_neurons</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#SEBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.SEBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.SEBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#SEBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.SEBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.SEBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.repvgg.SEBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.repvgg.conv_bn">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.repvgg.</span></span><span class="sig-name descname"><span class="pre">conv_bn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/repvgg.html#conv_bn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.repvgg.conv_bn" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.resnet">
<span id="super-gradients-training-models-resnet-module"></span><h2>super_gradients.training.models.resnet module<a class="headerlink" href="#module-super_gradients.training.models.resnet" title="Permalink to this headline"></a></h2>
<p>ResNet in PyTorch.
For Pre-activation ResNet, see ‘preact_resnet.py’.
Reference:
[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun</p>
<blockquote>
<div><p>Deep Residual Learning for Image Recognition. arXiv:1512.03385</p>
</div></blockquote>
<p>Code adapted from <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.BasicBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">BasicBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expansion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#BasicBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.BasicBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.BasicBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#BasicBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.BasicBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.BasicBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnet.BasicBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.Bottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">Bottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expansion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_relu</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#Bottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.Bottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.Bottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#Bottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.Bottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.Bottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnet.Bottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CifarResNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">CifarResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expansion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CifarResNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CifarResNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CifarResNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CifarResNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CifarResNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CifarResNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnet.CifarResNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CustomizedResnet">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">CustomizedResnet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CustomizedResnet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CustomizedResnet" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CustomizedResnet50">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">CustomizedResnet50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CustomizedResnet50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CustomizedResnet50" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CustomizedResnet50Cifar">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">CustomizedResnet50Cifar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CustomizedResnet50Cifar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CustomizedResnet50Cifar" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.CustomizedResnetCifar">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">CustomizedResnetCifar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#CustomizedResnetCifar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.CustomizedResnetCifar" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expansion</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_batchnorm</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>load_state_dict - Overloads the base method and calls it to load a modified dict for usage as a backbone
:param state_dict:  The state_dict to load
:param strict:      strict loading (see super() docs)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet101">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet101" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet152">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet152</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet152"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet152" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet18">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet18</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet18"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet18" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet18Cifar">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet18Cifar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet18Cifar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet18Cifar" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet34">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet34</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet34"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet34" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet50">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet50" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.ResNet50_3343">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">ResNet50_3343</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#ResNet50_3343"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.ResNet50_3343" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnet.width_multiplier">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnet.</span></span><span class="sig-name descname"><span class="pre">width_multiplier</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">original</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnet.html#width_multiplier"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnet.width_multiplier" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.resnext">
<span id="super-gradients-training-models-resnext-module"></span><h2>super_gradients.training.models.resnext module<a class="headerlink" href="#module-super_gradients.training.models.resnext" title="Permalink to this headline"></a></h2>
<p>ResNeXt in PyTorch.</p>
<p>See the paper “Aggregated Residual Transformations for Deep Neural Networks” for more details.</p>
<p>Code adapted from <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py">https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py</a></p>
<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.CustomizedResNeXt">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">CustomizedResNeXt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#CustomizedResNeXt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.CustomizedResNeXt" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.GroupedConvBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">GroupedConvBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inplanes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">downsample</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">norm_layer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#GroupedConvBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.GroupedConvBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Grouped convolution block.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.GroupedConvBlock.expansion">
<span class="sig-name descname"><span class="pre">expansion</span></span><em class="property"> <span class="pre">=</span> <span class="pre">4</span></em><a class="headerlink" href="#super_gradients.training.models.resnext.GroupedConvBlock.expansion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.GroupedConvBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#GroupedConvBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.GroupedConvBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.GroupedConvBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnext.GroupedConvBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.ResNeXt">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">ResNeXt</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cardinality</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bottleneck_width</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_stride_with_dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#ResNeXt"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.ResNeXt" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.ResNeXt.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#ResNeXt.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.ResNeXt.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.ResNeXt.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.resnext.ResNeXt.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.ResNeXt101">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">ResNeXt101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#ResNeXt101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.ResNeXt101" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.ResNeXt50">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">ResNeXt50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#ResNeXt50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.ResNeXt50" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.conv1x1">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">conv1x1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#conv1x1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.conv1x1" title="Permalink to this definition"></a></dt>
<dd><p>1x1 convolution</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.resnext.conv3x3">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.resnext.</span></span><span class="sig-name descname"><span class="pre">conv3x3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dilation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/resnext.html#conv3x3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.resnext.conv3x3" title="Permalink to this definition"></a></dt>
<dd><p>3x3 convolution with padding</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.senet">
<span id="super-gradients-training-models-senet-module"></span><h2>super_gradients.training.models.senet module<a class="headerlink" href="#module-super_gradients.training.models.senet" title="Permalink to this headline"></a></h2>
<p>SENet in PyTorch.</p>
<p>SENet is the winner of ImageNet-2017. The paper is not released yet.</p>
<p>Code adapted from <a class="reference external" href="https://github.com/fastai/imagenet-fast/blob/master/cifar10/models/cifar10/senet.py">https://github.com/fastai/imagenet-fast/blob/master/cifar10/models/cifar10/senet.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.BasicBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.senet.</span></span><span class="sig-name descname"><span class="pre">BasicBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#BasicBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.BasicBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.BasicBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#BasicBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.BasicBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.BasicBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.senet.BasicBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.PreActBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.senet.</span></span><span class="sig-name descname"><span class="pre">PreActBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#PreActBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.PreActBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.PreActBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#PreActBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.PreActBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.PreActBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.senet.PreActBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.SENet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.senet.</span></span><span class="sig-name descname"><span class="pre">SENet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#SENet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.SENet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.SENet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#SENet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.SENet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.SENet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.senet.SENet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.SENet18">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.senet.</span></span><span class="sig-name descname"><span class="pre">SENet18</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#SENet18"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.SENet18" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.senet.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.senet.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/senet.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.senet.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.sg_module">
<span id="super-gradients-training-models-sg-module-module"></span><h2>super_gradients.training.models.sg_module module<a class="headerlink" href="#module-super_gradients.training.models.sg_module" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.sg_module.</span></span><span class="sig-name descname"><span class="pre">SgModule</span></span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.get_exclude_attributes">
<span class="sig-name descname"><span class="pre">get_exclude_attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule.get_exclude_attributes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.get_exclude_attributes" title="Permalink to this definition"></a></dt>
<dd><p>This function is used by the EMA. When updating the EMA model, some attributes of the main model (used in training)
are updated to the EMA model along with the model weights.
By default, all attributes are updated except for private attributes (starting with ‘_’)
You can either set include_attributes or exclude_attributes. By returning a non empty list from this function,
you override the default behaviour and attributes named in this list will also be excluded from update.
Note: if get_include_attributes is not empty, it will override this list.</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>list of attributes to not update from main model to EMA mode</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.get_include_attributes">
<span class="sig-name descname"><span class="pre">get_include_attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule.get_include_attributes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.get_include_attributes" title="Permalink to this definition"></a></dt>
<dd><p>This function is used by the EMA. When updating the EMA model, some attributes of the main model (used in training)
are updated to the EMA model along with the model weights.
By default, all attributes are updated except for private attributes (starting with ‘_’)
You can either set include_attributes or exclude_attributes. By returning a non empty list from this function,
you override the default behaviour and only attributes named in this list will be updated.
Note: This will also override the get_exclude_attributes list.</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>list of attributes to update from main model to EMA model</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.initialize_param_groups">
<span class="sig-name descname"><span class="pre">initialize_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule.initialize_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.initialize_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>list of dictionaries containing the key ‘named_params’ with a list of named params</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.prep_model_for_conversion">
<span class="sig-name descname"><span class="pre">prep_model_for_conversion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule.prep_model_for_conversion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.prep_model_for_conversion" title="Permalink to this definition"></a></dt>
<dd><p>Prepare the model to be converted to ONNX or other frameworks.
Typically, this function will freeze the size of layers which is otherwise flexible, replace some modules
with convertible substitutes and remove all auxiliary or training related parts.
:param input_size: [H,W]</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.sg_module.SgModule.update_param_groups">
<span class="sig-name descname"><span class="pre">update_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_groups</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_batch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/sg_module.html#SgModule.update_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.sg_module.SgModule.update_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>param_groups</strong> – list of dictionaries containing the params</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of dictionaries containing the params</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.shelfnet">
<span id="super-gradients-training-models-shelfnet-module"></span><h2>super_gradients.training.models.shelfnet module<a class="headerlink" href="#module-super_gradients.training.models.shelfnet" title="Permalink to this headline"></a></h2>
<p>Shelfnet</p>
<p>paper: <a class="reference external" href="https://arxiv.org/abs/1811.11254">https://arxiv.org/abs/1811.11254</a>
based on: <a class="reference external" href="https://github.com/juntang-zhuang/ShelfNet">https://github.com/juntang-zhuang/ShelfNet</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.AttentionRefinementModule">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">AttentionRefinementModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chan</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chan</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#AttentionRefinementModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.AttentionRefinementModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.AttentionRefinementModule.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#AttentionRefinementModule.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.AttentionRefinementModule.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.AttentionRefinementModule.init_weight">
<span class="sig-name descname"><span class="pre">init_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#AttentionRefinementModule.init_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.AttentionRefinementModule.init_weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.AttentionRefinementModule.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.AttentionRefinementModule.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ConvBNReLU">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ConvBNReLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chan</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_chan</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ks</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ConvBNReLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ConvBNReLU" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="super_gradients.training.models.shelfnet.ShelfNetModuleBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetModuleBase</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ConvBNReLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ConvBNReLU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ConvBNReLU.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ConvBNReLU.init_weight">
<span class="sig-name descname"><span class="pre">init_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ConvBNReLU.init_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ConvBNReLU.init_weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ConvBNReLU.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ConvBNReLU.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">DecoderBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes:</span> <span class="pre">int</span></em>, <em class="sig-param"><span class="pre">layers:</span> <span class="pre">int</span></em>, <em class="sig-param"><span class="pre">kernel:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="super_gradients.training.models.shelfnet.ShelfNetModuleBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetModuleBase</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderBase.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderBase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderHW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">DecoderHW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">*args</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderHW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderHW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.DecoderBase" title="super_gradients.training.models.shelfnet.DecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.DecoderBase</span></code></a></p>
<p>DecoderHW - The Decoder for the Heavy-Weight ShelfNet Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderHW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderHW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderHW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderHW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderHW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderLW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">DecoderLW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">*args</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderLW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderLW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.DecoderBase" title="super_gradients.training.models.shelfnet.DecoderBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.DecoderBase</span></code></a></p>
<p>DecoderLW - The Decoder for the Light-Weight ShelfNet Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderLW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#DecoderLW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderLW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.DecoderLW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.DecoderLW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.FCNHead">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">FCNHead</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#FCNHead"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.FCNHead" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.FCNHead.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#FCNHead.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.FCNHead.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.FCNHead.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.FCNHead.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">LadderBlockBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes:</span> <span class="pre">int</span></em>, <em class="sig-param"><span class="pre">layers:</span> <span class="pre">int</span></em>, <em class="sig-param"><span class="pre">kernel:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">3</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="super_gradients.training.models.shelfnet.ShelfNetModuleBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetModuleBase</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockBase.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockBase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockHW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">LadderBlockHW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">*args</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockHW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockHW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.LadderBlockBase" title="super_gradients.training.models.shelfnet.LadderBlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.LadderBlockBase</span></code></a></p>
<p>LadderBlockHW - LadderBlock for the Heavy-Weight ShelfNet Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockHW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockHW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockHW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockHW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockHW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockLW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">LadderBlockLW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">planes</span></em>, <em class="sig-param"><span class="pre">layers</span></em>, <em class="sig-param"><span class="pre">block=&lt;class</span> <span class="pre">'super_gradients.training.models.shelfnet.ShelfBlock'&gt;</span></em>, <em class="sig-param"><span class="pre">*args</span></em>, <em class="sig-param"><span class="pre">**kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockLW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockLW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.LadderBlockBase" title="super_gradients.training.models.shelfnet.LadderBlockBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.LadderBlockBase</span></code></a></p>
<p>LadderBlockLW - LadderBlock for the Light-Weight ShelfNet Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockLW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#LadderBlockLW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockLW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.LadderBlockLW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.LadderBlockLW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.NetOutput">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">NetOutput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_chan</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_chan</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#NetOutput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.NetOutput" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="super_gradients.training.models.shelfnet.ShelfNetModuleBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetModuleBase</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.NetOutput.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#NetOutput.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.NetOutput.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.NetOutput.init_weight">
<span class="sig-name descname"><span class="pre">init_weight</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#NetOutput.init_weight"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.NetOutput.init_weight" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.NetOutput.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.NetOutput.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.25</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet101">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNet101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNet101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet101" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetHW" title="super_gradients.training.models.shelfnet.ShelfNetHW"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetHW</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet101.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet101.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet18">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNet18_LW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNet18"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet18" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetLW" title="super_gradients.training.models.shelfnet.ShelfNetLW"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetLW</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet18.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet18.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet34">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNet34_LW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNet34"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet34" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetLW" title="super_gradients.training.models.shelfnet.ShelfNetLW"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetLW</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet34.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet34.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet50">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNet50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNet50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet50" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetHW" title="super_gradients.training.models.shelfnet.ShelfNetHW"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetHW</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet50.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet50.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet503343">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNet503343</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNet503343"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet503343" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetHW" title="super_gradients.training.models.shelfnet.ShelfNetHW"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetHW</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNet503343.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNet503343.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNetBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backbone</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">planes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">21</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">512</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">net_output_mid_channels_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="super_gradients.training.models.shelfnet.ShelfNetModuleBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetModuleBase</span></code></a></p>
<p>ShelfNetBase - ShelfNet Base Generic Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetBase.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetBase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetBase.update_param_groups">
<span class="sig-name descname"><span class="pre">update_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_groups</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_batch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetBase.update_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetBase.update_param_groups" title="Permalink to this definition"></a></dt>
<dd><p>update_optimizer_for_param_groups - Updates the specific parameters with different LR</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetHW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNetHW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetHW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetHW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetBase" title="super_gradients.training.models.shelfnet.ShelfNetBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetBase</span></code></a></p>
<p>ShelfNetHW - Heavy-Weight Version of ShelfNet</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetHW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetHW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetHW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetHW.initialize_param_groups">
<span class="sig-name descname"><span class="pre">initialize_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetHW.initialize_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetHW.initialize_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>initialize_optimizer_for_model_param_groups - Initializes the weights of the optimizer</dt><dd><blockquote>
<div><p>Initializes the Backbone, the Output and the Auxilary Head
differently</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">param optimizer_cls</dt>
<dd class="field-odd"><p>The nn.optim (optimizer class) to initialize</p>
</dd>
<dt class="field-even">param lr</dt>
<dd class="field-even"><p>lr to set for the optimizer</p>
</dd>
<dt class="field-odd">param training_params</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>list of dictionaries with named params and optimizer attributes</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetHW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetHW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetLW">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNetLW</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetLW"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetLW" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfNetBase" title="super_gradients.training.models.shelfnet.ShelfNetBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfNetBase</span></code></a></p>
<p>ShelfNetLW - Light-Weight Implementation for ShelfNet</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetLW.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetLW.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetLW.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetLW.initialize_param_groups">
<span class="sig-name descname"><span class="pre">initialize_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetLW.initialize_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetLW.initialize_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>initialize_optimizer_for_model_param_groups - Initializes the optimizer group params, with 10x learning rate</dt><dd><blockquote>
<div><p>for all but the backbone</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">param lr</dt>
<dd class="field-odd"><p>lr to set for the backbone</p>
</dd>
<dt class="field-even">param training_params</dt>
<dd class="field-even"><p></p></dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>list of dictionaries with named params and optimizer attributes</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetLW.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetLW.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetModuleBase">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfNetModuleBase</span></span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetModuleBase"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<p>ShelfNetModuleBase - Base class for the different Modules of the ShelfNet Architecture</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetModuleBase.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetModuleBase.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetModuleBase.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfNetModuleBase.get_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase.get_params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfNetModuleBase.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfNetModuleBase.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">block</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_blocks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.resnet.ResNet" title="super_gradients.training.models.resnet.ResNet"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.resnet.ResNet</span></code></a></p>
<dl class="simple">
<dt>ShelfResNetBackBone - A class that Inherits from the original ResNet class and manipulates the forward pass,</dt><dd><p>to create a backbone for the ShelfNet architecture</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone101">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone101</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone101"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone101" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone101.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone101.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone18">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone18</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone18"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone18" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone18.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone18.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone34">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone34</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone34"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone34" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone34.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone34.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone50">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone50</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone50" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone50.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone50.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone503343">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shelfnet.</span></span><span class="sig-name descname"><span class="pre">ShelfResNetBackBone503343</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shelfnet.html#ShelfResNetBackBone503343"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone503343" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone" title="super_gradients.training.models.shelfnet.ShelfResNetBackBone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shelfnet.ShelfResNetBackBone</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shelfnet.ShelfResNetBackBone503343.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shelfnet.ShelfResNetBackBone503343.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.shufflenet">
<span id="super-gradients-training-models-shufflenet-module"></span><h2>super_gradients.training.models.shufflenet module<a class="headerlink" href="#module-super_gradients.training.models.shufflenet" title="Permalink to this headline"></a></h2>
<p>ShuffleNet in PyTorch.</p>
<p>See the paper “ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices” for more details.</p>
<p><a class="reference external" href="https://github.com/kuangliu/pytorch-cifar/blob/master/models/shufflenet.py">https://github.com/kuangliu/pytorch-cifar/blob/master/models/shufflenet.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.Bottleneck">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">Bottleneck</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_planes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#Bottleneck"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.Bottleneck" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.Bottleneck.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#Bottleneck.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.Bottleneck.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.Bottleneck.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenet.Bottleneck.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleBlock">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">ShuffleBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">groups</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleBlock" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleBlock.forward" title="Permalink to this definition"></a></dt>
<dd><p>Channel shuffle: [N,C,H,W] -&gt; [N,g,C/g,H,W] -&gt; [N,C/g,g,H,w] -&gt; [N,C,H,W]</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleBlock.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleBlock.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleNet">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">ShuffleNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cfg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleNet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleNet.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleNet.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleNet.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleNetG2">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">ShuffleNetG2</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleNetG2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleNetG2" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.ShuffleNetG3">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">ShuffleNetG3</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#ShuffleNetG3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.ShuffleNetG3" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenet.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenet.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenet.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenet.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.shufflenetv2">
<span id="super-gradients-training-models-shufflenetv2-module"></span><h2>super_gradients.training.models.shufflenetv2 module<a class="headerlink" href="#module-super_gradients.training.models.shufflenetv2" title="Permalink to this headline"></a></h2>
<p>ShuffleNetV2 in PyTorch.</p>
<p>See the paper “ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design” for more details.
(<a class="reference external" href="https://arxiv.org/abs/1807.11164">https://arxiv.org/abs/1807.11164</a>)</p>
<p>Code taken from torchvision/models/shufflenetv2.py</p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.CustomizedShuffleNetV2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">CustomizedShuffleNetV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#CustomizedShuffleNetV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.CustomizedShuffleNetV2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shufflenetv2.ShuffleNetV2Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.CustomizedShuffleNetV2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.CustomizedShuffleNetV2.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">ShuffleNetV2Base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">structure:</span> <span class="pre">List[int],</span> <span class="pre">stages_out_channels:</span> <span class="pre">List[int],</span> <span class="pre">backbone_mode:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">num_classes:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">1000,</span> <span class="pre">block:</span> <span class="pre">torch.nn.modules.module.Module</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'super_gradients.training.models.shufflenetv2.ChannelShuffleInvertedResidual'&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShuffleNetV2Base"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.Tensor</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShuffleNetV2Base.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShuffleNetV2Base.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>load_state_dict - Overloads the base method and calls it to load a modified dict for usage as a backbone
:param state_dict:  The state_dict to load
:param strict:      strict loading (see super() docs)</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x0_5">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">ShufflenetV2_x0_5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShufflenetV2_x0_5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x0_5" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shufflenetv2.ShuffleNetV2Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x0_5.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x0_5.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_0">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">ShufflenetV2_x1_0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShufflenetV2_x1_0"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_0" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shufflenetv2.ShuffleNetV2Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_0.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_0.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_5">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">ShufflenetV2_x1_5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShufflenetV2_x1_5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_5" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shufflenetv2.ShuffleNetV2Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_5.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x1_5.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x2_0">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.shufflenetv2.</span></span><span class="sig-name descname"><span class="pre">ShufflenetV2_x2_0</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">backbone_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/shufflenetv2.html#ShufflenetV2_x2_0"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x2_0" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.shufflenetv2.ShuffleNetV2Base" title="super_gradients.training.models.shufflenetv2.ShuffleNetV2Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.shufflenetv2.ShuffleNetV2Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.shufflenetv2.ShufflenetV2_x2_0.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.shufflenetv2.ShufflenetV2_x2_0.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.ssd">
<span id="super-gradients-training-models-ssd-module"></span><h2>super_gradients.training.models.ssd module<a class="headerlink" href="#module-super_gradients.training.models.ssd" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSD">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ssd.</span></span><span class="sig-name descname"><span class="pre">SSD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backbone</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SSD"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SSD" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<p>paper: <a class="reference external" href="https://arxiv.org/pdf/1512.02325.pdf">https://arxiv.org/pdf/1512.02325.pdf</a>
based on code: <a class="reference external" href="https://github.com/NVIDIA/DeepLearningExamples">https://github.com/NVIDIA/DeepLearningExamples</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSD.bbox_view">
<span class="sig-name descname"><span class="pre">bbox_view</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">src</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">conf</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SSD.bbox_view"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SSD.bbox_view" title="Permalink to this definition"></a></dt>
<dd><p>Shape the classifier to the view of bboxes</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSD.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SSD.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SSD.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSD.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ssd.SSD.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSDLiteMobileNetV2">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ssd.</span></span><span class="sig-name descname"><span class="pre">SSDLiteMobileNetV2</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SSDLiteMobileNetV2"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SSDLiteMobileNetV2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ssd.SSD" title="super_gradients.training.models.ssd.SSD"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ssd.SSD</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSDLiteMobileNetV2.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ssd.SSDLiteMobileNetV2.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSDMobileNetV1">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ssd.</span></span><span class="sig-name descname"><span class="pre">SSDMobileNetV1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SSDMobileNetV1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SSDMobileNetV1" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.ssd.SSD" title="super_gradients.training.models.ssd.SSD"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.ssd.SSD</span></code></a></p>
<p>paper: <a class="reference external" href="http://ceur-ws.org/Vol-2500/paper_5.pdf">http://ceur-ws.org/Vol-2500/paper_5.pdf</a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SSDMobileNetV1.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.ssd.SSDMobileNetV1.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.ssd.SeperableConv2d">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.ssd.</span></span><span class="sig-name descname"><span class="pre">SeperableConv2d</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/ssd.html#SeperableConv2d"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.ssd.SeperableConv2d" title="Permalink to this definition"></a></dt>
<dd><p>Replace Conv2d with a depthwise Conv2d and Pointwise Conv2d.</p>
</dd></dl>

</section>
<section id="module-super_gradients.training.models.vgg">
<span id="super-gradients-training-models-vgg-module"></span><h2>super_gradients.training.models.vgg module<a class="headerlink" href="#module-super_gradients.training.models.vgg" title="Permalink to this headline"></a></h2>
<p>VGG11/13/16/19 in Pytorch. Adapted from <a class="reference external" href="https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py">https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.vgg.VGG">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.vgg.</span></span><span class="sig-name descname"><span class="pre">VGG</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vgg_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/vgg.html#VGG"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.vgg.VGG" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.vgg.VGG.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/vgg.html#VGG.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.vgg.VGG.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.vgg.VGG.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.vgg.VGG.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="super_gradients.training.models.vgg.test">
<span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.vgg.</span></span><span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/vgg.html#test"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.vgg.test" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
<section id="module-super_gradients.training.models.yolov3">
<span id="super-gradients-training-models-yolov3-module"></span><h2>super_gradients.training.models.yolov3 module<a class="headerlink" href="#module-super_gradients.training.models.yolov3" title="Permalink to this headline"></a></h2>
<p>Yolov3 code adapted from <a class="reference external" href="https://github.com/ultralytics/yolov3">https://github.com/ultralytics/yolov3</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.SPPLayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov3.</span></span><span class="sig-name descname"><span class="pre">SPPLayer</span></span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#SPPLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.SPPLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.SPPLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#SPPLayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.SPPLayer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.SPPLayer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov3.SPPLayer.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.TinyYoloV3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov3.</span></span><span class="sig-name descname"><span class="pre">TinyYoloV3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">80</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">416</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_t</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.225</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yolo_v3_anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#TinyYoloV3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.TinyYoloV3" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov3.YoloV3" title="super_gradients.training.models.yolov3.YoloV3"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov3.YoloV3</span></code></a></p>
<p>TinyYoloV3 - Inherits from YoLoV3 class and overloads the relevant methods and members</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.TinyYoloV3.concatenate_layer_output">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">concatenate_layer_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_index</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">route_layers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">tuple</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#TinyYoloV3.concatenate_layer_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.TinyYoloV3.concatenate_layer_output" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – input for the layer</p></li>
<li><p><strong>layer_index</strong> – the layer index to decide how to concatenate to</p></li>
<li><p><strong>route_layers</strong> – the route layers list with previous data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tuple of x, route_layers</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.TinyYoloV3.create_modules_list">
<span class="sig-name descname"><span class="pre">create_modules_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#TinyYoloV3.create_modules_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.TinyYoloV3.create_modules_list" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>create_tiny_modules_list</dt><dd><dl class="field-list simple">
<dt class="field-odd">param num_classes</dt>
<dd class="field-odd"><p>The Number of different Classes</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>nn.ModuleList with the Tiny-Yolo-V3 Architecture</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.TinyYoloV3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov3.TinyYoloV3.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.Upsample">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov3.</span></span><span class="sig-name descname"><span class="pre">Upsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scale_factor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nearest'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#Upsample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.Upsample" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.Upsample.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#Upsample.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.Upsample.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.Upsample.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov3.Upsample.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YOLOLayer">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov3.</span></span><span class="sig-name descname"><span class="pre">YOLOLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">anchors_mask</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes_num</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_export_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YOLOLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YOLOLayer" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YOLOLayer.create_grids">
<span class="sig-name descname"><span class="pre">create_grids</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(416,</span> <span class="pre">416)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grid_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(13,</span> <span class="pre">13)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'cpu'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YOLOLayer.create_grids"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YOLOLayer.create_grids" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>create_grids - Creates the grids for image sizes that are different than the model’s defualt image size</dt><dd><dl class="field-list simple">
<dt class="field-odd">param img_size</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">param grid_size</dt>
<dd class="field-even"><p></p></dd>
<dt class="field-odd">param device</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">param data_type</dt>
<dd class="field-even"><p></p></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YOLOLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img_size</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YOLOLayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YOLOLayer.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YOLOLayer.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov3.YOLOLayer.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov3.</span></span><span class="sig-name descname"><span class="pre">YoloV3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">80</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">416</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iou_t</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0.225</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yolo_v3_anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_export_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.add_yolo_layer_to_modules_list">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">add_yolo_layer_to_modules_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">modules_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">torch.nn.modules.container.ModuleList</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">yolo_v3_anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchors_mask</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_stride</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onnx_export_mode</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.nn.modules.container.ModuleList</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.add_yolo_layer_to_modules_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.add_yolo_layer_to_modules_list" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>add_yolo_layer_to_modules_list - Adds a YoLo Head Layer to the nn.ModuleList</dt><dd><dl class="field-list simple">
<dt class="field-odd">param modules_list</dt>
<dd class="field-odd"><p>The Modules List</p>
</dd>
<dt class="field-even">param image_size</dt>
<dd class="field-even"><p>The YoLo Model Image Size</p>
</dd>
<dt class="field-odd">param yolo_v3_anchors</dt>
<dd class="field-odd"><p>The Anchors (K-Means) List for the YoLo Layer Initialization</p>
</dd>
<dt class="field-even">param anchors_mask</dt>
<dd class="field-even"><p>the mask to get the relevant anchors</p>
</dd>
<dt class="field-odd">param num_classes</dt>
<dd class="field-odd"><p>The number of different classes in the data</p>
</dd>
<dt class="field-even">param onnx_stride</dt>
<dd class="field-even"><p>The stride of the layer for ONNX grid points calculation in YoLo Layer init</p>
</dd>
<dt class="field-odd">param onnx_export_mode</dt>
<dd class="field-odd"><p>Alter the model YoLo Layer for ONNX Export</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The nn.ModuleList with the Added Yolo layer, and a Bias Initialization</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.concatenate_layer_output">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">concatenate_layer_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layer_index</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">route_layers</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">tuple</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.concatenate_layer_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.concatenate_layer_output" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – input for the layer</p></li>
<li><p><strong>layer_index</strong> – the layer index to decide how to concatenate to</p></li>
<li><p><strong>route_layers</strong> – the route layers list with previous data</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>tuple of x, route_layers</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.create_modules_list">
<span class="sig-name descname"><span class="pre">create_modules_list</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.create_modules_list"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.create_modules_list" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>num_classes</strong> – </p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.get_yolo_layers_indices">
<span class="sig-name descname"><span class="pre">get_yolo_layers_indices</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.get_yolo_layers_indices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.get_yolo_layers_indices" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.initialize_param_groups">
<span class="sig-name descname"><span class="pre">initialize_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.initialize_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.initialize_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>initialize_optimizer_for_model_param_groups - Initializes the optimizer group params,</dt><dd><blockquote>
<div><p>adds weight decay  <em>Only</em> to the Conv2D layers</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">param lr</dt>
<dd class="field-odd"><p>lr to set for the optimizer</p>
</dd>
<dt class="field-even">param training_params</dt>
<dd class="field-even"><p></p></dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>A dictionary with named params and optimizer attributes</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.named_sequential_module">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">named_sequential_module</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">torch.nn.modules.container.Sequential</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.named_sequential_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.named_sequential_module" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>create_named_nn_sequential_module</dt><dd><dl class="field-list simple">
<dt class="field-odd">param module_name</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">param module</dt>
<dd class="field-even"><p></p></dd>
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>nn.Sequential() with the added relevant names</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.prep_model_for_conversion">
<span class="sig-name descname"><span class="pre">prep_model_for_conversion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov3.html#YoloV3.prep_model_for_conversion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.prep_model_for_conversion" title="Permalink to this definition"></a></dt>
<dd><p>Method for preparing the Yolov3 and TinyYolov3 for conversion (ONNX, TRT, CoreML etc).
:param input_size: used for calculating the grid points.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov3.YoloV3.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov3.YoloV3.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models.yolov5">
<span id="super-gradients-training-models-yolov5-module"></span><h2>super_gradients.training.models.yolov5 module<a class="headerlink" href="#module-super_gradients.training.models.yolov5" title="Permalink to this headline"></a></h2>
<p>YoloV5 code adapted from <a class="reference external" href="https://github.com/ultralytics/yolov5/blob/master/models/yolo.py">https://github.com/ultralytics/yolov5/blob/master/models/yolo.py</a></p>
<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.AbstractYoLoV5Backbone">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">AbstractYoLoV5Backbone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#AbstractYoLoV5Backbone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.AbstractYoLoV5Backbone" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.AbstractYoLoV5Backbone.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#AbstractYoLoV5Backbone.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.AbstractYoLoV5Backbone.forward" title="Permalink to this definition"></a></dt>
<dd><p>:return A list, the length of self._modules_list containing the output of the layer if specified in
self._layers_to_extract and None otherwise</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Concat">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">Concat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dimension</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#Concat"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.Concat" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CONCATENATE A LIST OF TENSORS ALONG DIMENSION</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Concat.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#Concat.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.Concat.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Concat.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.Concat.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Custom_YoLoV5">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">Custom_YoLoV5</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#Custom_YoLoV5"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.Custom_YoLoV5" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="super_gradients.training.models.yolov5.YoLoV5Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.YoLoV5Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Custom_YoLoV5.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.Custom_YoLoV5.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Detect">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">Detect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchors</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.detection_utils.Anchors" title="super_gradients.training.utils.detection_utils.Anchors"><span class="pre">super_gradients.training.utils.detection_utils.Anchors</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">list</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">width_mult_factor</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#Detect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.Detect" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Detect.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#Detect.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.Detect.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.Detect.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.Detect.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5Base</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">backbone</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Type</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.nn.modules.module.Module</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">initialize_module</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.sg_module.SgModule" title="super_gradients.training.models.sg_module.SgModule"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.sg_module.SgModule</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.forward" title="Permalink to this definition"></a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.get_include_attributes">
<span class="sig-name descname"><span class="pre">get_include_attributes</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.get_include_attributes"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.get_include_attributes" title="Permalink to this definition"></a></dt>
<dd><p>This function is used by the EMA. When updating the EMA model, some attributes of the main model (used in training)
are updated to the EMA model along with the model weights.
By default, all attributes are updated except for private attributes (starting with ‘_’)
You can either set include_attributes or exclude_attributes. By returning a non empty list from this function,
you override the default behaviour and only attributes named in this list will be updated.
Note: This will also override the get_exclude_attributes list.</p>
<blockquote>
<div><dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>list of attributes to update from main model to EMA model</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.initialize_param_groups">
<span class="sig-name descname"><span class="pre">initialize_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.initialize_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.initialize_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl>
<dt>initialize_optimizer_for_model_param_groups - Initializes the weights of the optimizer</dt><dd><blockquote>
<div><p>adds weight decay  <em>Only</em> to the Conv2D layers</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">param optimizer_cls</dt>
<dd class="field-odd"><p>The nn.optim (optimizer class) to initialize</p>
</dd>
<dt class="field-even">param lr</dt>
<dd class="field-even"><p>lr to set for the optimizer</p>
</dd>
<dt class="field-odd">param training_params</dt>
<dd class="field-odd"><p></p></dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>The optimizer, initialized with the relevant param groups</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.load_state_dict">
<span class="sig-name descname"><span class="pre">load_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.load_state_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.load_state_dict" title="Permalink to this definition"></a></dt>
<dd><p>Copies parameters and buffers from <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> must exactly match the keys returned
by this module’s <code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>state_dict (dict): a dict containing parameters and</dt><dd><p>persistent buffers.</p>
</dd>
<dt>strict (bool, optional): whether to strictly enforce that the keys</dt><dd><p>in <code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code> match the keys returned by this module’s
<code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields:</dt><dd><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.prep_model_for_conversion">
<span class="sig-name descname"><span class="pre">prep_model_for_conversion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">tuple</span><span class="p"><span class="pre">,</span> </span><span class="pre">list</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.prep_model_for_conversion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.prep_model_for_conversion" title="Permalink to this definition"></a></dt>
<dd><p>A method for preparing the YoloV5 model for conversion to other frameworks (ONNX, CoreML etc)
:param input_size: expected input size
:return:</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Base.update_param_groups">
<span class="sig-name descname"><span class="pre">update_param_groups</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">param_groups</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lr</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iter</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_batch</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Base.update_param_groups"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Base.update_param_groups" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>param_groups</strong> – list of dictionaries containing the params</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>list of dictionaries containing the params</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5DarknetBackbone">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5DarknetBackbone</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5DarknetBackbone"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5DarknetBackbone" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.AbstractYoLoV5Backbone" title="super_gradients.training.models.yolov5.AbstractYoLoV5Backbone"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.AbstractYoLoV5Backbone</span></code></a>, <a class="reference internal" href="#super_gradients.training.models.csp_darknet53.CSPDarknet53" title="super_gradients.training.models.csp_darknet53.CSPDarknet53"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.csp_darknet53.CSPDarknet53</span></code></a></p>
<p>Implements the CSP_Darknet53 module and inherit the forward pass to extract layers indicated in arch_params</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5DarknetBackbone.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5DarknetBackbone.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5DarknetBackbone.forward" title="Permalink to this definition"></a></dt>
<dd><p>:return A list, the length of self._modules_list containing the output of the layer if specified in
self._layers_to_extract and None otherwise</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5DarknetBackbone.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5DarknetBackbone.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Head">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5Head</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Head"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Head" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Head.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">intermediate_output</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5Head.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Head.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>intermediate_output</strong> – A list of the intermediate prediction of layers specified in the</p>
</dd>
</dl>
<p>self._inter_layer_idx_to_extract from the Backbone</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5Head.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5Head.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5L">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5L</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5L"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5L" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="super_gradients.training.models.yolov5.YoLoV5Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.YoLoV5Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5L.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5L.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5M">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5M</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5M"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5M" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="super_gradients.training.models.yolov5.YoLoV5Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.YoLoV5Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5M.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5M.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5S">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5S</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5S"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5S" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="super_gradients.training.models.yolov5.YoLoV5Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.YoLoV5Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5S.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5S.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5X">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoLoV5X</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">arch_params</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.utils.HpmStruct" title="super_gradients.training.utils.utils.HpmStruct"><span class="pre">super_gradients.training.utils.utils.HpmStruct</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoLoV5X"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5X" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#super_gradients.training.models.yolov5.YoLoV5Base" title="super_gradients.training.models.yolov5.YoLoV5Base"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.models.yolov5.YoLoV5Base</span></code></a></p>
<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoLoV5X.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoLoV5X.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoloV5PostPredictionCallback">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">super_gradients.training.models.yolov5.</span></span><span class="sig-name descname"><span class="pre">YoloV5PostPredictionCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">conf:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.001</span></em>, <em class="sig-param"><span class="pre">iou:</span> <span class="pre">float</span> <span class="pre">=</span> <span class="pre">0.6</span></em>, <em class="sig-param"><span class="pre">classes:</span> <span class="pre">Optional[List[int]]</span> <span class="pre">=</span> <span class="pre">None</span></em>, <em class="sig-param"><span class="pre">nms_type:</span> <span class="pre">super_gradients.training.utils.detection_utils.NMS_Type</span> <span class="pre">=</span> <span class="pre">&lt;NMS_Type.ITERATIVE:</span> <span class="pre">'iterative'&gt;</span></em>, <em class="sig-param"><span class="pre">max_predictions:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">300</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoloV5PostPredictionCallback"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoloV5PostPredictionCallback" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="super_gradients.training.utils.html#super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback" title="super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback"><code class="xref py py-class docutils literal notranslate"><span class="pre">super_gradients.training.utils.detection_utils.DetectionPostPredictionCallback</span></code></a></p>
<p>Non-Maximum Suppression (NMS) module</p>
<dl class="py method">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoloV5PostPredictionCallback.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/super_gradients/training/models/yolov5.html#YoloV5PostPredictionCallback.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#super_gradients.training.models.yolov5.YoloV5PostPredictionCallback.forward" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the output of your model</p></li>
<li><p><strong>device</strong> – the device to move all output tensors into</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list with length batch_size, each item in the list is a detections
with shape: nx6 (x1, y1, x2, y2, confidence, class) where x and y are in range [0,1]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="super_gradients.training.models.yolov5.YoloV5PostPredictionCallback.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <span class="pre">bool</span></em><a class="headerlink" href="#super_gradients.training.models.yolov5.YoloV5PostPredictionCallback.training" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-super_gradients.training.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-super_gradients.training.models" title="Permalink to this headline"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="super_gradients.training.metrics.html" class="btn btn-neutral float-left" title="super_gradients.training.metrics package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="super_gradients.training.sg_model.html" class="btn btn-neutral float-right" title="super_gradients.training.sg_model package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, SuperGradients team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>