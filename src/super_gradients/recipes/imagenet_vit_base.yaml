#  ViT Imagenet1K fine tuning from Imagenet21K classification training:
#  This example trains with batch_size = 64 * 8 GPUs, total 512.
#  Training time on 8 x GeForce RTX A5000 is 15min / epoch.
#  ViT base : 84.15
#
#  Log and tensorboard at s3://deci-pretrained-models/vit_base_imagenet1k/

# Instructions:
# running from the command line, set the PYTHONPATH environment variable: (Replace "YOUR_LOCAL_PATH" with the path to the downloaded repo):
#   export PYTHONPATH="YOUR_LOCAL_PATH"/super_gradients/
# Then:
# for vit_base:
#   python -m torch.distributed.launch --nproc_per_node=8 train_from_recipe_example/train_from_recipe.py --config-name=imagenet_vit_base


defaults:
  - training_hyperparams: imagenet_vit_train_params
  - dataset_params: imagenet_vit_base_dataset_params
  - arch_params: vit_base_arch_params
  - checkpoint_params: vit_base_imagenet_checkpoint_params

model_checkpoints_location: local
load_checkpoint: True
load_weights_only: True

experiment_name: vit_base_imagenet1k

architecture: vit_base