defaults:
  - training_hyperparams: coco2017_dekr_pose_train_params
  - dataset_params: coco_pose_estimation_dekr_dataset_params
  - arch_params: dekr_w32
  - checkpoint_params: default_checkpoint_params
  - _self_

train_dataloader: coco2017_pose_train
val_dataloader: coco2017_pose_val

dataset_params:
  train_dataloader_params:
    batch_size: 8

  val_dataloader_params:
    batch_size: 16

training_hyperparams:
  phase_callbacks: []
#   Note: You can uncomment following block to enable visualization of intermediate results during training.
#   When enabled, these callbacks will save first batch from training & validation to Tensorboard.
#   This is helpful for debugging and doing visual checks whether predictions are reasonable and transforms are
#   working as expected.
#   The only downside is that it tend to bloat Tensorboard logs (Up to ten Gigs for long training regimes).
#  phase_callbacks:
#    - DEKRVisualizationCallback:
#        phase:
#          _target_: super_gradients.training.utils.callbacks.callbacks.Phase
#          value: TRAIN_BATCH_END
#        prefix: "train_"
#        mean: [ 0.485, 0.456, 0.406 ]
#        std: [ 0.229, 0.224, 0.225 ]
#        apply_sigmoid: False
#
#    - DEKRVisualizationCallback:
#        phase:
#          _target_: super_gradients.training.utils.callbacks.callbacks.Phase
#          value: VALIDATION_BATCH_END
#        prefix: "val_"
#        mean: [ 0.485, 0.456, 0.406 ]
#        std: [ 0.229, 0.224, 0.225 ]
#        apply_sigmoid: False



load_checkpoint: False
resume: False

architecture: dekr_custom

multi_gpu: DDP
num_gpus: 8

experiment_suffix: ""
experiment_name: coco2017_pose_${architecture}${experiment_suffix}

ckpt_root_dir:


# THE FOLLOWING PARAMS ARE DIRECTLY USED BY HYDRA
hydra:
  run:
    # Set the output directory (i.e. where .hydra folder that logs all the input params will be generated)
    dir: ${hydra_output_dir:${ckpt_root_dir}, ${experiment_name}}
