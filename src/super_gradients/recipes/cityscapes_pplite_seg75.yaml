#  PPLiteSeg segmentation training example with Cityscapes dataset.
#  Torch implementation of the paper:
#     Juncai Peng, Yi Liu, Shiyu Tang, Yuying Hao, Lutao Chu, Guowei Chen, Zewu Wu, Zeyu Chen, Zhiliang Yu, Yuning Du,
#     Qingqing Dang,Baohua Lai, Qiwen Liu, Xiaoguang Hu, Dianhai Yu, Yanjun Ma.
#     PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model.
#
#  Usage PPLite-T-Seg75:
#      python -m torch.distributed.launch --nproc_per_node=4 train_from_recipe.py --config-name=cityscapes_pplite_seg75 checkpoint_params.external_checkpoint_path=<stdc1-backbone-pretrained-path> architecture=pp_liteseg_t
#  Usage PPLite-B-Seg75:
#      python -m torch.distributed.launch --nproc_per_node=4 train_from_recipe.py --config-name=cityscapes_pplite_seg75 checkpoint_params.external_checkpoint_path=<stdc2-backbone-pretrained-path> architecture=pp_liteseg_b
#
#
#  Validation mIoU - Cityscapes, training time:
#      PPLite-T-Seg75:    input-size: [768, 1536]     mIoU: 77.56     4 X RTX A5000, 13 H
#      PPLite-B-Seg75:    input-size: [768, 1536]     mIoU: 78.52     4 X RTX A5000, 14 H
#
#  Official git repo:
#      https://github.com/PaddlePaddle/PaddleSeg/
#  Paper:
#      https://arxiv.org/abs/2204.02681
#
#  Pretrained checkpoints:
#      Backbones- downloaded from the STDC author's official repo.
#       PPLite-T-Seg75, (STDC1-backbone):   https://deci-pretrained-models.s3.amazonaws.com/stdc_backbones/stdc1_imagenet_pretrained.pth
#       PPLite-B-Seg75, (STDC2-backbone):   https://deci-pretrained-models.s3.amazonaws.com/stdc_backbones/stdc2_imagenet_pretrained.pth
#
#      Logs, tensorboards and network checkpoints:
#       PPLite-T-Seg75: https://deci-pretrained-models.s3.amazonaws.com/ppliteseg/cityscapes/pplite_t_seg75/
#       PPLite-B-Seg75: https://deci-pretrained-models.s3.amazonaws.com/ppliteseg/cityscapes/pplite_b_seg75/
#
#  Learning rate and batch size parameters, using 2 RTX A5000 with DDP:
#      PPLite-T-Seg75:    input-size: [768, 768]     initial_lr: 0.01    batch-size: 8 * 4gpus = 32
#      PPLite-B-Seg75:    input-size: [768, 768]     initial_lr: 0.01    batch-size: 8 * 4gpus = 32
#
#  Comments:
#      * ImageNet Pretrained backbones were used.

defaults:
  - cityscapes_pplite_seg50
  - _self_

dataset_params:
  _convert_: all
  batch_size: 8
  val_batch_size: 8
  crop_size: [768, 768]
  eval_scale: 0.75
  random_scales: [ 0.25, 1.75 ]

experiment_name: ${architecture}_75_cityscapes
